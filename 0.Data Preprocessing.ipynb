{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import calculate\n",
    "from calculate import gini, h_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify how long is the early career. Impacts which papers we take into account for early productivity and quality\n",
    "# EARLY_CAREER_LEN = 3\n",
    "EARLY_CAREER_LEN_LIST = [3, 6, 9, 12]\n",
    "# EARLY_CAREER_LEN_LIST = [3]\n",
    "# For early career work, when do we stop counting citations. Impacts recognition\n",
    "RECOGNITION_CUT_OFF_LIST = [3, 6, 9, 12]\n",
    "# RECOGNITION_CUT_OFF_LIST = [3]\n",
    "# Success after 15 years. Impacts when we stop counting citations\n",
    "SUCCESS_CUTOFF = 15\n",
    "SUCCESS_CUTOFF_LIST = [15] #6, 8, \n",
    "# Length of observed career for dropouts\n",
    "# (1-3), middle career (4-9), late career (10-15)\n",
    "CAREER_LENGTH_DROPOUTS_LIST = [(0, 15)]\n",
    "# CAREER_LENGTH_DROPOUTS = wi\n",
    "# INACTIVE_TIME_DROPOUTS = 10\n",
    "INACTIVE_TIME_DROPOUTS_LIST = [5,10]\n",
    "\n",
    "# Specify the first and last year we consider in our analysis\n",
    "START_YEAR = 1970\n",
    "LAST_START_YEAR = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_years(START_YEAR, LAST_START_YEAR):\n",
    "    all_years = credible_authors.start_year.unique()\n",
    "    start_years = [year for year in all_years if START_YEAR <= year <= LAST_START_YEAR]\n",
    "    start_years = sorted(start_years)\n",
    "    return start_years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cheat load\n",
    "# credible_authors = pd.read_csv('derived-data/authors-scientific-extended.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv raw data\n",
    "# publications\n",
    "authorPublicationData = pd.read_csv('./data/author_publications_2017_asiansAsNone.txt')\n",
    "# citations\n",
    "authorCitationsData = pd.read_csv('./data/citations_2017_asiansAsNone.txt')\n",
    "# arxiv\n",
    "arxiv_pubid = pd.read_csv('derived-data/arxiv_pubid_2017.csv', header=None, names=['pub_id'])\n",
    "# venue data\n",
    "publication_venues_rank = pd.read_csv('derived-data/publication-venues-rank.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates and remove arxiv\n",
    "print(authorPublicationData.shape)\n",
    "authorPublicationData.drop_duplicates(subset=['author', 'pub_id'], inplace=True)\n",
    "print(authorPublicationData.shape)\n",
    "authorPublicationData = authorPublicationData.loc[~authorPublicationData.pub_id.isin(arxiv_pubid['pub_id'])]\n",
    "print(authorPublicationData.shape)\n",
    "\n",
    "print(authorCitationsData.shape)\n",
    "authorCitationsData.drop_duplicates(inplace=True)\n",
    "print(authorCitationsData.shape)\n",
    "authorCitationsData = authorCitationsData.loc[(~authorCitationsData.id1.isin(arxiv_pubid['pub_id']))]\n",
    "authorCitationsData = authorCitationsData.loc[(~authorCitationsData.id2.isin(arxiv_pubid['pub_id']))]\n",
    "print(authorCitationsData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Authors#      - ', authorPublicationData['author'].nunique())\n",
    "print('Years#        - ', authorPublicationData['year'].nunique())\n",
    "print('Publications# - ', authorPublicationData['pub_id'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Career length and gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "groupByAuthor = authorPublicationData.groupby(['author'])\n",
    "\n",
    "groupByAuthorMinYearData = groupByAuthor['year'].min()\n",
    "groupByAuthorMaxYearData = groupByAuthor['year'].max()\n",
    "groupByAuthorCountPublicationsData = groupByAuthor['pub_id'].count()\n",
    "\n",
    "authorGroupedData = groupByAuthorMinYearData.to_frame(name='start_year')\n",
    "authorGroupedData['end_year'] = groupByAuthorMaxYearData\n",
    "authorGroupedData['total_num_pub'] = groupByAuthorCountPublicationsData\n",
    "authorGroupedData = authorGroupedData.reset_index()\n",
    "print('Total rows -                ', authorGroupedData.shape)\n",
    "\n",
    "authorGroupedData = authorGroupedData.drop_duplicates()\n",
    "print('After removing duplicates - ', authorGroupedData.shape)\n",
    "\n",
    "authorGroupedData = authorGroupedData.dropna(how='any')\n",
    "print(\"After droping na -          \", authorGroupedData.shape)\n",
    "\n",
    "authorGroupedData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 1 here to have career length be at least one. So 3 years career means year1, year2, year3.\n",
    "authorGroupedData[\"career_length\"] = authorGroupedData['end_year'] - authorGroupedData['start_year'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_authors = authorGroupedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# career len but limited to 15y\n",
    "credible_authors[\"career_length_15\"] = credible_authors[\"career_length\"].apply(lambda x: x if x<=15 else 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = pd.read_csv('./data/name_gender_2017_asiansAsNone_nodup.txt')\n",
    "credible_authors = credible_authors.merge(gender, left_on='author', right_on='name', how='left')\n",
    "credible_authors.drop('name', axis=1, inplace=True)\n",
    "\n",
    "print(credible_authors.gender.value_counts())\n",
    "gender.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save filtered data about authors, and cleaned publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_cred_authors(START_YEAR, LAST_START_YEAR):\n",
    "    return credible_authors[\n",
    "        (credible_authors.start_year >= START_YEAR) & (credible_authors.start_year <= LAST_START_YEAR)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_cred_authors(START_YEAR, LAST_START_YEAR).to_csv('derived-data/authors-scientific.csv', index=False,\n",
    "                                                        encoding='utf-8')\n",
    "credible_authors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authorPublicationData.to_csv('derived-data/author-publications.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authorPublicationData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare DFs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DF1 - Publications and Citations, no uncited papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every author and paper => every citation to the paper\n",
    "# Doesnt contain uncited papers\n",
    "# Contains multiple authors per paper\n",
    "# This is good for per author analysis\n",
    "# This is bad for per paper analysis\n",
    "publications_citations_no_uncited = authorPublicationData.merge(authorCitationsData, left_on='pub_id',\n",
    "                                                                right_on='id2', how='inner', suffixes=('_pub', '_cit'))\n",
    "publications_citations_no_uncited = publications_citations_no_uncited.merge(credible_authors[['author', 'start_year']],\n",
    "                                                                            on='author', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove cited before published\n",
    "publications_citations_no_uncited = publications_citations_no_uncited[\n",
    "    publications_citations_no_uncited.year_pub <= publications_citations_no_uncited.year_cit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate authors\n",
    "# no uncited papers\n",
    "paper_paper_citations = publications_citations_no_uncited[['id1', 'id2', 'year_pub', 'year_cit']]\n",
    "paper_paper_citations = paper_paper_citations.drop_duplicates(subset=['id1', 'id2'])\n",
    "paper_total_citations = paper_paper_citations.groupby('id2')['id1'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DF2 - Publications with uncited papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contains uncited papers\n",
    "# Good for early career publication related analysis\n",
    "publications_start_year = authorPublicationData.merge(credible_authors[['author', 'start_year']], on='author',\n",
    "                                                      how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DF3 - Author order in publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "publications_first_author = pd.read_csv('derived-data/publication_authors_order_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "publications_first_author = publications_first_author.merge(credible_authors[['author', 'start_year']],\n",
    "                                                            left_on='first_author',\n",
    "                                                            right_on='author', how='left')\n",
    "publications_first_author = publications_first_author.drop('first_author', axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author yearly citations and publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of citations an author receives per year\n",
    "author_yearly_citations = publications_citations_no_uncited.groupby(['author', 'year_cit'])['id1'].count()\n",
    "author_yearly_citations = author_yearly_citations.reset_index()\n",
    "author_yearly_citations = author_yearly_citations.rename(columns={'id1': 'num_cit', 'year_cit': 'year'})\n",
    "author_yearly_citations[['author', 'year', 'num_cit']].to_csv('derived-data/authors-perYear-citations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_yearly_publications = authorPublicationData.groupby(['author', 'year'])['pub_id'].count().reset_index()\n",
    "author_yearly_publications = author_yearly_publications.rename(columns={'pub_id': 'num_pub'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publication and citation based analysis - DF1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: Early quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "    combined_early_quality = publications_citations_no_uncited[\n",
    "        (publications_citations_no_uncited.year_pub < publications_citations_no_uncited.start_year + EARLY_CAREER) &\n",
    "        (publications_citations_no_uncited.year_cit < publications_citations_no_uncited.start_year + SUCCESS_CUTOFF)]\n",
    "\n",
    "    author_order_early = publications_first_author[\n",
    "        (publications_first_author.year < publications_first_author.start_year + EARLY_CAREER)]\n",
    "    early_career_quality_first = combined_early_quality.loc[\n",
    "        combined_early_quality['pub_id'].isin(author_order_early['pub_id'])]\n",
    "\n",
    "    early_career_quality = combined_early_quality.groupby('author')['id1'].count()\n",
    "    early_career_quality_first = early_career_quality_first.groupby('author')['id1'].count()\n",
    "\n",
    "    early_career_quality = early_career_quality.rename(f'early_career_qual_{EARLY_CAREER}').reset_index()\n",
    "    early_career_quality_first = early_career_quality_first.rename(\n",
    "        f'early_career_qual_first_{EARLY_CAREER}').reset_index()\n",
    "\n",
    "    credible_authors = credible_authors.merge(early_career_quality, on='author', how='left')\n",
    "    credible_authors = credible_authors.merge(early_career_quality_first, on='author', how='left')\n",
    "\n",
    "    credible_authors[f'early_career_qual_{EARLY_CAREER}'] = credible_authors[\n",
    "        f'early_career_qual_{EARLY_CAREER}'].fillna(0)\n",
    "    credible_authors[f'early_career_qual_first_{EARLY_CAREER}'] = credible_authors[\n",
    "        f'early_career_qual_first_{EARLY_CAREER}'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Early recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "    for RECOGNITION_CUT in RECOGNITION_CUT_OFF_LIST:\n",
    "        if RECOGNITION_CUT != EARLY_CAREER: continue\n",
    "        early_career_recognition = publications_citations_no_uncited[\n",
    "            (publications_citations_no_uncited.year_pub < publications_citations_no_uncited.start_year + EARLY_CAREER) &\n",
    "            (publications_citations_no_uncited.year_cit < publications_citations_no_uncited.start_year + RECOGNITION_CUT)]\n",
    "        early_career_recognition = early_career_recognition.groupby('author')['id1'].count()\n",
    "        col_name = f'early_career_recognition_EC{EARLY_CAREER}_RC{RECOGNITION_CUT}'\n",
    "        early_career_recognition = early_career_recognition.rename(col_name)\n",
    "        early_career_recognition = early_career_recognition.reset_index()\n",
    "        credible_authors = credible_authors.merge(early_career_recognition, on='author', how='left')\n",
    "        credible_authors[col_name] = credible_authors[col_name].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: Citation count after X years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for SUCCESS_CUTOFF in [*EARLY_CAREER_LEN_LIST, *SUCCESS_CUTOFF_LIST]:\n",
    "    publications_citations_before_cutoff = publications_citations_no_uncited[\n",
    "        publications_citations_no_uncited.year_cit < publications_citations_no_uncited.start_year + SUCCESS_CUTOFF]\n",
    "    citations_per_author = publications_citations_before_cutoff.groupby('author')['id1'].count()\n",
    "\n",
    "    citations_per_author = citations_per_author.rename(f'citation_count_{SUCCESS_CUTOFF}')\n",
    "    citations_per_author = citations_per_author.reset_index()\n",
    "    credible_authors = credible_authors.merge(citations_per_author, on='author', how='left')\n",
    "    credible_authors[f'citation_count_{SUCCESS_CUTOFF}'] = credible_authors[f'citation_count_{SUCCESS_CUTOFF}'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: H index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for YEAR in [*EARLY_CAREER_LEN_LIST, *SUCCESS_CUTOFF_LIST]:\n",
    "    combined_h_index = publications_citations_no_uncited[\n",
    "        publications_citations_no_uncited.year_cit < publications_citations_no_uncited.start_year + YEAR]\n",
    "\n",
    "    combined_h_index = combined_h_index.groupby(['author', 'pub_id'])['id1'].count()\n",
    "    combined_h_index = combined_h_index.reset_index()\n",
    "    combined_h_index = combined_h_index.groupby('author')['id1'].apply(lambda x: h_index(x.values))\n",
    "    combined_h_index = combined_h_index.rename(f'h-index_{YEAR}')\n",
    "\n",
    "    credible_authors = credible_authors.merge(combined_h_index.reset_index(), on='author', how='left')\n",
    "    credible_authors[f'h-index_{YEAR}'] = credible_authors[f'h-index_{YEAR}'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5: Early Coauthor max h-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"for each paper in EC, calculate the h-index of all its authors\n",
    "    This requires extra work\n",
    "    We want to calculate the h index of coauthors at the time of publishing the paper\n",
    "    for this we need an extra lookup table, where we store \n",
    "    all papers - authors - h-index at the time\n",
    "\n",
    "\n",
    "    final_citation_count_from_ids - we merge pub data with cit data, but \"inner\"\n",
    "    this means we will not find papers with 0 citations in this df\n",
    "    these papers dont impact the h-index, so this is okay\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def author_h_index(author, year_x):\n",
    "    combined_h = publications_citations_no_uncited[\n",
    "        (publications_citations_no_uncited.year_cit < year_x) &\n",
    "        (publications_citations_no_uncited.author == author)]\n",
    "    citations_count_list = combined_h.groupby(['pub_id']).agg({'id1': 'count'})['id1'].values\n",
    "    return h_index(citations_count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def author_h_index_in_year_X(authors, year_x):\n",
    "    #     print(year_x)\n",
    "    combined_h = publications_citations_no_uncited[\n",
    "        (publications_citations_no_uncited.year_cit < year_x) &\n",
    "        (publications_citations_no_uncited.author.isin(authors))]\n",
    "    combined_h = combined_h.groupby(['author', 'pub_id']).agg({'id1': 'count'}).reset_index()\n",
    "    author_hind_at_year = combined_h.groupby('author').agg({'id1': h_index}).reset_index()\n",
    "    author_hind_at_year['year_pub'] = year_x\n",
    "    author_hind_at_year = author_hind_at_year.rename({'id1': 'h-index'}, axis='columns')\n",
    "    return author_hind_at_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author and year pub of cited papers. a paper can be uncited, but have a strong coauthor.\n",
    "# BUG: change this df to publications_df equivalent\n",
    "papers_authors = publications_citations_no_uncited[['author', 'year_pub']].drop_duplicates(\n",
    "    subset=['author', 'year_pub'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# take the years when authors publish and calc h-index\n",
    "all_authors_hind = pd.DataFrame(columns=['author', 'h-index', 'year_pub'])\n",
    "all_authors_hind['year_pub'] = all_authors_hind['year_pub'].astype('int64')\n",
    "for year_x in papers_authors.year_pub.unique():\n",
    "    authors = papers_authors[papers_authors.year_pub == year_x].author.values\n",
    "    author_hind_at_year = author_h_index_in_year_X(authors, year_x)\n",
    "    all_authors_hind = all_authors_hind.append(author_hind_at_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_authors = papers_authors.merge(all_authors_hind, how='left')\n",
    "papers_authors['h-index'] = papers_authors['h-index'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "    combined_early_coauthor = publications_start_year[\n",
    "        (publications_start_year.year < publications_start_year.start_year + EARLY_CAREER)]\n",
    "\n",
    "    combined_early_coauthor = combined_early_coauthor.drop_duplicates(subset=['author', 'pub_id'])\n",
    "\n",
    "    combined_early_coauthor = combined_early_coauthor[['author', 'pub_id']]\n",
    "\n",
    "    # merging with combined_df not to remove coauthors that are not in their early career\n",
    "    combined_early_coauthor = combined_early_coauthor.merge(publications_start_year, on='pub_id')\n",
    "\n",
    "    combined_early_coauthor = combined_early_coauthor[\n",
    "        combined_early_coauthor.author_x != combined_early_coauthor.author_y]\n",
    "    combined_early_coauthor = combined_early_coauthor.drop_duplicates(subset=['author_x', 'author_y'])\n",
    "\n",
    "    # papers_authors contains h-index of authors in different publishing years\n",
    "    combined_early_coauthor = combined_early_coauthor.merge(papers_authors, left_on=['author_y', 'year'],\n",
    "                                                            right_on=['author', 'year_pub'])\n",
    "\n",
    "    combined_early_coauthor = combined_early_coauthor.groupby('author_x')['h-index'].max().reset_index()\n",
    "\n",
    "    combined_early_coauthor.rename(\n",
    "        {\"author_x\": \"author\", \"h-index\": f\"early_career_coauthor_max_hindex_{EARLY_CAREER}\"},\n",
    "        axis='columns', inplace=True)\n",
    "\n",
    "    combined_early_coauthor = combined_early_coauthor[['author', f\"early_career_coauthor_max_hindex_{EARLY_CAREER}\"]]\n",
    "\n",
    "    credible_authors = credible_authors.merge(combined_early_coauthor, on='author', how='left')\n",
    "    credible_authors[f\"early_career_coauthor_max_hindex_{EARLY_CAREER}\"] = credible_authors[\n",
    "        f\"early_career_coauthor_max_hindex_{EARLY_CAREER}\"].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6: Success increase- hindex, citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "    for SUCCESS_CUTOFF in SUCCESS_CUTOFF_LIST:\n",
    "        credible_authors[f'citation_increase_{SUCCESS_CUTOFF}_{EARLY_CAREER}'] = credible_authors[f'citation_count_{SUCCESS_CUTOFF}'] - credible_authors[f'citation_count_{EARLY_CAREER}']\n",
    "        credible_authors[f'h_index_increase_{SUCCESS_CUTOFF}_{EARLY_CAREER}'] = credible_authors[f'h-index_{SUCCESS_CUTOFF}'] - credible_authors[f'h-index_{EARLY_CAREER}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for EARLY_CAREER in EARLY_CAREER_LEN_LIST[:-1]:\n",
    "#     credible_authors[f'citation_increase_{EARLY_CAREER+2}_{EARLY_CAREER}'] = credible_authors[f'citation_count_{EARLY_CAREER+2}'] - credible_authors[f'citation_count_{EARLY_CAREER}']\n",
    "#     credible_authors[f'h_index_increase_{EARLY_CAREER+2}_{EARLY_CAREER}'] = credible_authors[f'h-index_{EARLY_CAREER+2}'] - credible_authors[f'h-index_{EARLY_CAREER}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EARLY_CAREER_LEN_LIST[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_authors.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publication based analysis - DF2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: Label authors that drop out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_append(lst, item):\n",
    "    lst.append(item)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_new_only(lst, item):\n",
    "    if item not in lst:\n",
    "        lst.append(item)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_consec(arr_diff):\n",
    "    if arr_diff.size == 0: return 1\n",
    "    last_ind = np.where(arr_diff > 1)[0]\n",
    "    if last_ind.size == 0: return 15\n",
    "    last_ind = last_ind[0]\n",
    "    return sum(arr_diff[:last_ind])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "def get_author_avg_max_absence(CAREER_LENGTH_DROPOUTS_LIST, credible_authors):\n",
    "    for start, end in CAREER_LENGTH_DROPOUTS_LIST:\n",
    "        pubs_grouped = publications_start_year[\n",
    "            (publications_start_year.year >= publications_start_year.start_year + start) &\n",
    "            (publications_start_year.year < publications_start_year.start_year + end)]\n",
    "        # for every 2 consecutive years the author has published find a difference (absence time)\n",
    "        # we artificially add one value: career start + career end (0+15), as a limiter of our observation window\n",
    "        # we add the limiter only if the author did not publish in this year\n",
    "        pubs_grouped = pubs_grouped.groupby('author').agg({'year': lambda x: sorted(list(x))})\n",
    "        pubs_grouped['year'] = pubs_grouped['year'].apply(lambda x: sorted(list_append(x, x[0] + end)))\n",
    "        # calculate consecutive differences - np.diff\n",
    "        pubs_grouped['absence_list'] = pubs_grouped['year'].apply(np.diff)\n",
    "        pubs_grouped[f'last_consec_ca_{start}_{end}'] = pubs_grouped['absence_list'].apply(get_last_consec)\n",
    "        pubs_grouped['absence_list'] = pubs_grouped['absence_list'].apply(lambda x: [e for e in x if e != 0 or e != 1])\n",
    "        pubs_grouped[f'max_absence_{start}_{end}'] = pubs_grouped['absence_list'].apply(max)\n",
    "        pubs_grouped[f'avg_absence_{start}_{end}'] = pubs_grouped['absence_list'].apply(np.mean)\n",
    "        # HACK: reduce max and avg by 1\n",
    "        # reason: 1990, 1993, 2015. author breaks: 2y and 11y. doing diff produces 3 and 12\n",
    "        pubs_grouped[f'max_absence_{start}_{end}'] = pubs_grouped[f'max_absence_{start}_{end}'] - 1\n",
    "        pubs_grouped[f'avg_absence_{start}_{end}'] = pubs_grouped[f'avg_absence_{start}_{end}'] - 1\n",
    "        pubs_grouped.reset_index(inplace=True)\n",
    "\n",
    "        credible_authors = credible_authors.merge(\n",
    "            pubs_grouped[['author', f'max_absence_{start}_{end}', f'avg_absence_{start}_{end}',\n",
    "                         f'last_consec_ca_{start}_{end}']], on='author', how='left')\n",
    "    return credible_authors\n",
    "\n",
    "def get_author_dropped_after(INACTIVE_TIME_DROPOUTS_LIST, credible_authors, start=0, end=15):\n",
    "    for INACTIVE_TIME_DROPOUTS in INACTIVE_TIME_DROPOUTS_LIST:\n",
    "        credible_authors[f'dropped_after_{INACTIVE_TIME_DROPOUTS}'] = credible_authors[f'max_absence_{start}_{end}'].apply(\n",
    "            lambda x: True if x >= INACTIVE_TIME_DROPOUTS else False)\n",
    "    return credible_authors\n",
    "\n",
    "credible_authors = get_author_avg_max_absence(CAREER_LENGTH_DROPOUTS_LIST, credible_authors)\n",
    "credible_authors = get_author_dropped_after(INACTIVE_TIME_DROPOUTS_LIST, credible_authors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Team size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "    publications_early = publications_start_year[(\n",
    "            publications_start_year.year < publications_start_year.start_year + EARLY_CAREER)]\n",
    "    paper_team_size = publications_early.groupby('pub_id').agg({'author': 'nunique'}).reset_index()\n",
    "    paper_team_size = paper_team_size.rename({'author': f'team_size_{EARLY_CAREER}'}, axis='columns')\n",
    "    publications_early = publications_early.merge(paper_team_size, on='pub_id', how='left')\n",
    "    team_size_median = publications_early.groupby('author').agg({f'team_size_{EARLY_CAREER}': 'median'}).reset_index()\n",
    "    team_size_median = team_size_median.rename({f'team_size_{EARLY_CAREER}': f'team_size_median_{EARLY_CAREER}'},\n",
    "                                               axis='columns')\n",
    "    team_size_mean = publications_early.groupby('author').agg({f'team_size_{EARLY_CAREER}': 'mean'}).reset_index()\n",
    "    team_size_mean = team_size_mean.rename({f'team_size_{EARLY_CAREER}': f'team_size_mean_{EARLY_CAREER}'},\n",
    "                                           axis='columns')\n",
    "\n",
    "    credible_authors = credible_authors.merge(team_size_median, on='author', how='left')\n",
    "    credible_authors = credible_authors.merge(team_size_mean, on='author', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: Early degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "    combined_early_degree = publications_start_year[\n",
    "        (publications_start_year.year < publications_start_year.start_year + EARLY_CAREER)]\n",
    "\n",
    "    combined_early_degree = combined_early_degree.drop_duplicates(subset=['author', 'pub_id'])\n",
    "\n",
    "    combined_early_degree = combined_early_degree[['author', 'pub_id']]\n",
    "\n",
    "    combined_early_degree = combined_early_degree.merge(publications_start_year, on='pub_id')\n",
    "\n",
    "    combined_early_degree = combined_early_degree[combined_early_degree.author_x != combined_early_degree.author_y]\n",
    "    combined_early_degree = combined_early_degree.drop_duplicates(subset=['author_x', 'author_y'])\n",
    "\n",
    "    combined_early_degree = combined_early_degree.groupby('author_x')['author_y'].count().reset_index()\n",
    "\n",
    "    combined_early_degree.rename({\"author_x\": \"author\", \"author_y\": f\"early_career_degree_{EARLY_CAREER}\"},\n",
    "                                 axis='columns', inplace=True)\n",
    "\n",
    "    credible_authors = credible_authors.merge(combined_early_degree, on='author', how='left')\n",
    "    credible_authors[f\"early_career_degree_{EARLY_CAREER}\"] = credible_authors[\n",
    "        f\"early_career_degree_{EARLY_CAREER}\"].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: Early productivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "    early_career_publications_reduced = publications_start_year[publications_start_year.year <\n",
    "                                                                publications_start_year.start_year + EARLY_CAREER]\n",
    "    early_career_publications_ = early_career_publications_reduced.groupby('author').agg(\n",
    "        {'pub_id': 'nunique'}).reset_index()\n",
    "    early_career_publications_ = early_career_publications_.rename({'pub_id': f'early_career_prod_{EARLY_CAREER}'},\n",
    "                                                                   axis='columns')\n",
    "    credible_authors = credible_authors.merge(early_career_publications_, on='author', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5: Venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO including the MAX and MIN values as missing. Check this. also what to do with ranking?\n",
    "early_career_venues = publications_start_year.merge(publication_venues_rank[[\n",
    "    'pub_id', 'h5_index', 'ranking', 'deciles', 'quantiles']], on='pub_id', how='inner')\n",
    "def quantile_binary(quant):\n",
    "    return quant <= 3\n",
    "\n",
    "\n",
    "for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "    #     EARLY_CAREER = 3\n",
    "    early_career_venues_ec = early_career_venues[\n",
    "        early_career_venues.year < early_career_venues.start_year + EARLY_CAREER]\n",
    "    early_career_venues_gr = early_career_venues_ec.groupby('author').agg({\n",
    "        'h5_index': 'max',\n",
    "        #     'ranking': 'min',\n",
    "        'deciles': 'min',\n",
    "        'quantiles': 'min'}).rename(columns={\n",
    "        'h5_index': f'h5_index_max_{EARLY_CAREER}',\n",
    "        #     'ranking': f'ranking_{EARLY_CAREER}',\n",
    "        'deciles': f'deciles_min_{EARLY_CAREER}',\n",
    "        'quantiles': f'quantiles_min_{EARLY_CAREER}'})\n",
    "    early_career_venues_gr = early_career_venues_gr.reset_index()\n",
    "    credible_authors = credible_authors.merge(early_career_venues_gr, on='author', how='left')\n",
    "\n",
    "    credible_authors[f'h5_index_max_{EARLY_CAREER}'] = credible_authors[f'h5_index_max_{EARLY_CAREER}'].fillna(0)\n",
    "    credible_authors[f'deciles_min_{EARLY_CAREER}'] = credible_authors[f'deciles_min_{EARLY_CAREER}'].fillna(10)\n",
    "    credible_authors[f'quantiles_min_{EARLY_CAREER}'] = credible_authors[f'quantiles_min_{EARLY_CAREER}'].fillna(4)\n",
    "\n",
    "    # CLAUDIA this should be TRUE if the author has AT LEAST one paper that exceeds the threshold\n",
    "    credible_authors[f'quantiles_bin_{EARLY_CAREER}'] = credible_authors[f'quantiles_min_{EARLY_CAREER}'].apply(\n",
    "        quantile_binary)\n",
    "\n",
    "    # credible_authors[f'ranking_{EARLY_CAREER}'] = credible_authors[f'ranking_{EARLY_CAREER}'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Number of early publications - first author (DF3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# number of first author publications\n",
    "for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "    publications_first_author_early = publications_first_author[\n",
    "        (publications_first_author.year < publications_first_author.start_year + EARLY_CAREER)]\n",
    "    publications_first_author_early = publications_first_author_early.groupby('author').agg(\n",
    "        {'pub_id': 'count'}).reset_index()\n",
    "    publications_first_author_early.rename({'pub_id': f'ec_first_auth_{EARLY_CAREER}'}, axis='columns', inplace=True)\n",
    "    credible_authors = credible_authors.merge(publications_first_author_early, on='author', how='left')\n",
    "    credible_authors[f'ec_first_auth_{EARLY_CAREER}'] = credible_authors[f'ec_first_auth_{EARLY_CAREER}'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counts Dataframe \n",
    "For every author, construct a 15 years time frame and count metrics for every career age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_years = get_start_years(START_YEAR, LAST_START_YEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create publication and citation dfs for first author\n",
    "author_year_numPub_first = publications_first_author.groupby(['author', 'year'])['pub_id'].count().reset_index()\n",
    "author_year_numPub_first = author_year_numPub_first.rename(columns={'pub_id': 'num_pub'})\n",
    "\n",
    "publications_citations_no_uncited_first = publications_citations_no_uncited.merge(\n",
    "    publications_first_author[['author', 'pub_id']], how='inner')\n",
    "citations_year_auth_first = publications_citations_no_uncited_first.groupby(['author', 'year_cit'])['id1'].count()\n",
    "\n",
    "citations_year_auth_first = citations_year_auth_first.reset_index()\n",
    "citations_year_auth_first = citations_year_auth_first.rename(columns={'id1': 'num_cit', 'year_cit': 'year'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(publications_citations_no_uncited_first.shape)\n",
    "print(publications_citations_no_uncited.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# create a dataframe with 15 career age entries for every author\n",
    "def create_counts_df(credible_authors, citations_year_auth_df, author_year_numPub_df):\n",
    "    counts0 = credible_authors[['author', 'start_year']].copy()\n",
    "    # filter out start years\n",
    "    counts0 = counts0[counts0['start_year'].isin(start_years)]\n",
    "    counts0['year'] = counts0['start_year'].apply(lambda x: [x + i for i in range(0, 15)])\n",
    "    counts = pd.DataFrame(counts0['year'].tolist(), index=counts0['author']).stack().reset_index(\n",
    "        level=1, drop=True).reset_index(name='year')[['year', 'author']]\n",
    "    counts = counts.merge(credible_authors[['author', 'start_year', 'end_year', 'gender']], on='author', how='inner')\n",
    "    counts['career_age'] = counts['year'] - counts['start_year'] + 1\n",
    "    counts['year'] = counts['year'].astype('int32')\n",
    "\n",
    "    counts['career_duration'] = counts['end_year'] - counts['start_year'] + 1\n",
    "    \n",
    "    counts = add_absolute_counts(counts, citations_year_auth_df, author_year_numPub_df)\n",
    "    \n",
    "    counts = add_cumulative_counts(counts, 'num_cit')\n",
    "    counts = add_cumulative_counts(counts, 'num_pub')\n",
    "    \n",
    "    return counts\n",
    "\n",
    "def add_absolute_counts(counts_df, citations_year_auth_df, author_year_numPub_df):\n",
    "    # merge in publications\n",
    "    counts_df = counts_df.merge(author_year_numPub_df, on=['author', 'year'], how='left')\n",
    "    counts_df['num_pub'] = counts_df['num_pub'].fillna(0)\n",
    "    # merge in citations\n",
    "    counts_df = counts_df.merge(citations_year_auth_df, on=['author', 'year'], how='left')\n",
    "    counts_df['num_cit'] = counts_df['num_cit'].fillna(0)\n",
    "    return counts_df\n",
    "\n",
    "def add_cumulative_counts(counts_df, feature):\n",
    "    counts_df = calculate.calculate_cumulative_for_authors(counts_df, feature)\n",
    "    return counts_df\n",
    "\n",
    "# add citation and publication window features to citations df\n",
    "def add_citation_window_counts(counts_df, combined_df, WINDOW_SIZE):\n",
    "    \"\"\"\n",
    "    Adds 2 columns to the counts dataframe: win_num_cit, win_num_pub\n",
    "    win_num_pub: count publications for career ages, with forward looking windows of size WINDOW_SIZE\n",
    "    \n",
    "    win_num_cit: for a publication window defined by win_num_pub, count citations in a sliding window\n",
    "    that starts at publication year and extends to pub_year+WINDOW_SIZE, non inclusive\n",
    "    \"\"\"\n",
    "    shift = -(WINDOW_SIZE - 1)\n",
    "    # citations window\n",
    "    df_list = []\n",
    "    for year in start_years:\n",
    "        df_year = combined_df[combined_df.start_year == year]\n",
    "        for y in range(year, year + 13):  # y is the first year we count for\n",
    "            df_window = df_year[(df_year.year_pub >= y) & (df_year.year_pub < y + WINDOW_SIZE) &\n",
    "                                (df_year.year_cit >= y) & \n",
    "                                (df_year.year_cit < df_year.year_pub + WINDOW_SIZE)]\n",
    "            df_window = df_window.groupby('author').agg({'id1': 'count'}).reset_index()\n",
    "            df_window['year'] = y\n",
    "            df_window = df_window.rename({'id1': 'win_num_cit'}, axis=1)\n",
    "            df_list.append(df_window)\n",
    "    df_cit_window = pd.concat(df_list).sort_values(by=['author', 'year'])\n",
    "    counts_df = counts_df.merge(df_cit_window, on=['author', 'year'], how='left')\n",
    "    counts_df['win_num_cit'] = counts_df['win_num_cit'].fillna(0)\n",
    "    \n",
    "    counts_df['win_num_pub'] = counts_df.groupby('author')['num_pub'].transform(\n",
    "        lambda x: x.rolling(WINDOW_SIZE, min_periods=WINDOW_SIZE).sum().shift(shift))\n",
    "    \n",
    "    return counts_df\n",
    "\n",
    "\n",
    "def save_counts(counts_df, WINDOW_SIZE, ext=''):\n",
    "    counts_df.to_csv(f'derived-data/citations_window_{WINDOW_SIZE}{ext}.csv', index=None)\n",
    "\n",
    "\n",
    "def make_counts_file(base_df, publications_citations_no_uncited, WINDOW_SIZE, file_ext=''):\n",
    "    counts_df = base_df.copy(deep=True)\n",
    "    counts_df = add_citation_window_counts(base_df, publications_citations_no_uncited, WINDOW_SIZE)\n",
    "\n",
    "    save_counts(counts_df, WINDOW_SIZE, file_ext)\n",
    "    return counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "base_df = create_counts_df(credible_authors, author_yearly_citations, author_yearly_publications)\n",
    "base_df_first = create_counts_df(credible_authors, citations_year_auth_first, author_year_numPub_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# all authors\n",
    "WINDOW_SIZE = 3\n",
    "counts_df = make_counts_file(base_df, publications_citations_no_uncited, WINDOW_SIZE)\n",
    "# first author\n",
    "counts_df_first = make_counts_file(base_df_first, publications_citations_no_uncited_first, WINDOW_SIZE, file_ext='_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "WINDOW_SIZE = 5\n",
    "# all authors\n",
    "counts_df_5 = make_counts_file(base_df, publications_citations_no_uncited, WINDOW_SIZE)\n",
    "# first author\n",
    "counts_df_first_5 = make_counts_file(base_df_first, publications_citations_no_uncited_first, WINDOW_SIZE, file_ext='_first')\n",
    "#TODO write tests for counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Deprecated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Early, mid and late papers analysis - citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# TODO Delete\n",
    "# def add_fine_grained_citation_counts(counts):\n",
    "#     # publish_years = [[0,3], [3,6], [6,9], [0,1], [3,4], [6,7]]\n",
    "#     publish_years = [[i, i + 1] for i in range(0, 15)]\n",
    "#     for start, end in publish_years:\n",
    "#         first_3 = publications_citations_no_uncited[\n",
    "#             (publications_citations_no_uncited.year_pub >= publications_citations_no_uncited.start_year + start) &\n",
    "#             (publications_citations_no_uncited.year_pub < publications_citations_no_uncited.start_year + end)]\n",
    "#         first_3 = first_3.groupby(['author', 'year_cit']).agg({'id1': 'count'}).reset_index()\n",
    "#         first_3 = first_3.rename({'year_cit': 'year', 'id1': f'ec_cit_{start}_{end}'}, axis=1)\n",
    "#         counts = counts.merge(first_3, on=['author', 'year'], how='left')\n",
    "#         counts[f'ec_cit_{start}_{end}'] = counts[f'ec_cit_{start}_{end}'].fillna(0)\n",
    "#     for start, end in publish_years:\n",
    "#         counts[f'ec_cit_{start}_{end}_cum'] = counts.sort_values(['author', 'career_age']).groupby('author')[\n",
    "#             f'ec_cit_{start}_{end}'].transform(pd.Series.cumsum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Early Coauthor max citations - deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "#     combined_early_coauthor = combined_df[(combined_df.year_pub < combined_df.start_year + EARLY_CAREER)]\n",
    "\n",
    "#     combined_early_coauthor = combined_early_coauthor.drop_duplicates(subset=['author', 'pub_id'])\n",
    "\n",
    "#     combined_early_coauthor = combined_early_coauthor[['author', 'pub_id']]\n",
    "\n",
    "#     combined_early_coauthor = combined_early_coauthor.merge(combined_df, on='pub_id')\n",
    "\n",
    "#     combined_early_coauthor = combined_early_coauthor[combined_early_coauthor.author_x != combined_early_coauthor.author_y]\n",
    "#     combined_early_coauthor = combined_early_coauthor.drop_duplicates(subset=['author_x', 'author_y'])\n",
    "\n",
    "#     combined_early_coauthor = combined_early_coauthor.merge(credible_authors[['author', 'succ_after_15y']], left_on='author_y', right_on='author')\n",
    "#     combined_early_coauthor = combined_early_coauthor.groupby('author_x')['succ_after_15y'].max().reset_index()\n",
    "\n",
    "#     combined_early_coauthor.rename({\"author_x\":\"author\", \"succ_after_15y\": f\"early_career_coauthor_max_cit_{EARLY_CAREER}\"}, \n",
    "#                                  axis='columns', inplace=True)\n",
    "\n",
    "#     combined_early_coauthor = combined_early_coauthor[['author', f\"early_career_coauthor_max_cit_{EARLY_CAREER}\"]]\n",
    "\n",
    "#     credible_authors = credible_authors.merge(combined_early_coauthor, on='author', how='left')\n",
    "#     credible_authors[f\"early_career_coauthor_max_cit_{EARLY_CAREER}\"] = credible_authors[f\"early_career_coauthor_max_cit_{EARLY_CAREER}\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# drop\n",
    "def drop_list_cols(drop_list):\n",
    "    credible_authors.drop(drop_list, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def drop_col(df, cols):\n",
    "    df.drop(cols, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_authors[credible_authors.start_year >= START_YEAR].to_csv('derived-data/authors-scientific-extended_all2.csv',\n",
    "                                                                   index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author', 'start_year', 'end_year', 'total_num_pub', 'career_length',\n",
       "       'career_length_15', 'gender', 'early_career_qual_3',\n",
       "       'early_career_qual_first_3', 'early_career_qual_6',\n",
       "       'early_career_qual_first_6', 'early_career_qual_9',\n",
       "       'early_career_qual_first_9', 'early_career_qual_12',\n",
       "       'early_career_qual_first_12', 'early_career_recognition_EC3_RC3',\n",
       "       'early_career_recognition_EC6_RC6', 'early_career_recognition_EC9_RC9',\n",
       "       'early_career_recognition_EC12_RC12', 'citation_count_3',\n",
       "       'citation_count_6', 'citation_count_9', 'citation_count_12',\n",
       "       'citation_count_15', 'h-index_3', 'h-index_6', 'h-index_9',\n",
       "       'h-index_12', 'h-index_15', 'early_career_coauthor_max_hindex_3',\n",
       "       'early_career_coauthor_max_hindex_6',\n",
       "       'early_career_coauthor_max_hindex_9',\n",
       "       'early_career_coauthor_max_hindex_12', 'citation_increase_15_3',\n",
       "       'h_index_increase_15_3', 'citation_increase_15_6',\n",
       "       'h_index_increase_15_6', 'citation_increase_15_9',\n",
       "       'h_index_increase_15_9', 'citation_increase_15_12',\n",
       "       'h_index_increase_15_12', 'max_absence_0_15', 'avg_absence_0_15',\n",
       "       'last_consec_ca_0_15', 'dropped_after_5', 'dropped_after_10',\n",
       "       'team_size_median_3', 'team_size_mean_3', 'team_size_median_6',\n",
       "       'team_size_mean_6', 'team_size_median_9', 'team_size_mean_9',\n",
       "       'team_size_median_12', 'team_size_mean_12', 'early_career_degree_3',\n",
       "       'early_career_degree_6', 'early_career_degree_9',\n",
       "       'early_career_degree_12', 'early_career_prod_3', 'early_career_prod_6',\n",
       "       'early_career_prod_9', 'early_career_prod_12', 'h5_index_max_3',\n",
       "       'deciles_min_3', 'quantiles_min_3', 'quantiles_bin_3', 'h5_index_max_6',\n",
       "       'deciles_min_6', 'quantiles_min_6', 'quantiles_bin_6', 'h5_index_max_9',\n",
       "       'deciles_min_9', 'quantiles_min_9', 'quantiles_bin_9',\n",
       "       'h5_index_max_12', 'deciles_min_12', 'quantiles_min_12',\n",
       "       'quantiles_bin_12', 'ec_first_auth_3', 'ec_first_auth_6',\n",
       "       'ec_first_auth_9', 'ec_first_auth_12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credible_authors.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_authors[credible_authors.start_year >= START_YEAR].shape"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_json": true,
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
