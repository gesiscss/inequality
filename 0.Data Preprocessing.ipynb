{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import calculate\n",
    "from calculate import gini, h_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify how long is the early career. Impacts which papers we take into account for early productivity and quality\n",
    "EARLY_CAREER_LEN = 3\n",
    "# EARLY_CAREER_LEN_LIST = [3, 5, 7, 9, 11, 12]\n",
    "EARLY_CAREER_LEN_LIST = [3]\n",
    "# For early career work, when do we stop counting citations. Impacts recognition\n",
    "# RECOGNITION_CUT_OFF_LIST = [3, 5, 7, 9, 11, 12]\n",
    "RECOGNITION_CUT_OFF_LIST = [3]\n",
    "# Success after 15 years. Impacts when we stop counting citations\n",
    "SUCCESS_CUTOFF = 15\n",
    "SUCCESS_CUTOFF_LIST = [10, 15]\n",
    "# Length of observed career for dropouts\n",
    "# (1-3), middle career (4-9), late career (10-15)\n",
    "\n",
    "CAREER_LENGTH_DROPOUTS_LIST = [(0, 15)]\n",
    "# CAREER_LENGTH_DROPOUTS = 15\n",
    "INACTIVE_TIME_DROPOUTS = 10\n",
    "INACTIVE_TIME_DROPOUTS_LIST = [5,10]\n",
    "\n",
    "# Specify the first and last year we consider in our analysis\n",
    "START_YEAR = 1970\n",
    "LAST_START_YEAR = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_years(START_YEAR, LAST_START_YEAR):\n",
    "    all_years = credible_authors.start_year.unique()\n",
    "    start_years = [year for year in all_years if START_YEAR <= year <= LAST_START_YEAR]\n",
    "    start_years = sorted(start_years)\n",
    "    return start_years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cheat load\n",
    "# credible_authors = pd.read_csv('derived-data/authors-scientific-extended.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv raw data\n",
    "# publications\n",
    "authorPublicationData = pd.read_csv('./data/author_publications_2017_asiansAsNone.txt')\n",
    "# citations\n",
    "authorCitationsData = pd.read_csv('./data/citations_2017_asiansAsNone.txt')\n",
    "# arxiv\n",
    "arxiv_pubid = pd.read_csv('derived-data/arxiv_pubid_2017.csv', header=None, names=['pub_id'])\n",
    "# venue data\n",
    "publication_venues_rank = pd.read_csv('derived-data/publication-venues-rank.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9471668, 3)\n",
      "(9467149, 3)\n",
      "(9317809, 3)\n",
      "(8938798, 3)\n",
      "(8938798, 3)\n",
      "(8846838, 3)\n"
     ]
    }
   ],
   "source": [
    "# remove duplicates and remove arxiv\n",
    "print(authorPublicationData.shape)\n",
    "authorPublicationData.drop_duplicates(subset=['author', 'pub_id'], inplace=True)\n",
    "print(authorPublicationData.shape)\n",
    "authorPublicationData = authorPublicationData.loc[~authorPublicationData.pub_id.isin(arxiv_pubid['pub_id'])]\n",
    "print(authorPublicationData.shape)\n",
    "\n",
    "print(authorCitationsData.shape)\n",
    "authorCitationsData.drop_duplicates(inplace=True)\n",
    "print(authorCitationsData.shape)\n",
    "authorCitationsData = authorCitationsData.loc[(~authorCitationsData.id1.isin(arxiv_pubid['pub_id']))]\n",
    "authorCitationsData = authorCitationsData.loc[(~authorCitationsData.id2.isin(arxiv_pubid['pub_id']))]\n",
    "print(authorCitationsData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authors#      -  1694302\n",
      "Years#        -  83\n",
      "Publications# -  3029829\n"
     ]
    }
   ],
   "source": [
    "print('Authors#      - ', authorPublicationData['author'].nunique())\n",
    "print('Years#        - ', authorPublicationData['year'].nunique())\n",
    "print('Publications# - ', authorPublicationData['pub_id'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Career length and gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows -                 (1694302, 4)\n",
      "After removing duplicates -  (1694302, 4)\n",
      "After droping na -           (1694302, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>start_year</th>\n",
       "      <th>end_year</th>\n",
       "      <th>total_num_pub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>'maseka lesaoana</td>\n",
       "      <td>2001</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(max) zong-ming cheng</td>\n",
       "      <td>2009</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(zhou) bryan bai</td>\n",
       "      <td>2011</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>a aart blokhuis</td>\n",
       "      <td>1992</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>a ahrabian</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  author  start_year  end_year  total_num_pub\n",
       "0       'maseka lesaoana        2001      2015              2\n",
       "1  (max) zong-ming cheng        2009      2011              2\n",
       "2       (zhou) bryan bai        2011      2012              2\n",
       "3        a aart blokhuis        1992      2005              2\n",
       "4             a ahrabian        2017      2017              1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupByAuthor = authorPublicationData.groupby(['author'])\n",
    "\n",
    "groupByAuthorMinYearData = groupByAuthor['year'].min()\n",
    "groupByAuthorMaxYearData = groupByAuthor['year'].max()\n",
    "groupByAuthorCountPublicationsData = groupByAuthor['pub_id'].count()\n",
    "\n",
    "authorGroupedData = groupByAuthorMinYearData.to_frame(name='start_year')\n",
    "authorGroupedData['end_year'] = groupByAuthorMaxYearData\n",
    "authorGroupedData['total_num_pub'] = groupByAuthorCountPublicationsData\n",
    "authorGroupedData = authorGroupedData.reset_index()\n",
    "print('Total rows -                ', authorGroupedData.shape)\n",
    "\n",
    "authorGroupedData = authorGroupedData.drop_duplicates()\n",
    "print('After removing duplicates - ', authorGroupedData.shape)\n",
    "\n",
    "authorGroupedData = authorGroupedData.dropna(how='any')\n",
    "print(\"After droping na -          \", authorGroupedData.shape)\n",
    "\n",
    "authorGroupedData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 1 here to have career length be at least one. So 3 years career means year1, year2, year3.\n",
    "authorGroupedData[\"career_length\"] = authorGroupedData['end_year'] - authorGroupedData['start_year'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_authors = authorGroupedData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m       791347\n",
      "none    648819\n",
      "f       254136\n",
      "Name: gender, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>gareth beale</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>graeme earl</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>altaf hossain</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>faisal zaman</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>m. nasser</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name gender\n",
       "0   gareth beale      m\n",
       "1    graeme earl      m\n",
       "2  altaf hossain      m\n",
       "3   faisal zaman      m\n",
       "4      m. nasser   none"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender = pd.read_csv('./data/name_gender_2017_asiansAsNone_nodup.txt')\n",
    "credible_authors = credible_authors.merge(gender, left_on='author', right_on='name', how='left')\n",
    "credible_authors.drop('name', axis=1, inplace=True)\n",
    "\n",
    "print(credible_authors.gender.value_counts())\n",
    "gender.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save filtered data about authors, and cleaned publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_cred_authors(START_YEAR, LAST_START_YEAR):\n",
    "    return credible_authors[\n",
    "        (credible_authors.start_year >= START_YEAR) & (credible_authors.start_year <= LAST_START_YEAR)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>start_year</th>\n",
       "      <th>end_year</th>\n",
       "      <th>total_num_pub</th>\n",
       "      <th>career_length</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>'maseka lesaoana</td>\n",
       "      <td>2001</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(max) zong-ming cheng</td>\n",
       "      <td>2009</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(zhou) bryan bai</td>\n",
       "      <td>2011</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>a aart blokhuis</td>\n",
       "      <td>1992</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>a ahrabian</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  author  start_year  end_year  total_num_pub  career_length  \\\n",
       "0       'maseka lesaoana        2001      2015              2             15   \n",
       "1  (max) zong-ming cheng        2009      2011              2              3   \n",
       "2       (zhou) bryan bai        2011      2012              2              2   \n",
       "3        a aart blokhuis        1992      2005              2             14   \n",
       "4             a ahrabian        2017      2017              1              1   \n",
       "\n",
       "  gender  \n",
       "0   none  \n",
       "1   none  \n",
       "2   none  \n",
       "3   none  \n",
       "4   none  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_cred_authors(START_YEAR, LAST_START_YEAR).to_csv('derived-data/authors-scientific.csv', index=False,\n",
    "                                                        encoding='utf-8')\n",
    "credible_authors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "authorPublicationData.to_csv('derived-data/author-publications.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9317809, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authorPublicationData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare DFs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DF1 - Publications and Citations, no uncited papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every author and paper => every citation to the paper\n",
    "# Doesnt contain uncited papers\n",
    "# Contains multiple authors per paper\n",
    "# This is good for per author analysis\n",
    "# This is bad for per paper analysis\n",
    "publications_citations_no_uncited = authorPublicationData.merge(authorCitationsData, left_on='pub_id',\n",
    "                                                                right_on='id2', how='inner', suffixes=('_pub', '_cit'))\n",
    "publications_citations_no_uncited = publications_citations_no_uncited.merge(credible_authors[['author', 'start_year']],\n",
    "                                                                            on='author', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove cited before published\n",
    "publications_citations_no_uncited = publications_citations_no_uncited[\n",
    "    publications_citations_no_uncited.year_pub <= publications_citations_no_uncited.year_cit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate authors\n",
    "# no uncited papers\n",
    "paper_paper_citations = publications_citations_no_uncited[['id1', 'id2', 'year_pub', 'year_cit']]\n",
    "paper_paper_citations = paper_paper_citations.drop_duplicates(subset=['id1', 'id2'])\n",
    "paper_total_citations = paper_paper_citations.groupby('id2')['id1'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DF2 - Publications with uncited papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contains uncited papers\n",
    "# Good for early career publication related analysis\n",
    "publications_start_year = authorPublicationData.merge(credible_authors[['author', 'start_year']], on='author',\n",
    "                                                      how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DF3 - Author order in publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "publications_first_author = pd.read_csv('derived-data/publication_authors_order_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "publications_first_author = publications_first_author.merge(credible_authors[['author', 'start_year']],\n",
    "                                                            left_on='first_author',\n",
    "                                                            right_on='author', how='left')\n",
    "publications_first_author = publications_first_author.drop('first_author', axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author yearly citations and publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of citations an author receives per year\n",
    "author_yearly_citations = publications_citations_no_uncited.groupby(['author', 'year_cit'])['id1'].count()\n",
    "author_yearly_citations = author_yearly_citations.reset_index()\n",
    "author_yearly_citations = author_yearly_citations.rename(columns={'id1': 'num_cit', 'year_cit': 'year'})\n",
    "author_yearly_citations[['author', 'year', 'num_cit']].to_csv('derived-data/authors-perYear-citations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_yearly_publications = authorPublicationData.groupby(['author', 'year'])['pub_id'].count().reset_index()\n",
    "author_yearly_publications = author_yearly_publications.rename(columns={'pub_id': 'num_pub'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publication and citation based analysis - DF1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: Early quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "    combined_early_quality = publications_citations_no_uncited[\n",
    "        (publications_citations_no_uncited.year_pub < publications_citations_no_uncited.start_year + EARLY_CAREER) &\n",
    "        (publications_citations_no_uncited.year_cit < publications_citations_no_uncited.start_year + SUCCESS_CUTOFF)]\n",
    "\n",
    "    author_order_early = publications_first_author[\n",
    "        (publications_first_author.year < publications_first_author.start_year + EARLY_CAREER)]\n",
    "    early_career_quality_first = combined_early_quality.loc[\n",
    "        combined_early_quality['pub_id'].isin(author_order_early['pub_id'])]\n",
    "\n",
    "    early_career_quality = combined_early_quality.groupby('author')['id1'].count()\n",
    "    early_career_quality_first = early_career_quality_first.groupby('author')['id1'].count()\n",
    "\n",
    "    early_career_quality = early_career_quality.rename(f'early_career_qual_{EARLY_CAREER}').reset_index()\n",
    "    early_career_quality_first = early_career_quality_first.rename(\n",
    "        f'early_career_qual_first_{EARLY_CAREER}').reset_index()\n",
    "\n",
    "    credible_authors = credible_authors.merge(early_career_quality, on='author', how='left')\n",
    "    credible_authors = credible_authors.merge(early_career_quality_first, on='author', how='left')\n",
    "\n",
    "    credible_authors[f'early_career_qual_{EARLY_CAREER}'] = credible_authors[\n",
    "        f'early_career_qual_{EARLY_CAREER}'].fillna(0)\n",
    "    credible_authors[f'early_career_qual_first_{EARLY_CAREER}'] = credible_authors[\n",
    "        f'early_career_qual_first_{EARLY_CAREER}'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Early recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "    for RECOGNITION_CUT in RECOGNITION_CUT_OFF_LIST:\n",
    "        if RECOGNITION_CUT != EARLY_CAREER: continue\n",
    "        early_career_recognition = publications_citations_no_uncited[\n",
    "            (publications_citations_no_uncited.year_pub < publications_citations_no_uncited.start_year + EARLY_CAREER) &\n",
    "            (publications_citations_no_uncited.year_cit < publications_citations_no_uncited.start_year + RECOGNITION_CUT)]\n",
    "        early_career_recognition = early_career_recognition.groupby('author')['id1'].count()\n",
    "        col_name = f'early_career_recognition_EC{EARLY_CAREER}_RC{RECOGNITION_CUT}'\n",
    "        early_career_recognition = early_career_recognition.rename(col_name)\n",
    "        early_career_recognition = early_career_recognition.reset_index()\n",
    "        credible_authors = credible_authors.merge(early_career_recognition, on='author', how='left')\n",
    "        credible_authors[col_name] = credible_authors[col_name].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: Citation count after X years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for SUCCESS_CUTOFF in [*EARLY_CAREER_LEN_LIST, *SUCCESS_CUTOFF_LIST]:\n",
    "    publications_citations_before_cutoff = publications_citations_no_uncited[\n",
    "        publications_citations_no_uncited.year_cit < publications_citations_no_uncited.start_year + SUCCESS_CUTOFF]\n",
    "    citations_per_author = publications_citations_before_cutoff.groupby('author')['id1'].count()\n",
    "\n",
    "    citations_per_author = citations_per_author.rename(f'citation_count_{SUCCESS_CUTOFF}')\n",
    "    citations_per_author = citations_per_author.reset_index()\n",
    "    credible_authors = credible_authors.merge(citations_per_author, on='author', how='left')\n",
    "    credible_authors[f'citation_count_{SUCCESS_CUTOFF}'] = credible_authors[f'citation_count_{SUCCESS_CUTOFF}'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: H index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for YEAR in [*EARLY_CAREER_LEN_LIST, *SUCCESS_CUTOFF_LIST]:\n",
    "    combined_h_index = publications_citations_no_uncited[\n",
    "        publications_citations_no_uncited.year_cit < publications_citations_no_uncited.start_year + YEAR]\n",
    "\n",
    "    combined_h_index = combined_h_index.groupby(['author', 'pub_id'])['id1'].count()\n",
    "    combined_h_index = combined_h_index.reset_index()\n",
    "    combined_h_index = combined_h_index.groupby('author')['id1'].apply(lambda x: h_index(x.values))\n",
    "    combined_h_index = combined_h_index.rename(f'h-index_{YEAR}')\n",
    "\n",
    "    credible_authors = credible_authors.merge(combined_h_index.reset_index(), on='author', how='left')\n",
    "    credible_authors[f'h-index_{YEAR}'] = credible_authors[f'h-index_{YEAR}'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5: Early Coauthor max h-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for each paper in EC, calculate the h-index of all its authors\\n    This requires extra work\\n    We want to calculate the h index of coauthors at the time of publishing the paper\\n    for this we need an extra lookup table, where we store \\n    all papers - authors - h-index at the time\\n\\n\\n    final_citation_count_from_ids - we merge pub data with cit data, but \"inner\"\\n    this means we will not find papers with 0 citations in this df\\n    these papers dont impact the h-index, so this is okay\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for each paper in EC, calculate the h-index of all its authors\n",
    "    This requires extra work\n",
    "    We want to calculate the h index of coauthors at the time of publishing the paper\n",
    "    for this we need an extra lookup table, where we store \n",
    "    all papers - authors - h-index at the time\n",
    "\n",
    "\n",
    "    final_citation_count_from_ids - we merge pub data with cit data, but \"inner\"\n",
    "    this means we will not find papers with 0 citations in this df\n",
    "    these papers dont impact the h-index, so this is okay\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def author_h_index_in_year_X(authors, year_x):\n",
    "    #     print(year_x)\n",
    "    combined_h = publications_citations_no_uncited[\n",
    "        (publications_citations_no_uncited.year_cit < year_x) &\n",
    "        (publications_citations_no_uncited.author.isin(authors))]\n",
    "    combined_h = combined_h.groupby(['author', 'pub_id']).agg({'id1': 'count'}).reset_index()\n",
    "    author_hind_at_year = combined_h.groupby('author').agg({'id1': h_index}).reset_index()\n",
    "    author_hind_at_year['year_pub'] = year_x\n",
    "    author_hind_at_year = author_hind_at_year.rename({'id1': 'h-index'}, axis='columns')\n",
    "    return author_hind_at_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def author_h_index(author, year_x):\n",
    "    combined_h = publications_citations_no_uncited[\n",
    "        (publications_citations_no_uncited.year_cit < year_x) &\n",
    "        (publications_citations_no_uncited.author == author)]\n",
    "    citations_count_list = combined_h.groupby(['pub_id']).agg({'id1': 'count'})['id1'].values\n",
    "    return h_index(citations_count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "papers_authors = publications_citations_no_uncited[['author', 'year_pub']].drop_duplicates(\n",
    "    subset=['author', 'year_pub'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "all_authors_hind = pd.DataFrame(columns=['author', 'h-index', 'year_pub'])\n",
    "all_authors_hind['year_pub'] = all_authors_hind['year_pub'].astype('int64')\n",
    "for year_x in papers_authors.year_pub.unique():\n",
    "    authors = papers_authors[papers_authors.year_pub == year_x].author.values\n",
    "    author_hind_at_year = author_h_index_in_year_X(authors, year_x)\n",
    "    all_authors_hind = all_authors_hind.append(author_hind_at_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_authors = papers_authors.merge(all_authors_hind, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_authors['h-index'] = papers_authors['h-index'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "    combined_early_coauthor = publications_start_year[\n",
    "        (publications_start_year.year < publications_start_year.start_year + EARLY_CAREER)]\n",
    "\n",
    "    combined_early_coauthor = combined_early_coauthor.drop_duplicates(subset=['author', 'pub_id'])\n",
    "\n",
    "    combined_early_coauthor = combined_early_coauthor[['author', 'pub_id']]\n",
    "\n",
    "    # merging with combined_df not to remove coauthors that are not in their early career\n",
    "    combined_early_coauthor = combined_early_coauthor.merge(publications_start_year, on='pub_id')\n",
    "\n",
    "    combined_early_coauthor = combined_early_coauthor[\n",
    "        combined_early_coauthor.author_x != combined_early_coauthor.author_y]\n",
    "    combined_early_coauthor = combined_early_coauthor.drop_duplicates(subset=['author_x', 'author_y'])\n",
    "\n",
    "    # papers_authors contains h-index of authors in different publishing years\n",
    "    combined_early_coauthor = combined_early_coauthor.merge(papers_authors, left_on=['author_y', 'year'],\n",
    "                                                            right_on=['author', 'year_pub'])\n",
    "\n",
    "    combined_early_coauthor = combined_early_coauthor.groupby('author_x')['h-index'].max().reset_index()\n",
    "\n",
    "    combined_early_coauthor.rename(\n",
    "        {\"author_x\": \"author\", \"h-index\": f\"early_career_coauthor_max_hindex_{EARLY_CAREER}\"},\n",
    "        axis='columns', inplace=True)\n",
    "\n",
    "    combined_early_coauthor = combined_early_coauthor[['author', f\"early_career_coauthor_max_hindex_{EARLY_CAREER}\"]]\n",
    "\n",
    "    credible_authors = credible_authors.merge(combined_early_coauthor, on='author', how='left')\n",
    "    credible_authors[f\"early_career_coauthor_max_hindex_{EARLY_CAREER}\"] = credible_authors[\n",
    "        f\"early_career_coauthor_max_hindex_{EARLY_CAREER}\"].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6: Success increase- hindex, citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "    for SUCCESS_CUTOFF in SUCCESS_CUTOFF_LIST:\n",
    "        credible_authors[f'citation_increase_{SUCCESS_CUTOFF}_{EARLY_CAREER}'] = credible_authors[f'citation_count_{SUCCESS_CUTOFF}'] - credible_authors[f'citation_count_{EARLY_CAREER}']\n",
    "        credible_authors[f'h_index_increase_{SUCCESS_CUTOFF}_{EARLY_CAREER}'] = credible_authors[f'h-index_{SUCCESS_CUTOFF}'] - credible_authors[f'h-index_{EARLY_CAREER}']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publication based analysis - DF2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: Label authors that drop out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_append(lst, item):\n",
    "    lst.append(item)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_new_only(lst, item):\n",
    "    if item not in lst:\n",
    "        lst.append(item)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_author_avg_max_absence(CAREER_LENGTH_DROPOUTS_LIST, INACTIVE_TIME_DROPOUTS, credible_authors):\n",
    "    for start, end in CAREER_LENGTH_DROPOUTS_LIST:\n",
    "        pubs_grouped = publications_start_year[\n",
    "            (publications_start_year.year >= publications_start_year.start_year + start) &\n",
    "            (publications_start_year.year <= publications_start_year.start_year + end)]\n",
    "        # for every 2 consecutive years the author has published find a difference (absence time)\n",
    "        # we artificially add one value: career start + 15, as a limiter of our observation window\n",
    "        # we add the limiter only if the author did not publish in this year\n",
    "        pubs_grouped = pubs_grouped.groupby('author').agg({'year': lambda x: sorted(list(x))})\n",
    "        pubs_grouped['year'] = pubs_grouped['year'].apply(lambda x: sorted(append_new_only(x, x[0] + 15)))\n",
    "        pubs_grouped['absence_list'] = pubs_grouped['year'].apply(np.diff)\n",
    "        pubs_grouped[f'max_absence_{start}_{end}'] = pubs_grouped['absence_list'].apply(max)\n",
    "        pubs_grouped[f'avg_absence_{start}_{end}'] = pubs_grouped['absence_list'].apply(np.mean)\n",
    "        pubs_grouped.reset_index(inplace=True)\n",
    "\n",
    "        credible_authors = credible_authors.merge(pubs_grouped[\n",
    "                                                      ['author', f'max_absence_{start}_{end}',\n",
    "                                                       f'avg_absence_{start}_{end}']], on='author', how='left')\n",
    "        credible_authors[f'dropped_after_{INACTIVE_TIME_DROPOUTS}'] = credible_authors[\n",
    "            f'max_absence_{start}_{end}'].apply(lambda x: False if x < INACTIVE_TIME_DROPOUTS else True)\n",
    "\n",
    "get_author_avg_max_absence(CAREER_LENGTH_DROPOUTS_LIST, INACTIVE_TIME_DROPOUTS, credible_authors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Team size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "    publications_early = publications_start_year[(\n",
    "            publications_start_year.year < publications_start_year.start_year + EARLY_CAREER)]\n",
    "    paper_team_size = publications_early.groupby('pub_id').agg({'author': 'nunique'}).reset_index()\n",
    "    paper_team_size = paper_team_size.rename({'author': f'team_size_{EARLY_CAREER}'}, axis='columns')\n",
    "    publications_early = publications_early.merge(paper_team_size, on='pub_id', how='left')\n",
    "    team_size_median = publications_early.groupby('author').agg({f'team_size_{EARLY_CAREER}': 'median'}).reset_index()\n",
    "    team_size_median = team_size_median.rename({f'team_size_{EARLY_CAREER}': f'team_size_median_{EARLY_CAREER}'},\n",
    "                                               axis='columns')\n",
    "    team_size_mean = publications_early.groupby('author').agg({f'team_size_{EARLY_CAREER}': 'mean'}).reset_index()\n",
    "    team_size_mean = team_size_mean.rename({f'team_size_{EARLY_CAREER}': f'team_size_mean_{EARLY_CAREER}'},\n",
    "                                           axis='columns')\n",
    "\n",
    "    credible_authors = credible_authors.merge(team_size_median, on='author', how='left')\n",
    "    credible_authors = credible_authors.merge(team_size_mean, on='author', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: Early degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "    combined_early_degree = publications_start_year[\n",
    "        (publications_start_year.year < publications_start_year.start_year + EARLY_CAREER)]\n",
    "\n",
    "    combined_early_degree = combined_early_degree.drop_duplicates(subset=['author', 'pub_id'])\n",
    "\n",
    "    combined_early_degree = combined_early_degree[['author', 'pub_id']]\n",
    "\n",
    "    combined_early_degree = combined_early_degree.merge(publications_start_year, on='pub_id')\n",
    "\n",
    "    combined_early_degree = combined_early_degree[combined_early_degree.author_x != combined_early_degree.author_y]\n",
    "    combined_early_degree = combined_early_degree.drop_duplicates(subset=['author_x', 'author_y'])\n",
    "\n",
    "    combined_early_degree = combined_early_degree.groupby('author_x')['author_y'].count().reset_index()\n",
    "\n",
    "    combined_early_degree.rename({\"author_x\": \"author\", \"author_y\": f\"early_career_degree_{EARLY_CAREER}\"},\n",
    "                                 axis='columns', inplace=True)\n",
    "\n",
    "    credible_authors = credible_authors.merge(combined_early_degree, on='author', how='left')\n",
    "    credible_authors[f\"early_career_degree_{EARLY_CAREER}\"] = credible_authors[\n",
    "        f\"early_career_degree_{EARLY_CAREER}\"].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: Early productivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "    early_career_publications_reduced = publications_start_year[publications_start_year.year <\n",
    "                                                                publications_start_year.start_year + EARLY_CAREER]\n",
    "    early_career_publications_ = early_career_publications_reduced.groupby('author').agg(\n",
    "        {'pub_id': 'nunique'}).reset_index()\n",
    "    early_career_publications_ = early_career_publications_.rename({'pub_id': f'early_career_prod_{EARLY_CAREER}'},\n",
    "                                                                   axis='columns')\n",
    "    credible_authors = credible_authors.merge(early_career_publications_, on='author', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5: Venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO including the MAX and MIN values as missing. Check this. also what to do with ranking?\n",
    "early_career_venues = publications_start_year.merge(publication_venues_rank[[\n",
    "    'pub_id', 'h5_index', 'ranking', 'deciles', 'quantiles']], on='pub_id', how='inner')\n",
    "def quantile_binary(quant):\n",
    "    return quant <= 3\n",
    "\n",
    "\n",
    "for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "    #     EARLY_CAREER = 3\n",
    "    early_career_venues_ec = early_career_venues[\n",
    "        early_career_venues.year < early_career_venues.start_year + EARLY_CAREER]\n",
    "    early_career_venues_gr = early_career_venues_ec.groupby('author').agg({\n",
    "        'h5_index': 'max',\n",
    "        #     'ranking': 'min',\n",
    "        'deciles': 'min',\n",
    "        'quantiles': 'min'}).rename(columns={\n",
    "        'h5_index': f'h5_index_max_{EARLY_CAREER}',\n",
    "        #     'ranking': f'ranking_{EARLY_CAREER}',\n",
    "        'deciles': f'deciles_min_{EARLY_CAREER}',\n",
    "        'quantiles': f'quantiles_min_{EARLY_CAREER}'})\n",
    "    early_career_venues_gr = early_career_venues_gr.reset_index()\n",
    "    credible_authors = credible_authors.merge(early_career_venues_gr, on='author', how='left')\n",
    "\n",
    "    credible_authors[f'h5_index_max_{EARLY_CAREER}'] = credible_authors[f'h5_index_max_{EARLY_CAREER}'].fillna(0)\n",
    "    credible_authors[f'deciles_min_{EARLY_CAREER}'] = credible_authors[f'deciles_min_{EARLY_CAREER}'].fillna(10)\n",
    "    credible_authors[f'quantiles_min_{EARLY_CAREER}'] = credible_authors[f'quantiles_min_{EARLY_CAREER}'].fillna(4)\n",
    "\n",
    "    # CLAUDIA this should be TRUE if the author has AT LEAST one paper that exceeds the threshold\n",
    "    credible_authors[f'quantiles_bin_{EARLY_CAREER}'] = credible_authors[f'quantiles_min_{EARLY_CAREER}'].apply(\n",
    "        quantile_binary)\n",
    "\n",
    "    # credible_authors[f'ranking_{EARLY_CAREER}'] = credible_authors[f'ranking_{EARLY_CAREER}'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Number of early publications - first author (DF3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# number of first author publications\n",
    "for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "    publications_first_author_early = publications_first_author[\n",
    "        (publications_first_author.year < publications_first_author.start_year + EARLY_CAREER)]\n",
    "    publications_first_author_early = publications_first_author_early.groupby('author').agg(\n",
    "        {'pub_id': 'count'}).reset_index()\n",
    "    publications_first_author_early.rename({'pub_id': f'ec_first_auth_{EARLY_CAREER}'}, axis='columns', inplace=True)\n",
    "    credible_authors = credible_authors.merge(publications_first_author_early, on='author', how='left')\n",
    "    credible_authors[f'ec_first_auth_{EARLY_CAREER}'] = credible_authors[f'ec_first_auth_{EARLY_CAREER}'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counts Dataframe \n",
    "For every author, construct a 15 years time frame and count metrics for every career age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_years = get_start_years(START_YEAR, LAST_START_YEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create publication and citation dfs for first author\n",
    "author_year_numPub_first = publications_first_author.groupby(['author', 'year'])['pub_id'].count().reset_index()\n",
    "author_year_numPub_first = author_year_numPub_first.rename(columns={'pub_id': 'num_pub'})\n",
    "\n",
    "publications_citations_no_uncited_first = publications_citations_no_uncited.merge(\n",
    "    publications_first_author[['author', 'pub_id']], how='inner')\n",
    "citations_year_auth_first = publications_citations_no_uncited_first.groupby(['author', 'year_cit'])['id1'].count()\n",
    "\n",
    "citations_year_auth_first = citations_year_auth_first.reset_index()\n",
    "citations_year_auth_first = citations_year_auth_first.rename(columns={'id1': 'num_cit', 'year_cit': 'year'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8733089, 7)\n",
      "(26072622, 7)\n"
     ]
    }
   ],
   "source": [
    "print(publications_citations_no_uncited_first.shape)\n",
    "print(publications_citations_no_uncited.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "code_folding": [
     1,
     21,
     35,
     66,
     70
    ]
   },
   "outputs": [],
   "source": [
    "# create a dataframe with 15 career age entries for every author\n",
    "def create_counts_df(credible_authors, citations_year_auth_df, author_year_numPub_df):\n",
    "    counts0 = credible_authors[['author', 'start_year']].copy()\n",
    "    # filter out start years\n",
    "    counts0 = counts0[counts0['start_year'].isin(start_years)]\n",
    "    counts0['year'] = counts0['start_year'].apply(lambda x: [x + i for i in range(0, 15)])\n",
    "    counts = pd.DataFrame(counts0['year'].tolist(), index=counts0['author']).stack().reset_index(\n",
    "        level=1, drop=True).reset_index(name='year')[['year', 'author']]\n",
    "    counts = counts.merge(credible_authors[['author', 'start_year', 'end_year', 'gender']], on='author', how='inner')\n",
    "    counts['career_age'] = counts['year'] - counts['start_year'] + 1\n",
    "    counts['year'] = counts['year'].astype('int32')\n",
    "\n",
    "    counts['career_duration'] = counts['end_year'] - counts['start_year'] + 1\n",
    "    \n",
    "    counts = add_absolute_counts(counts, citations_year_auth_df, author_year_numPub_df)\n",
    "    \n",
    "    counts = add_cumulative_counts(counts, 'num_cit')\n",
    "    counts = add_cumulative_counts(counts, 'num_pub')\n",
    "    \n",
    "    return counts\n",
    "\n",
    "def add_absolute_counts(counts_df, citations_year_auth_df, author_year_numPub_df):\n",
    "    # merge in publications\n",
    "    counts_df = counts_df.merge(author_year_numPub_df, on=['author', 'year'], how='left')\n",
    "    counts_df['num_pub'] = counts_df['num_pub'].fillna(0)\n",
    "    # merge in citations\n",
    "    counts_df = counts_df.merge(citations_year_auth_df, on=['author', 'year'], how='left')\n",
    "    counts_df['num_cit'] = counts_df['num_cit'].fillna(0)\n",
    "    return counts_df\n",
    "\n",
    "def add_cumulative_counts(counts_df, feature):\n",
    "    counts_df = calculate.calculate_cumulative_for_authors(counts_df, feature)\n",
    "    return counts_df\n",
    "\n",
    "# add citation and publication window features to citations df\n",
    "def add_citation_window_counts(counts_df, combined_df, WINDOW_SIZE):\n",
    "    \"\"\"\n",
    "    Adds 2 columns to the counts dataframe: win_num_cit, win_num_pub\n",
    "    win_num_pub: count publications for career ages, with forward looking windows of size WINDOW_SIZE\n",
    "    \n",
    "    win_num_cit: for a publication window defined by win_num_pub, count citations in a sliding window\n",
    "    that starts at publication year and extends to pub_year+WINDOW_SIZE, non inclusive\n",
    "    \"\"\"\n",
    "    shift = -(WINDOW_SIZE - 1)\n",
    "    # citations window\n",
    "    df_list = []\n",
    "    for year in start_years:\n",
    "        df_year = combined_df[combined_df.start_year == year]\n",
    "        for y in range(year, year + 13):  # y is the first year we count for\n",
    "            df_window = df_year[(df_year.year_pub >= y) & (df_year.year_pub < y + WINDOW_SIZE) &\n",
    "                                (df_year.year_cit >= y) & \n",
    "                                (df_year.year_cit < df_year.year_pub + WINDOW_SIZE)]\n",
    "            df_window = df_window.groupby('author').agg({'id1': 'count'}).reset_index()\n",
    "            df_window['year'] = y\n",
    "            df_window = df_window.rename({'id1': 'win_num_cit'}, axis=1)\n",
    "            df_list.append(df_window)\n",
    "    df_cit_window = pd.concat(df_list).sort_values(by=['author', 'year'])\n",
    "    counts_df = counts_df.merge(df_cit_window, on=['author', 'year'], how='left')\n",
    "    counts_df['win_num_cit'] = counts_df['win_num_cit'].fillna(0)\n",
    "    \n",
    "    counts_df['win_num_pub'] = counts_df.groupby('author')['num_pub'].transform(\n",
    "        lambda x: x.rolling(WINDOW_SIZE, min_periods=WINDOW_SIZE).sum().shift(shift))\n",
    "    \n",
    "    return counts_df\n",
    "\n",
    "\n",
    "def save_counts(counts_df, WINDOW_SIZE, ext=''):\n",
    "    counts_df.to_csv(f'derived-data/citations_window_{WINDOW_SIZE}{ext}.csv', index=None)\n",
    "\n",
    "\n",
    "def make_counts_file(base_df, publications_citations_no_uncited, WINDOW_SIZE, file_ext=''):\n",
    "    counts_df = base_df.copy(deep=True)\n",
    "    counts_df = add_citation_window_counts(base_df, publications_citations_no_uncited, WINDOW_SIZE)\n",
    "\n",
    "    save_counts(counts_df, WINDOW_SIZE, file_ext)\n",
    "    return counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20min 22s, sys: 20.7 s, total: 20min 43s\n",
      "Wall time: 23min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "base_df = create_counts_df(credible_authors, author_yearly_citations, author_yearly_publications)\n",
    "base_df_first = create_counts_df(credible_authors, citations_year_auth_first, author_year_numPub_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 44s, sys: 16.4 s, total: 19min 1s\n",
      "Wall time: 21min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# all authors\n",
    "WINDOW_SIZE = 3\n",
    "counts_df = make_counts_file(base_df, publications_citations_no_uncited, WINDOW_SIZE)\n",
    "# first author\n",
    "counts_df_first = make_counts_file(base_df_first, publications_citations_no_uncited_first, WINDOW_SIZE, file_ext='_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 59s, sys: 17.4 s, total: 19min 17s\n",
      "Wall time: 21min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "WINDOW_SIZE = 5\n",
    "# all authors\n",
    "counts_df_5 = make_counts_file(base_df, publications_citations_no_uncited, WINDOW_SIZE)\n",
    "# first author\n",
    "counts_df_first_5 = make_counts_file(base_df_first, publications_citations_no_uncited_first, WINDOW_SIZE, file_ext='_first')\n",
    "#TODO write tests for counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deprecated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early, mid and late papers analysis - citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# TODO Delete\n",
    "# def add_fine_grained_citation_counts(counts):\n",
    "#     # publish_years = [[0,3], [3,6], [6,9], [0,1], [3,4], [6,7]]\n",
    "#     publish_years = [[i, i + 1] for i in range(0, 15)]\n",
    "#     for start, end in publish_years:\n",
    "#         first_3 = publications_citations_no_uncited[\n",
    "#             (publications_citations_no_uncited.year_pub >= publications_citations_no_uncited.start_year + start) &\n",
    "#             (publications_citations_no_uncited.year_pub < publications_citations_no_uncited.start_year + end)]\n",
    "#         first_3 = first_3.groupby(['author', 'year_cit']).agg({'id1': 'count'}).reset_index()\n",
    "#         first_3 = first_3.rename({'year_cit': 'year', 'id1': f'ec_cit_{start}_{end}'}, axis=1)\n",
    "#         counts = counts.merge(first_3, on=['author', 'year'], how='left')\n",
    "#         counts[f'ec_cit_{start}_{end}'] = counts[f'ec_cit_{start}_{end}'].fillna(0)\n",
    "#     for start, end in publish_years:\n",
    "#         counts[f'ec_cit_{start}_{end}_cum'] = counts.sort_values(['author', 'career_age']).groupby('author')[\n",
    "#             f'ec_cit_{start}_{end}'].transform(pd.Series.cumsum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Coauthor max citations - deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "#     combined_early_coauthor = combined_df[(combined_df.year_pub < combined_df.start_year + EARLY_CAREER)]\n",
    "\n",
    "#     combined_early_coauthor = combined_early_coauthor.drop_duplicates(subset=['author', 'pub_id'])\n",
    "\n",
    "#     combined_early_coauthor = combined_early_coauthor[['author', 'pub_id']]\n",
    "\n",
    "#     combined_early_coauthor = combined_early_coauthor.merge(combined_df, on='pub_id')\n",
    "\n",
    "#     combined_early_coauthor = combined_early_coauthor[combined_early_coauthor.author_x != combined_early_coauthor.author_y]\n",
    "#     combined_early_coauthor = combined_early_coauthor.drop_duplicates(subset=['author_x', 'author_y'])\n",
    "\n",
    "#     combined_early_coauthor = combined_early_coauthor.merge(credible_authors[['author', 'succ_after_15y']], left_on='author_y', right_on='author')\n",
    "#     combined_early_coauthor = combined_early_coauthor.groupby('author_x')['succ_after_15y'].max().reset_index()\n",
    "\n",
    "#     combined_early_coauthor.rename({\"author_x\":\"author\", \"succ_after_15y\": f\"early_career_coauthor_max_cit_{EARLY_CAREER}\"}, \n",
    "#                                  axis='columns', inplace=True)\n",
    "\n",
    "#     combined_early_coauthor = combined_early_coauthor[['author', f\"early_career_coauthor_max_cit_{EARLY_CAREER}\"]]\n",
    "\n",
    "#     credible_authors = credible_authors.merge(combined_early_coauthor, on='author', how='left')\n",
    "#     credible_authors[f\"early_career_coauthor_max_cit_{EARLY_CAREER}\"] = credible_authors[f\"early_career_coauthor_max_cit_{EARLY_CAREER}\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop\n",
    "def drop_list_cols(drop_list):\n",
    "    credible_authors.drop(drop_list, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_col(df, cols):\n",
    "    df.drop(cols, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_authors[credible_authors.start_year >= START_YEAR].to_csv('derived-data/authors-scientific-extended.csv',\n",
    "                                                                   index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author', 'start_year', 'end_year', 'total_num_pub', 'career_length',\n",
       "       'gender', 'early_career_qual_3', 'early_career_qual_first_3',\n",
       "       'early_career_recognition_EC3_RC3', 'citation_count_3',\n",
       "       'citation_count_10', 'citation_count_15', 'h-index_3', 'h-index_10',\n",
       "       'h-index_15', 'early_career_coauthor_max_hindex_3',\n",
       "       'citation_increase_10_3', 'h_index_increase_10_3',\n",
       "       'citation_increase_15_3', 'h_index_increase_15_3', 'team_size_median_3',\n",
       "       'team_size_mean_3', 'early_career_degree_3', 'early_career_prod_3',\n",
       "       'h5_index_max_3', 'deciles_min_3', 'quantiles_min_3', 'quantiles_bin_3',\n",
       "       'ec_first_auth_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credible_authors.columns"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
