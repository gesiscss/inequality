{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual and gender inequality in computer science: A career study of cohorts from 1970 to 2000\n",
    "\n",
    "## Part 4: Prediction\n",
    "\n",
    "In this notebook, we run linear regression models using the engineered cohort, gender, early achievement, and social support features. First, in table 2, we predict whether or not an author will have dropped out at career age 15. Second, in table 3, we predict the success of an author at career age 15 for all authors and for dropouts removed.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Imports\n",
    "\n",
    "Many of the custom functions we need are stored in a utilities file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import ElasticNetCV, LogisticRegressionCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load data\n",
    "\n",
    "Load feature dataframe from the 'data' directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "features = pd.read_csv('../data/features.csv.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preprocess data\n",
    "\n",
    "Reduce observations to authors from cohorts 1970 to 2000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "COHORT_START_YEARS = get_start_years(1970, 2000, features)\n",
    "features = features[features.career_length >= 1]\n",
    "features = features[features.cohort.isin(COHORT_START_YEARS)]\n",
    "print('Number of authors:', len(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct dataframe with dropouts removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_stayed = features[features['dropout'] == False].copy()\n",
    "print('Number of authors (dropouts removed):', len(features_stayed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get fraction of dropouts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_percent = features.groupby('cohort')['dropout'].sum() / features.groupby('cohort')['dropout'].count()\n",
    "dropped_percent = dropped_percent.to_frame().T\n",
    "\n",
    "dropped_percent_agg = features['dropout'].sum() / features['dropout'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Linear regression\n",
    "\n",
    "#### 4.1. Provide functions\n",
    "\n",
    "The inner working of the predictions is stored in these functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cols_lists(INCLUDE_BASELINE, INCLUDE_GENDER, INCLUDE_ACHIEVEMENT, INCLUDE_SOCIAL, REMOVE_NONE_AUTHORS, dep_var):\n",
    "    categorical_cols = []\n",
    "    cols_std = []\n",
    "    if INCLUDE_BASELINE:\n",
    "        cols_std.append('cohort')\n",
    "    if INCLUDE_GENDER:\n",
    "        categorical_cols.append('gender')\n",
    "    if INCLUDE_ACHIEVEMENT:\n",
    "        cols_std.append('productivity')\n",
    "        cols_std.append('productivity_first')\n",
    "        cols_std.append('impact')\n",
    "        cols_std.append('top_source')\n",
    "    if INCLUDE_SOCIAL:\n",
    "        cols_std.append('collaboration_network')\n",
    "        cols_std.append('team_size')\n",
    "        cols_std.append('senior_support')\n",
    "    if dep_var == 'dropout':\n",
    "        categorical_cols.append(dep_var)\n",
    "    else:\n",
    "        cols_std.append(dep_var)\n",
    "    return cols_std, categorical_cols\n",
    "\n",
    "def prepare_data(features, cols_std, categorical_cols, REMOVE_NONE_AUTHORS, aggr=False):\n",
    "    X = features[features.cohort.isin(COHORT_START_YEARS)].copy()\n",
    "    if not aggr:\n",
    "        for year in COHORT_START_YEARS:\n",
    "            X.loc[X.cohort == year, cols_std] = scale_columns(X.loc[X.cohort == year, cols_std])\n",
    "    else:\n",
    "        X[cols_std] = scale_columns(X[cols_std])\n",
    "    if len(categorical_cols) > 0:\n",
    "        cat_cols = pd.get_dummies(X[categorical_cols]) \n",
    "        X = X[cols_std].join(cat_cols)\n",
    "    else:\n",
    "        X = X[cols_std]\n",
    "    if REMOVE_NONE_AUTHORS:\n",
    "        X.drop('gender_none', axis=1)\n",
    "    X['cohort'] = features['cohort']\n",
    "    return X\n",
    "\n",
    "def run_elastic_net_aggr(features, cols_std, categorical_cols, INCLUDE_YEAR, REMOVE_NONE_AUTHORS, dep_var):\n",
    "    X = prepare_data(features, cols_std, categorical_cols, REMOVE_NONE_AUTHORS, aggr=True)\n",
    "    Y = X[dep_var].copy()\n",
    "    X = X.drop(dep_var, axis=1)\n",
    "    if not INCLUDE_YEAR:\n",
    "        X = X.drop('cohort' , axis=1)\n",
    "    feat_table = run_elastic_net(X, Y)\n",
    "    feat_table = feat_table.set_index(0)\n",
    "    if dep_var == 'dropout': \n",
    "        feat_table = feat_table.append(pd.DataFrame(index=['drop_percentage'], data=[dropped_percent_agg], columns=[1]))\n",
    "    return feat_table\n",
    "\n",
    "def run_elastic_net(X, y):\n",
    "    if X.empty:\n",
    "        X = pd.DataFrame(1, index=np.arange(len(y)), columns=['dummy'])\n",
    "    kf = KFold(10, shuffle=True, random_state=42)\n",
    "    if y.nunique() == 2:   \n",
    "        y = y.astype(int)\n",
    "        cv_dict = cross_validate(LogisticRegressionCV(cv=10, penalty='l2', max_iter=200), X, y, scoring=['f1_micro','f1_macro','f1_weighted','average_precision'], cv=kf, return_estimator=True, return_train_score=False)\n",
    "        net_coef = pd.DataFrame([es.coef_[0] for es in cv_dict['estimator']], columns=X.columns)\n",
    "        score = np.mean(cv_dict['test_f1_micro'])\n",
    "        score2 = np.mean(cv_dict['test_f1_macro'])\n",
    "        score3 = np.mean(cv_dict['test_f1_weighted'])\n",
    "        score4 = np.mean(cv_dict['test_average_precision'])\n",
    "    else:\n",
    "        adj_r2_scorer = make_scorer(adjusted_r2, num_feat=X.shape[1])\n",
    "        cv_dict = cross_validate(ElasticNetCV(cv=10), X, y, scoring={'r2':make_scorer(r2_score), 'neg_mean_squared_error': make_scorer(mean_squared_error), 'adj_r2': adj_r2_scorer}, cv=kf, return_estimator=True, return_train_score=False)\n",
    "        net_coef = pd.DataFrame([es.coef_ for es in cv_dict['estimator']], columns=X.columns)\n",
    "        score = np.mean(cv_dict['test_r2'])\n",
    "        score2 = abs(np.mean(cv_dict['test_neg_mean_squared_error']))\n",
    "        score3 = np.mean(cv_dict['test_adj_r2'])\n",
    "\n",
    "    net_intercept = np.mean([es.intercept_ for es in cv_dict['estimator']])\n",
    "    net_coef_mean = net_coef.mean()\n",
    "    net_coef_std = net_coef.std()\n",
    "    rounding = 2\n",
    "    net_coef_mean_std = list(zip(np.round(net_coef_mean.values,rounding), np.round(net_coef_std.values,rounding)))\n",
    "    net_coef_mean_std = [f'{x[0]}({x[1]})' for x in net_coef_mean_std]\n",
    "\n",
    "    cohort_size = len(y)\n",
    "    if y.nunique() != 2:\n",
    "        net_coef_mean_std.extend([np.round(net_intercept, rounding), np.round(score, rounding), np.round(score3, rounding), np.round(score2, rounding), cohort_size])\n",
    "        feat_table = pd.DataFrame(list(zip(np.append(X.columns, ['intercept', 'r2', 'adj_r2', 'neg_mean_squared_error', 'cohort_size']), net_coef_mean_std)))\n",
    "    else:\n",
    "        net_coef_mean_std.extend([np.round(net_intercept, rounding), np.round(score, rounding), np.round(score2, rounding), np.round(score3, rounding), np.round(score4, rounding), cohort_size])\n",
    "        feat_table = pd.DataFrame(list(zip(np.append(X.columns, ['intercept', 'f1_micro','f1_macro','f1_weighted', 'avg_precision', 'cohort_size']), net_coef_mean_std)))\n",
    "    return feat_table\n",
    "\n",
    "def get_baseline_vars():\n",
    "    INCLUDE_BASELINE = 1\n",
    "    INCLUDE_GENDER = 0\n",
    "    INCLUDE_ACHIEVEMENT = 0\n",
    "    INCLUDE_SOCIAL = 0\n",
    "    REMOVE_NONE_AUTHORS = 0\n",
    "    return INCLUDE_BASELINE, INCLUDE_GENDER, INCLUDE_ACHIEVEMENT, INCLUDE_SOCIAL, REMOVE_NONE_AUTHORS\n",
    "\n",
    "def get_gender_vars():\n",
    "    INCLUDE_BASELINE = 1\n",
    "    INCLUDE_GENDER = 1\n",
    "    INCLUDE_ACHIEVEMENT = 0\n",
    "    INCLUDE_SOCIAL = 0\n",
    "    REMOVE_NONE_AUTHORS = 0\n",
    "    return INCLUDE_BASELINE, INCLUDE_GENDER, INCLUDE_ACHIEVEMENT, INCLUDE_SOCIAL, REMOVE_NONE_AUTHORS\n",
    "\n",
    "def get_achievement_vars():\n",
    "    INCLUDE_BASELINE = 1\n",
    "    INCLUDE_GENDER = 1\n",
    "    INCLUDE_ACHIEVEMENT = 1\n",
    "    INCLUDE_SOCIAL = 0\n",
    "    REMOVE_NONE_AUTHORS = 0\n",
    "    return INCLUDE_BASELINE, INCLUDE_GENDER, INCLUDE_ACHIEVEMENT, INCLUDE_SOCIAL, REMOVE_NONE_AUTHORS\n",
    "\n",
    "def get_social_vars():\n",
    "    INCLUDE_BASELINE = 1\n",
    "    INCLUDE_GENDER = 1\n",
    "    INCLUDE_ACHIEVEMENT = 1\n",
    "    INCLUDE_SOCIAL = 1\n",
    "    REMOVE_NONE_AUTHORS = 0\n",
    "    return INCLUDE_BASELINE, INCLUDE_GENDER, INCLUDE_ACHIEVEMENT, INCLUDE_SOCIAL, REMOVE_NONE_AUTHORS\n",
    "\n",
    "def elastic_agg(features, params_func, DV):\n",
    "    params = params_func()\n",
    "    cols_std, categorical_cols = make_cols_lists(*params, DV)\n",
    "    INCLUDE_BASELINE = params[0]\n",
    "    REMOVE_NONE_AUTHORS = params[4]\n",
    "    res_agg = run_elastic_net_aggr(features, cols_std, categorical_cols, INCLUDE_BASELINE, REMOVE_NONE_AUTHORS, DV)\n",
    "    return res_agg\n",
    "\n",
    "def elastic_agg_all(features, DV):\n",
    "    params_func_list = [get_baseline_vars, get_gender_vars, get_achievement_vars, get_social_vars]\n",
    "    res_agg_list = [elastic_agg(features, params_func, DV) for params_func in params_func_list]\n",
    "    res_all_agg = pd.DataFrame(index=res_agg_list[-1].index, data=[])\n",
    "    res_all_agg['Baseline'] = res_agg_list[0]\n",
    "    res_all_agg['Gender'] = res_agg_list[1]\n",
    "    res_all_agg['Early Achievement'] = res_agg_list[2]\n",
    "    res_all_agg['Social Support'] = res_agg_list[3]\n",
    "    if DV == 'dropout':\n",
    "        reorderlist = ['cohort',\n",
    "                       'gender_f', 'gender_m', 'gender_none',\n",
    "                       'productivity', 'productivity_first', 'impact', 'top_source',\n",
    "                       'collaboration_network', 'senior_support', 'team_size',\n",
    "                       'cohort_size', 'drop_percentage', 'intercept', 'avg_precision', 'f1_micro', 'f1_macro', 'f1_weighted']\n",
    "        res_all_agg = res_all_agg.reindex(reorderlist)\n",
    "        res_all_agg = res_all_agg.fillna('')\n",
    "        res_all_agg['names'] = ['Cohort',\n",
    "                                'Female', 'Male', 'Undetected',\n",
    "                                'Productivity', 'Productivity (1st)', 'Impact', 'Top venue',\n",
    "                                'Collaboration network', 'Senior support', 'Median team size',\n",
    "                                'Cohort size', '% dropouts', 'Intercept', 'Average precision', 'F1 micro', 'F1 macro', 'F1 weighted']\n",
    "    else:\n",
    "        reorderlist = ['cohort',\n",
    "                       'gender_f', 'gender_m', 'gender_none',\n",
    "                       'productivity', 'productivity_first', 'impact', 'top_source',\n",
    "                       'collaboration_network', 'senior_support', 'team_size',\n",
    "                       'cohort_size', 'neg_mean_squared_error', 'intercept', 'r2', 'adj_r2']\n",
    "        res_all_agg = res_all_agg.reindex(reorderlist)\n",
    "        res_all_agg = res_all_agg.fillna('')\n",
    "        res_all_agg['names'] = ['Cohort',\n",
    "                                'Female', 'Male', 'Undetected',\n",
    "                                'Productivity', 'Productivity (1st)', 'Impact', 'Top venue',\n",
    "                                'Collaboration network', 'Senior support', 'Median team size',\n",
    "                                'Cohort size', 'MSE', 'Intercept','R2', 'Adjusted R2']\n",
    "    res_all_agg = res_all_agg.set_index('names')\n",
    "    return res_all_agg\n",
    "\n",
    "def results_to_latex(results, name):\n",
    "    ltx_file = open(f'../results/results_{name}.tex', 'w')\n",
    "    ltx_file.write('\\n'.join(results.to_latex().split('\\n')[5:-7]))\n",
    "    ltx_file.write('\\hline \\n')\n",
    "    ltx_file.write('\\n'.join(results.to_latex().split('\\n')[-7:-3]))\n",
    "    ltx_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Table 2: Dropout prediction\n",
    "\n",
    "Here, we predict whether or not an author will have dropped out at career age 15:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv_dropout = 'dropout'\n",
    "reg_dropout = elastic_agg_all(features, dv_dropout)\n",
    "results_to_latex(reg_dropout, 'reg_dropout')\n",
    "reg_dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3. Table 3: Success prediction\n",
    "\n",
    "Here, we predict the success of an author at career age 15. In the paper, these two tables are combined into one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all authors\n",
    "dv_success = 'success'\n",
    "reg_success = elastic_agg_all(features, dv_success)\n",
    "results_to_latex(reg_success, 'reg_success')\n",
    "reg_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropouts removed\n",
    "reg_success_stayed = elastic_agg_all(features_stayed, dv_success)\n",
    "results_to_latex(reg_success_stayed, 'reg_success_stayed')\n",
    "reg_success_stayed"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_json": true,
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
