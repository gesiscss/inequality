{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAREER_LENGTH = 1\n",
    "\n",
    "#EARLY_CAREER_LEN_LIST = [1, 2, 3, 4, 5]\n",
    "EARLY_CAREER_LEN_LIST = [3]\n",
    "#RECOGNITION_CUT_OFF_LIST = [3, 4, 5, 6, 7, 8, 9]\n",
    "RECOGNITION_CUT_OFF_LIST = [5]\n",
    "\n",
    "MAX_CAREER_LEN = 15\n",
    "END_YEAR = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_authors = pd.read_csv('derived-data/authors-scientific-extended.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author', 'start_year', 'end_year', 'total_num_pub', 'career_length',\n",
       "       'max_absence-0-15', 'avg_absence-0-15', 'dropped_after_10', 'gender',\n",
       "       'early_career_degree_3', 'early_career_qual_3', 'succ_after_15y',\n",
       "       'early_career_prod_3', 'early_career_coauthor_max_cit_3',\n",
       "       'early_career_recognition_EC3_RC3', 'early_career_recognition_EC3_RC5',\n",
       "       'h-index_15', 'h-index_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credible_authors.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_authors = credible_authors[credible_authors.career_length >= CAREER_LENGTH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_authors['citation_increase_15_3'] = credible_authors['succ_after_15y'] - credible_authors[\n",
    "    'early_career_recognition_EC3_RC3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_authors['h_index_increase_15_3'] = credible_authors['h-index_15'] - credible_authors['h-index_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data first look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_authors.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_authors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cor_qual = credible_authors.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cor_qual\n",
    "#cor_qual['succ_after_15y'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#cor_rec = credible_authors[['early_career_recognition_EC1_RC3', 'early_career_recognition_EC1_RC5',\n",
    "#       'early_career_recognition_EC1_RC7', 'early_career_recognition_EC1_RC9',\n",
    "#       'early_career_recognition_EC2_RC3', 'early_career_recognition_EC2_RC5',\n",
    "#       'early_career_recognition_EC2_RC7', 'early_career_recognition_EC2_RC9',\n",
    "#       'early_career_recognition_EC3_RC3', 'early_career_recognition_EC3_RC5',\n",
    "#       'early_career_recognition_EC3_RC7', 'early_career_recognition_EC3_RC9',\n",
    "#       'early_career_recognition_EC4_RC5', 'early_career_recognition_EC4_RC7',\n",
    "#       'early_career_recognition_EC4_RC9', 'early_career_recognition_EC5_RC5',\n",
    "#       'early_career_recognition_EC5_RC7', 'early_career_recognition_EC5_RC9',\n",
    "#       'succ_after_15y']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#cor_rec['succ_after_15y'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cor = credible_authors.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cor['citation_increase_15_3'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.heatmap(cor, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, ElasticNet, ElasticNetCV, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test different predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# test different early career lenghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "year = 1995\n",
    "\n",
    "credible_authors_1991 = credible_authors[credible_authors.start_year == year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = credible_authors_1991.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "categorical_cols = ['gender']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    X = X.join(pd.get_dummies(X[categorical_cols]))\n",
    "\n",
    "X.drop(categorical_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def run_linear(func, name):\n",
    "    df = pd.DataFrame(columns=['params', f'r_squared_{name}'])\n",
    "    for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "        for RECOGNITION_CUT in RECOGNITION_CUT_OFF_LIST:\n",
    "            if RECOGNITION_CUT < EARLY_CAREER: continue\n",
    "            H = X[[\n",
    "                #'max_absence-0-3', 'avg_absence-0-3',\n",
    "                   'gender_f', 'gender_m', 'gender_none',\n",
    "                   f'early_career_degree_{EARLY_CAREER}', \n",
    "                   f'early_career_prod_{EARLY_CAREER}',\n",
    "                   f'early_career_qual_{EARLY_CAREER}', f'early_career_recognition_EC{EARLY_CAREER}_RC{RECOGNITION_CUT}']]\n",
    "            reg = func.fit(H, y)\n",
    "            df = df.append({'params': f'EC:{EARLY_CAREER},REC:{RECOGNITION_CUT}',\n",
    "                            f'r_squared_{name}': reg.score(H, y)}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def run_cv(func, name, cv, y_col='succ_after_15y'):\n",
    "    df = pd.DataFrame(columns=['params', f'r_squared_{name}'])\n",
    "    for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "        for RECOGNITION_CUT in RECOGNITION_CUT_OFF_LIST:\n",
    "            if RECOGNITION_CUT < EARLY_CAREER: continue\n",
    "            H = X[[\n",
    "                #'max_absence-0-3', 'avg_absence-0-3',\n",
    "                   'gender_f', 'gender_m', 'gender_none',\n",
    "                   f'early_career_degree_{EARLY_CAREER}', \n",
    "                   f'early_career_prod_{EARLY_CAREER}',\n",
    "                   f'early_career_qual_{EARLY_CAREER}', f'early_career_recognition_EC{EARLY_CAREER}_RC{RECOGNITION_CUT}']]\n",
    "            y = X[y_col]\n",
    "            score = np.mean(cross_val_score(func, H, y, cv=cv, scoring='r2'))\n",
    "            df = df.append({'params': f'EC:{EARLY_CAREER},REC:{RECOGNITION_CUT}',\n",
    "                            f'r_squared_{name}': score}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1 = run_cv(LinearRegression(), 'linear', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# df1_null = run_cv(LinearRegression(), 'linear_null', cv=3, y_col='succ_shuffled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2 = run_cv(ElasticNet(), 'elastic', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df3 = run_cv(ElasticNetCV(cv=3), 'elastic_CV', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df4 = run_cv(Lasso(alpha=0.1), 'lasso', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Decision tree overfits pretty bad. Maybe GridParam Search?\n",
    "df5 = run_cv(DecisionTreeRegressor(), 'tree', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df6 = run_cv(RandomForestRegressor(), 'forest', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# df6_null = run_cv(RandomForestRegressor(), 'forest_null', cv=3, y_col='succ_shuffled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfs = [df1, df2, df3, df4, df5, df6] #df1_null, df6_null\n",
    "for df_ in dfs: df_.set_index('params', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfs[0].join(dfs[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = sorted(credible_authors.start_year.unique())\n",
    "cohort_start_years = [y for y in years if y < (END_YEAR - MAX_CAREER_LEN)]\n",
    "EARLY_CAREER = EARLY_CAREER_LEN_LIST[0]\n",
    "RECOGNITION_CUT = RECOGNITION_CUT_OFF_LIST[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,RobustScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_std = [f'early_career_degree_{EARLY_CAREER}',\n",
    "       f'early_career_prod_{EARLY_CAREER}', f'early_career_coauthor_max_cit_{EARLY_CAREER}',\n",
    "       f'early_career_qual_{EARLY_CAREER}', \n",
    "#             f'early_career_recognition_EC3_RC3',\n",
    "#             f'early_career_recognition_EC{EARLY_CAREER}_RC{RECOGNITION_CUT}'\n",
    "           ] \n",
    "cols_all = [f'early_career_degree_{EARLY_CAREER}',\n",
    "       f'early_career_prod_{EARLY_CAREER}', f'early_career_coauthor_max_cit_{EARLY_CAREER}',\n",
    "       f'early_career_qual_{EARLY_CAREER}', \n",
    "#             f'early_career_recognition_EC3_RC3',\n",
    "#         f'early_career_recognition_EC{EARLY_CAREER}_RC{RECOGNITION_CUT}',\n",
    "       'gender_m', 'gender_f',  'intercept', 'r2', 'adj_r2', 'cohort_size'] #'gender_none', \n",
    "categorical_cols = ['gender']\n",
    "num_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_table = pd.DataFrame(cols_all, columns=['feature']).set_index('feature')\n",
    "feature_table2 = pd.DataFrame(cols_all, columns=['feature']).set_index('feature')\n",
    "feature_table3 = pd.DataFrame(cols_all, columns=['feature']).set_index('feature')\n",
    "\n",
    "for year in cohort_start_years:\n",
    "    credible_authors_year = credible_authors[credible_authors.start_year == year]\n",
    "    #std all\n",
    "    #credible_authors_year = credible_authors_std[credible_authors_std.start_year == year]\n",
    "    X = credible_authors_year.copy()\n",
    "    \n",
    "    # Make dummy values for categorical columns\n",
    "    gender_cols = pd.get_dummies(X[categorical_cols])\n",
    "    # drop gender none?\n",
    "    gender_cols.drop('gender_none', axis=1, inplace=True)\n",
    "      \n",
    "    #standardize cols_std\n",
    "    standardized_cols = RobustScaler().fit_transform(X[cols_std])\n",
    "    #std all\n",
    "    #standardized_cols = X[cols_std]\n",
    "    \n",
    "    #combine\n",
    "    H = pd.DataFrame(standardized_cols, index=X.index, columns=cols_std)\n",
    "    H = H.join(gender_cols)\n",
    "\n",
    "    y = X['h_index_increase_15_3']\n",
    "    y2 = X['citation_increase_15_3']\n",
    "    y3 = X['dropped_after_10'].astype(int)\n",
    "    \n",
    "    kf = KFold(n_splits=num_splits)\n",
    "    net_list, net2_list, net3_list = [], [], []\n",
    "    score_list, score2_list, score3_list = [], [], []\n",
    "    \n",
    "    for train_index, test_index in kf.split(H):\n",
    "\n",
    "        H_train, H_test, y_train, y_test = H.iloc[train_index], H.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "        y2_train, y2_test = y2.iloc[train_index], y2.iloc[test_index]\n",
    "        y3_train, y3_test = y3.iloc[train_index], y3.iloc[test_index]\n",
    "\n",
    "    #     H_train, H_test, y_train, y_test = train_test_split(H, y, test_size=0.2, random_state=424)\n",
    "    #     H_train, H_test, y2_train, y2_test = train_test_split(H, y2, test_size=0.2, random_state=424)\n",
    "    #     H_train, H_test, y3_train, y3_test = train_test_split(H, y3, test_size=0.2, random_state=424)\n",
    "\n",
    "\n",
    "        net = ElasticNetCV(cv=3)\n",
    "        net.fit(H_train, y_train)\n",
    "        net2 = ElasticNetCV(cv=3)\n",
    "        net2.fit(H_train, y2_train)\n",
    "    #     net3 = ElasticNetCV(cv=3)\n",
    "        net3 = LogisticRegressionCV(cv=3)\n",
    "        net3.fit(H_train, y3_train)\n",
    "        score = r2_score(y_test, net.predict(H_test))\n",
    "        score2 = r2_score(y2_test, net2.predict(H_test))\n",
    "\n",
    "    #     score = np.mean(cross_val_score(net, H_test, y_test, cv=3, scoring='r2'))\n",
    "    #     score2 = np.mean(cross_val_score(net2, H_test, y2_test, cv=3, scoring='r2'))\n",
    "        cohort_size = len(y2)\n",
    "        num_nonzero_coefs = sum(net2.coef_ != 0)\n",
    "        adj_score2 = 1 - (1-score2)*(cohort_size-1)/(cohort_size-num_nonzero_coefs-1)\n",
    "        score3 = roc_auc_score(y3_test, net3.decision_function(H_test))\n",
    "        # score3 = np.mean(cross_val_score(net3, H, y3, cv=3, scoring='accuracy'))\n",
    "        net_list.append(net.coef_)\n",
    "        net2_list.append(net2.coef_)\n",
    "        net3_list.append(net3.coef_)\n",
    "        score_list.append(score)\n",
    "        score2_list.append(score2)\n",
    "        score3_list.append(score3)\n",
    "        \n",
    "    \n",
    "    \n",
    "    net_coef = pd.DataFrame(list(zip(np.append(H.columns, ['intercept', 'r2', 'cohort_size']), \n",
    "                                      np.append(net.coef_, [net.intercept_, score, cohort_size]))), \n",
    "                             columns=['year', year]).set_index('year')\n",
    "    net_coef2 = pd.DataFrame(list(zip(np.append(H.columns, ['intercept', 'r2', 'adj_r2', 'cohort_size']), \n",
    "                                      np.append(net2.coef_, [net2.intercept_, score2, adj_score2, cohort_size]))), \n",
    "                             columns=['year', year]).set_index('year')\n",
    "    net_coef3 = pd.DataFrame(list(zip(np.append(H.columns, ['intercept', 'r2', 'cohort_size']), \n",
    "                                      np.append(np.exp(net3.coef_), [net3.intercept_, score3, cohort_size]))),\n",
    "                             columns=['year', year]).set_index('year')\n",
    "\n",
    "    feature_table = feature_table.join(net_coef)\n",
    "    feature_table2 = feature_table2.join(net_coef2)\n",
    "    feature_table3 = feature_table3.join(net_coef3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ElasticNetCV(alphas=None, copy_X=True, cv=3, eps=0.001, fit_intercept=True,\n",
       "        l1_ratio=0.5, max_iter=1000, n_alphas=100, n_jobs=None,\n",
       "        normalize=False, positive=False, precompute='auto',\n",
       "        random_state=None, selection='cyclic', tol=0.0001, verbose=0),\n",
       " ElasticNetCV(alphas=None, copy_X=True, cv=3, eps=0.001, fit_intercept=True,\n",
       "        l1_ratio=0.5, max_iter=1000, n_alphas=100, n_jobs=None,\n",
       "        normalize=False, positive=False, precompute='auto',\n",
       "        random_state=None, selection='cyclic', tol=0.0001, verbose=0),\n",
       " ElasticNetCV(alphas=None, copy_X=True, cv=3, eps=0.001, fit_intercept=True,\n",
       "        l1_ratio=0.5, max_iter=1000, n_alphas=100, n_jobs=None,\n",
       "        normalize=False, positive=False, precompute='auto',\n",
       "        random_state=None, selection='cyclic', tol=0.0001, verbose=0),\n",
       " ElasticNetCV(alphas=None, copy_X=True, cv=3, eps=0.001, fit_intercept=True,\n",
       "        l1_ratio=0.5, max_iter=1000, n_alphas=100, n_jobs=None,\n",
       "        normalize=False, positive=False, precompute='auto',\n",
       "        random_state=None, selection='cyclic', tol=0.0001, verbose=0),\n",
       " ElasticNetCV(alphas=None, copy_X=True, cv=3, eps=0.001, fit_intercept=True,\n",
       "        l1_ratio=0.5, max_iter=1000, n_alphas=100, n_jobs=None,\n",
       "        normalize=False, positive=False, precompute='auto',\n",
       "        random_state=None, selection='cyclic', tol=0.0001, verbose=0))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(ElasticNetCV(cv=3), H, y2, cv=5, return_estimator=True, return_train_score=False)['estimator'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(net_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = feature_table.transpose()\n",
    "#shorten column names\n",
    "new_cols = dict(zip(results.columns, [col.replace('early_career', 'ec') for col in results.columns]))\n",
    "\n",
    "results.rename(new_cols, axis='columns', inplace=True)\n",
    "results.rename({'ec_coauthor_max_cit_3': 'ec_coauth_max_cit_3', 'ec_recognition_EC3_RC5':'ec_recog_EC3_RC5'}, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = feature_table2.transpose()\n",
    "results2.rename(new_cols, axis='columns', inplace=True)\n",
    "results2.rename({'ec_coauthor_max_cit_3': 'ec_coauth_max_cit_3', 'ec_recognition_EC3_RC5':'ec_recog_EC3_RC5'}, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results3 = feature_table3.transpose()\n",
    "results3.rename(new_cols, axis='columns', inplace=True)\n",
    "results3.rename({'ec_coauthor_max_cit_3': 'ec_coauth_max_cit_3', 'ec_recognition_EC3_RC5':'ec_recog_EC3_RC5', 'r2':'aoc_roc'}, axis='columns', inplace=True)\n",
    "results3.drop('adj_r2', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results\n",
    "# h index increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2\n",
    "# citation increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results3\n",
    "# coefficients are exponentiated\n",
    "# positive means bigger change to drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predictor diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_index = feature_table.transpose().copy()\n",
    "citations = feature_table2.transpose().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h_index['r2'], label='Increase H index')\n",
    "plt.plot(citations['r2'], label='Increase Citations')\n",
    "print(\"Average difference in r squared\", sum(citations['r2']-h_index['r2'])/len(h_index['r2']))\n",
    "# quality was used as a feature!\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gender diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender coefs\n",
    "plt.plot(results3['gender_m'], label=\"Male\")\n",
    "plt.plot(results3['gender_f'], label=\"Female\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results3['gender_m'] - results3['gender_f'], label=\"Male-Female diff\")\n",
    "plt.plot(results.index ,np.zeros(len(results)))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cohort size diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "# ax1.plot(results['r2'], label='r2')\n",
    "ax1.plot(results['adj_r2'], label='adjusted r2', color='C2')\n",
    "ax1.set_ylim([0,1])\n",
    "ax1.set_xlabel('Years')\n",
    "ax1.set_ylabel('R squared', color='C2')\n",
    "ax1.legend(loc=2)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(results['cohort_size'], label='Cohort size', color='C3')\n",
    "ax2.set_ylabel('Cohort size', color='C3')\n",
    "ax2.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cheating diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cheating = feature_table2.transpose().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheat_RC5 = feature_table2.transpose().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheat_quality = feature_table2.transpose().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does removing the quality affect the r squared?\n",
    "plt.plot(with_quality['adj_r2'], label='With quality')\n",
    "plt.plot(cheat_RC5['adj_r2'], label='With recognition year 5')\n",
    "plt.plot(no_cheating['adj_r2'], label='No cheating')\n",
    "print(\"Average difference in r squared\", sum(with_quality['adj_r2']-no_cheating['adj_r2'])/len(cheat_quality))\n",
    "print(np.mean)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "avg = sum(cheat_quality['adj_r2']-no_cheating['adj_r2'])/len(no_cheating)\n",
    "plt.plot(cheat_quality['adj_r2']-no_cheating['adj_r2'], label='Difference')\n",
    "plt.plot(no_cheating.index, [avg]*len(no_cheating), label='Average diff')\n",
    "plt.title(\"Difference between quality(15y) and recognition(3y)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scaler diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = feature_table2.transpose().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rob_scaler = feature_table2.transpose().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does changing the scaler affect the r squared?\n",
    "plt.plot(std_scaler['adj_r2'], label='Std')\n",
    "plt.plot(rob_scaler['adj_r2'], label='Rob')\n",
    "print(\"Average difference in r squared\", sum(std_scaler['adj_r2']-rob_scaler['adj_r2'])/len(rob_scaler))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# almost no difference\n",
    "\n",
    "avg = sum(std_scaler['adj_r2']-rob_scaler['adj_r2'])/len(std_scaler)\n",
    "plt.plot(std_scaler['adj_r2']-rob_scaler['adj_r2'], label='Difference')\n",
    "plt.plot(std_scaler.index, [avg]*len(std_scaler), label='Average diff')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_table3.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Best feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression, RFE, RFECV\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def show_kbest(data_frame, target, linear_rel=True, k=4):\n",
    "    \"\"\"\n",
    "    Selecting K-Best features for classification\n",
    "    :param data_frame: A pandas dataFrame with the training data\n",
    "    :param target: target variable name in DataFrame\n",
    "    :param k: desired number of features from the data\n",
    "    :returns feature_scores: scores for each feature in the data as \n",
    "    pandas DataFrame\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    if linear_rel == True: \n",
    "        feat_selector = SelectKBest(f_regression, k=k)\n",
    "        col_name = \"F Score\"\n",
    "    else:\n",
    "        feat_selector = SelectKBest(mutual_info_regression, k=k)\n",
    "        col_name = \"Mutual Information\"\n",
    "    \n",
    "    feat_selector = feat_selector.fit(data_frame, target)\n",
    "    feat_scores = pd.DataFrame()\n",
    "    feat_scores[col_name] = feat_selector.scores_\n",
    "    feat_scores[\"P Value\"] = feat_selector.pvalues_\n",
    "    feat_scores[\"Support\"] = feat_selector.get_support()\n",
    "    feat_scores[\"Attribute\"] = data_frame.columns\n",
    "    \n",
    "    return feat_scores \n",
    "\n",
    "def get_features_rfe(data_frame, target, model,k=5):\n",
    "    \"\"\"\n",
    "    Returns list of features (k specified) selected using RFE for\n",
    "    :param data_frame: A pandas dataFrame with features and labels\n",
    "    :param k: top k features to select  \n",
    "    :returns list: most relevant features \n",
    "    \"\"\"\n",
    "    X = data_frame\n",
    "    y = target\n",
    "    selector = RFE(model, k, step=1)\n",
    "    selector = selector.fit(X, y)\n",
    "#     print(selector.support_)\n",
    "    df = pd.DataFrame({\n",
    "        \"feature\": X.columns,\n",
    "        \"support\": selector.support_\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def get_features_rfecv(data_frame, target, model, cv=3):\n",
    "    \"\"\"\n",
    "    Returns list of features (k specified) selected using RFE for\n",
    "    :param data_frame: A pandas dataFrame with features and labels\n",
    "    :param k: top k features to select  \n",
    "    :returns list: most relevant features \n",
    "    \"\"\"\n",
    "    X = data_frame\n",
    "    y = target\n",
    "    selector = RFECV(model, step=1, cv=cv)\n",
    "    selector = selector.fit(X, y)\n",
    "#     print(selector.support_)\n",
    "    df = pd.DataFrame({\n",
    "        \"feature\": X.columns,\n",
    "        \"support\": selector.support_\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "years = credible_authors.start_year.unique()\n",
    "years = sorted(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = credible_authors.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "categorical_cols = ['gender']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df = df.join(pd.get_dummies(df[categorical_cols]))\n",
    "\n",
    "df.drop(categorical_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Show k best - F regression or mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "linear = True\n",
    "# true - fregression\n",
    "# false - mutual info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params = []\n",
    "for year in years:\n",
    "    df_year = df[df.start_year == year]\n",
    "    df_year = df_year.drop('start_year', axis=1)\n",
    "#     for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "#         for RECOGNITION_CUT in RECOGNITION_CUT_OFF_LIST:\n",
    "#             if RECOGNITION_CUT < EARLY_CAREER: continue\n",
    "    EARLY_CAREER = 3\n",
    "    RECOGNITION_CUT= 5\n",
    "    X_year = df_year[['max_absence-0-3', 'avg_absence-0-3', \n",
    "           'gender_f', 'gender_m', 'gender_none',\n",
    "           f'early_career_degree_{EARLY_CAREER}', \n",
    "           f'early_career_prod_{EARLY_CAREER}',\n",
    "           f'early_career_qual_{EARLY_CAREER}', f'early_career_recognition_EC{EARLY_CAREER}_RC{RECOGNITION_CUT}']]\n",
    "    y_year = df_year['succ_after_15y']\n",
    "    params.append(show_kbest(X_year, y_year, linear, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "selected_f = defaultdict(int)\n",
    "for param in params:\n",
    "    selected = param[param.Support == True]['Attribute'].values\n",
    "    selected_f['total'] += 1\n",
    "#     print(selected)\n",
    "    for select in selected:\n",
    "        selected_f[select] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "selected_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params_rfe = []\n",
    "for year in years:\n",
    "    df_year = df[df.start_year == year]\n",
    "    df_year = df_year.drop('start_year', axis=1)\n",
    "#     for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "#         for RECOGNITION_CUT in RECOGNITION_CUT_OFF_LIST:\n",
    "#             if RECOGNITION_CUT < EARLY_CAREER: continue\n",
    "    EARLY_CAREER = 3\n",
    "    RECOGNITION_CUT= 5\n",
    "    X_year = df_year[[\n",
    "        #'max_absence-0-3', 'avg_absence-0-3', \n",
    "           'gender_f', 'gender_m', 'gender_none',\n",
    "           f'early_career_degree_{EARLY_CAREER}', \n",
    "           f'early_career_prod_{EARLY_CAREER}',\n",
    "           f'early_career_qual_{EARLY_CAREER}', f'early_career_recognition_EC{EARLY_CAREER}_RC{RECOGNITION_CUT}']]\n",
    "    y_year = df_year['succ_after_15y']\n",
    "    params_rfe.append(get_features_rfe(X_year, y_year, LinearRegression(),k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "selected_f = defaultdict(int)\n",
    "for param in params_rfe:\n",
    "    selected = param[param.support == True]['feature'].values\n",
    "    selected_f['total'] += 1\n",
    "#     print(selected)\n",
    "    for select in selected:\n",
    "        selected_f[select] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "selected_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### RFE CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params_rfecv = []\n",
    "for year in years:\n",
    "    df_year = df[df.start_year == year]\n",
    "    df_year = df_year.drop('start_year', axis=1)\n",
    "#     for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "#         for RECOGNITION_CUT in RECOGNITION_CUT_OFF_LIST:\n",
    "#             if RECOGNITION_CUT < EARLY_CAREER: continue\n",
    "    EARLY_CAREER = 3\n",
    "    RECOGNITION_CUT= 5\n",
    "    X_year = df_year[['max_absence-0-3', 'avg_absence-0-3', \n",
    "           'gender_f', 'gender_m', 'gender_none',\n",
    "           f'early_career_degree_{EARLY_CAREER}', \n",
    "           f'early_career_prod_{EARLY_CAREER}',\n",
    "           f'early_career_qual_{EARLY_CAREER}', f'early_career_recognition_EC{EARLY_CAREER}_RC{RECOGNITION_CUT}']]\n",
    "    y_year = df_year['succ_after_15y']\n",
    "    params_rfecv.append(get_features_rfecv(X_year, y_year, LinearRegression(),cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "selected_f = defaultdict(int)\n",
    "for param in params_rfecv:\n",
    "    selected = param[param.support == True]['feature'].values\n",
    "    selected_f['total'] += 1\n",
    "#     print(selected)\n",
    "    for select in selected:\n",
    "        selected_f[select] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "selected_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations_per_year = pd.read_csv('derived-data/paper-citation-count.csv', header=None, names=['pub_id', 'cit_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publications = pd.read_csv('derived-data/author-publications.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# publications.sort_values(by='author').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove authors by career_len, and add start year\n",
    "publications = publications.merge(credible_authors[['author', 'start_year']], on='author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publications = publications[publications.year <= publications.year + MAX_CAREER_LEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# citations_per_year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publications['pub_id'] = shuffle(publications['pub_id']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# publications.sort_values(by='author').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publications = publications.merge(citations_per_year, on='pub_id', how='left')\n",
    "publications = publications.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publications.sort_values(by='author').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_authors[credible_authors.author == \"a min tjoa\"]['succ_after_15y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_authors.set_index('author', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_authors['succ_shuffled'] = publications.groupby('author')['cit_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_authors[['succ_shuffled', 'succ_after_15y']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_authors.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
