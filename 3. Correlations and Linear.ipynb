{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, ElasticNet, ElasticNetCV, Lasso, LogisticRegressionCV, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, f1_score, matthews_corrcoef\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAREER_LENGTH = 1\n",
    "\n",
    "#EARLY_CAREER_LEN_LIST = [1, 2, 3, 4, 5]\n",
    "EARLY_CAREER_LEN_LIST = [3]\n",
    "EARLY_CAREER = 3\n",
    "#RECOGNITION_CUT_OFF_LIST = [3, 4, 5, 6, 7, 8, 9]\n",
    "RECOGNITION_CUT_OFF_LIST = [3]\n",
    "RECOGNITION_CUT = 3\n",
    "\n",
    "MAX_CAREER_LEN = 15\n",
    "END_YEAR = 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1699352, 71)\n"
     ]
    }
   ],
   "source": [
    "credible_authors = pd.read_csv('derived-data/authors-scientific-extended.csv')\n",
    "print(credible_authors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = sorted(credible_authors.start_year.unique())\n",
    "COHORT_START_YEARS = [y for y in years if y < (END_YEAR - MAX_CAREER_LEN)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "#credible_authors.columns\n",
    "#print(credible_authors.groupby(\"start_year\")['dropped_after_10'].agg('sum'))\n",
    "#print(credible_authors.groupby(\"start_year\")['author'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1699352, 71)\n",
      "1\n",
      "[2001 2009 2011 1992 2017 2002 2003 2010 2008 1979 2007 1995 2016 2015\n",
      " 1986 2005 2012 1998 2006 2013 1999 1980 2014 1988 1996 1970 2004 1994\n",
      " 1997 1987 1982 2000 1990 1989 1985 1974 1977 1993 1991 1975 1984 1983\n",
      " 1973 1972 1971 1981 1978 1976 2018]\n",
      "(292659, 71)\n",
      "[1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000]\n"
     ]
    }
   ],
   "source": [
    "credible_authors = credible_authors[credible_authors.career_length >= CAREER_LENGTH]\n",
    "print(credible_authors.shape)\n",
    "print(CAREER_LENGTH)\n",
    "print(credible_authors.start_year.unique())\n",
    "\n",
    "credible_authors = credible_authors[credible_authors.start_year.isin(COHORT_START_YEARS)]\n",
    "\n",
    "print(credible_authors.shape)\n",
    "print(COHORT_START_YEARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author', 'start_year', 'end_year', 'total_num_pub', 'career_length',\n",
       "       'max_absence-0-15', 'avg_absence-0-15', 'dropped_after_10', 'gender',\n",
       "       'h5_index_max_3', 'deciles_min_3', 'quantiles_min_3', 'quantiles_bin_3',\n",
       "       'h5_index_max_5', 'deciles_min_5', 'quantiles_min_5', 'quantiles_bin_5',\n",
       "       'h5_index_max_7', 'deciles_min_7', 'quantiles_min_7', 'quantiles_bin_7',\n",
       "       'h5_index_max_9', 'deciles_min_9', 'quantiles_min_9', 'quantiles_bin_9',\n",
       "       'h5_index_max_11', 'deciles_min_11', 'quantiles_min_11',\n",
       "       'quantiles_bin_11', 'h5_index_max_12', 'deciles_min_12',\n",
       "       'quantiles_min_12', 'quantiles_bin_12', 'early_career_degree_3',\n",
       "       'early_career_degree_5', 'early_career_degree_7',\n",
       "       'early_career_degree_9', 'early_career_degree_11',\n",
       "       'early_career_degree_12', 'early_career_qual_3', 'early_career_qual_5',\n",
       "       'early_career_qual_7', 'early_career_qual_9', 'early_career_qual_11',\n",
       "       'early_career_qual_12', 'early_career_recognition_EC3_RC3',\n",
       "       'early_career_recognition_EC5_RC5', 'early_career_recognition_EC7_RC7',\n",
       "       'early_career_recognition_EC9_RC9',\n",
       "       'early_career_recognition_EC11_RC11',\n",
       "       'early_career_recognition_EC12_RC12', 'succ_after_15y', 'h-index_3',\n",
       "       'h-index_5', 'h-index_7', 'h-index_9', 'h-index_11', 'h-index_12',\n",
       "       'h-index_15', 'early_career_prod_3', 'early_career_prod_5',\n",
       "       'early_career_prod_7', 'early_career_prod_9', 'early_career_prod_11',\n",
       "       'early_career_prod_12', 'early_career_coauthor_max_hindex_3',\n",
       "       'early_career_coauthor_max_hindex_5',\n",
       "       'early_career_coauthor_max_hindex_7',\n",
       "       'early_career_coauthor_max_hindex_9',\n",
       "       'early_career_coauthor_max_hindex_11',\n",
       "       'early_career_coauthor_max_hindex_12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credible_authors.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO move this to 0.\n",
    "EARLY_CAREER_LEN_LIST_EXT = [3,5,7,9,11,12]\n",
    "RECOGNITION_CUT_OFF_LIST_EXT = [3,5,7,9,11,12]\n",
    "EARLY_CAREER_LEN_LIST_EXT = [3]\n",
    "RECOGNITION_CUT_OFF_LIST_EXT = [3]\n",
    "\n",
    "for year in EARLY_CAREER_LEN_LIST_EXT:\n",
    "    credible_authors[f'citation_increase_15_{year}'] = credible_authors['succ_after_15y'] - credible_authors[\n",
    "        f'early_career_recognition_EC{year}_RC{year}']\n",
    "    credible_authors[f'h_index_increase_15_{year}'] = credible_authors['h-index_15'] - credible_authors[f'h-index_{year}']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols = ['succ_after_15y', 'h_index_increase_15_3', 'citation_increase_15_3', 'max_absence-0-15', \n",
    "        'early_career_prod_3', 'early_career_degree_3', 'early_career_coauthor_max_hindex_12', \n",
    "        'early_career_recognition_EC3_RC3', 'early_career_qual_12']\n",
    "\n",
    "col_names_short = ['succ', 'hindex_incr', 'cit_incr', 'max_abs', \n",
    "        'prod_3', 'degree_3', 'maxh_3', \n",
    "        'rec_3', 'qual_3']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cor_qual = credible_authors[cols].corr(method='kendall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>succ_after_15y</th>\n",
       "      <th>h_index_increase_15_3</th>\n",
       "      <th>citation_increase_15_3</th>\n",
       "      <th>max_absence-0-15</th>\n",
       "      <th>early_career_prod_3</th>\n",
       "      <th>early_career_degree_3</th>\n",
       "      <th>early_career_coauthor_max_hindex_12</th>\n",
       "      <th>early_career_recognition_EC3_RC3</th>\n",
       "      <th>early_career_qual_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>succ_after_15y</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.644757</td>\n",
       "      <td>0.960224</td>\n",
       "      <td>-0.542337</td>\n",
       "      <td>0.477676</td>\n",
       "      <td>0.413726</td>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.502084</td>\n",
       "      <td>0.982328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_index_increase_15_3</th>\n",
       "      <td>0.644757</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.686337</td>\n",
       "      <td>-0.666190</td>\n",
       "      <td>0.502945</td>\n",
       "      <td>0.280664</td>\n",
       "      <td>0.509254</td>\n",
       "      <td>0.111535</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citation_increase_15_3</th>\n",
       "      <td>0.960224</td>\n",
       "      <td>0.686337</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.557741</td>\n",
       "      <td>0.474961</td>\n",
       "      <td>0.389224</td>\n",
       "      <td>0.571958</td>\n",
       "      <td>0.435173</td>\n",
       "      <td>0.942939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_absence-0-15</th>\n",
       "      <td>-0.542337</td>\n",
       "      <td>-0.666190</td>\n",
       "      <td>-0.557741</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.555907</td>\n",
       "      <td>-0.187729</td>\n",
       "      <td>-0.455013</td>\n",
       "      <td>-0.203186</td>\n",
       "      <td>-0.529727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>early_career_prod_3</th>\n",
       "      <td>0.477676</td>\n",
       "      <td>0.502945</td>\n",
       "      <td>0.474961</td>\n",
       "      <td>-0.555907</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.322134</td>\n",
       "      <td>0.401059</td>\n",
       "      <td>0.349846</td>\n",
       "      <td>0.478984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>early_career_degree_3</th>\n",
       "      <td>0.413726</td>\n",
       "      <td>0.280664</td>\n",
       "      <td>0.389224</td>\n",
       "      <td>-0.187729</td>\n",
       "      <td>0.322134</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.405335</td>\n",
       "      <td>0.435229</td>\n",
       "      <td>0.420423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>early_career_coauthor_max_hindex_12</th>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.509254</td>\n",
       "      <td>0.571958</td>\n",
       "      <td>-0.455013</td>\n",
       "      <td>0.401059</td>\n",
       "      <td>0.405335</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.374420</td>\n",
       "      <td>0.580100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>early_career_recognition_EC3_RC3</th>\n",
       "      <td>0.502084</td>\n",
       "      <td>0.111535</td>\n",
       "      <td>0.435173</td>\n",
       "      <td>-0.203186</td>\n",
       "      <td>0.349846</td>\n",
       "      <td>0.435229</td>\n",
       "      <td>0.374420</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.509829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>early_career_qual_12</th>\n",
       "      <td>0.982328</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.942939</td>\n",
       "      <td>-0.529727</td>\n",
       "      <td>0.478984</td>\n",
       "      <td>0.420423</td>\n",
       "      <td>0.580100</td>\n",
       "      <td>0.509829</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     succ_after_15y  h_index_increase_15_3  \\\n",
       "succ_after_15y                             1.000000               0.644757   \n",
       "h_index_increase_15_3                      0.644757               1.000000   \n",
       "citation_increase_15_3                     0.960224               0.686337   \n",
       "max_absence-0-15                          -0.542337              -0.666190   \n",
       "early_career_prod_3                        0.477676               0.502945   \n",
       "early_career_degree_3                      0.413726               0.280664   \n",
       "early_career_coauthor_max_hindex_12        0.579609               0.509254   \n",
       "early_career_recognition_EC3_RC3           0.502084               0.111535   \n",
       "early_career_qual_12                       0.982328               0.631579   \n",
       "\n",
       "                                     citation_increase_15_3  max_absence-0-15  \\\n",
       "succ_after_15y                                     0.960224         -0.542337   \n",
       "h_index_increase_15_3                              0.686337         -0.666190   \n",
       "citation_increase_15_3                             1.000000         -0.557741   \n",
       "max_absence-0-15                                  -0.557741          1.000000   \n",
       "early_career_prod_3                                0.474961         -0.555907   \n",
       "early_career_degree_3                              0.389224         -0.187729   \n",
       "early_career_coauthor_max_hindex_12                0.571958         -0.455013   \n",
       "early_career_recognition_EC3_RC3                   0.435173         -0.203186   \n",
       "early_career_qual_12                               0.942939         -0.529727   \n",
       "\n",
       "                                     early_career_prod_3  \\\n",
       "succ_after_15y                                  0.477676   \n",
       "h_index_increase_15_3                           0.502945   \n",
       "citation_increase_15_3                          0.474961   \n",
       "max_absence-0-15                               -0.555907   \n",
       "early_career_prod_3                             1.000000   \n",
       "early_career_degree_3                           0.322134   \n",
       "early_career_coauthor_max_hindex_12             0.401059   \n",
       "early_career_recognition_EC3_RC3                0.349846   \n",
       "early_career_qual_12                            0.478984   \n",
       "\n",
       "                                     early_career_degree_3  \\\n",
       "succ_after_15y                                    0.413726   \n",
       "h_index_increase_15_3                             0.280664   \n",
       "citation_increase_15_3                            0.389224   \n",
       "max_absence-0-15                                 -0.187729   \n",
       "early_career_prod_3                               0.322134   \n",
       "early_career_degree_3                             1.000000   \n",
       "early_career_coauthor_max_hindex_12               0.405335   \n",
       "early_career_recognition_EC3_RC3                  0.435229   \n",
       "early_career_qual_12                              0.420423   \n",
       "\n",
       "                                     early_career_coauthor_max_hindex_12  \\\n",
       "succ_after_15y                                                  0.579609   \n",
       "h_index_increase_15_3                                           0.509254   \n",
       "citation_increase_15_3                                          0.571958   \n",
       "max_absence-0-15                                               -0.455013   \n",
       "early_career_prod_3                                             0.401059   \n",
       "early_career_degree_3                                           0.405335   \n",
       "early_career_coauthor_max_hindex_12                             1.000000   \n",
       "early_career_recognition_EC3_RC3                                0.374420   \n",
       "early_career_qual_12                                            0.580100   \n",
       "\n",
       "                                     early_career_recognition_EC3_RC3  \\\n",
       "succ_after_15y                                               0.502084   \n",
       "h_index_increase_15_3                                        0.111535   \n",
       "citation_increase_15_3                                       0.435173   \n",
       "max_absence-0-15                                            -0.203186   \n",
       "early_career_prod_3                                          0.349846   \n",
       "early_career_degree_3                                        0.435229   \n",
       "early_career_coauthor_max_hindex_12                          0.374420   \n",
       "early_career_recognition_EC3_RC3                             1.000000   \n",
       "early_career_qual_12                                         0.509829   \n",
       "\n",
       "                                     early_career_qual_12  \n",
       "succ_after_15y                                   0.982328  \n",
       "h_index_increase_15_3                            0.631579  \n",
       "citation_increase_15_3                           0.942939  \n",
       "max_absence-0-15                                -0.529727  \n",
       "early_career_prod_3                              0.478984  \n",
       "early_career_degree_3                            0.420423  \n",
       "early_career_coauthor_max_hindex_12              0.580100  \n",
       "early_career_recognition_EC3_RC3                 0.509829  \n",
       "early_career_qual_12                             1.000000  "
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor_qual\n",
    "#cor_qual['succ_after_15y'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cor_qual, vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,9,1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(col_names_short, rotation=45)\n",
    "ax.set_yticklabels(col_names_short)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#cor = credible_authors.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#cor_qual[f'h_index_increase_15_{EARLY_CAREER}'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sns.heatmap(cor, center=0,\n",
    "#             square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test different predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# test different early career lenghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "year = 1995\n",
    "\n",
    "credible_authors_1991 = credible_authors[credible_authors.start_year == year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = credible_authors_1991.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "categorical_cols = ['gender']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    X = X.join(pd.get_dummies(X[categorical_cols]))\n",
    "\n",
    "X.drop(categorical_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def run_linear(func, name):\n",
    "    df = pd.DataFrame(columns=['params', f'r_squared_{name}'])\n",
    "    for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "        for RECOGNITION_CUT in RECOGNITION_CUT_OFF_LIST:\n",
    "            if RECOGNITION_CUT < EARLY_CAREER: continue\n",
    "            H = X[[\n",
    "                #'max_absence-0-3', 'avg_absence-0-3',\n",
    "                   'gender_f', 'gender_m', 'gender_none',\n",
    "                   f'early_career_degree_{EARLY_CAREER}', \n",
    "                   f'early_career_prod_{EARLY_CAREER}',\n",
    "                   f'early_career_qual_{EARLY_CAREER}', f'early_career_recognition_EC{EARLY_CAREER}_RC{RECOGNITION_CUT}']]\n",
    "            reg = func.fit(H, y)\n",
    "            df = df.append({'params': f'EC:{EARLY_CAREER},REC:{RECOGNITION_CUT}',\n",
    "                            f'r_squared_{name}': reg.score(H, y)}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def run_cv(func, name, cv, y_col='succ_after_15y'):\n",
    "    df = pd.DataFrame(columns=['params', f'r_squared_{name}'])\n",
    "    for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "        for RECOGNITION_CUT in RECOGNITION_CUT_OFF_LIST:\n",
    "            if RECOGNITION_CUT < EARLY_CAREER: continue\n",
    "            H = X[[\n",
    "                #'max_absence-0-3', 'avg_absence-0-3',\n",
    "                   'gender_f', 'gender_m', 'gender_none',\n",
    "                   f'early_career_degree_{EARLY_CAREER}', \n",
    "                   f'early_career_prod_{EARLY_CAREER}',\n",
    "                   f'early_career_qual_{EARLY_CAREER}', f'early_career_recognition_EC{EARLY_CAREER}_RC{RECOGNITION_CUT}']]\n",
    "            y = X[y_col]\n",
    "            score = np.mean(cross_val_score(func, H, y, cv=cv, scoring='r2'))\n",
    "            df = df.append({'params': f'EC:{EARLY_CAREER},REC:{RECOGNITION_CUT}',\n",
    "                            f'r_squared_{name}': score}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1 = run_cv(LinearRegression(), 'linear', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# df1_null = run_cv(LinearRegression(), 'linear_null', cv=3, y_col='succ_shuffled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2 = run_cv(ElasticNet(), 'elastic', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df3 = run_cv(ElasticNetCV(cv=3), 'elastic_CV', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df4 = run_cv(Lasso(alpha=0.1), 'lasso', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Decision tree overfits pretty bad. Maybe GridParam Search?\n",
    "df5 = run_cv(DecisionTreeRegressor(), 'tree', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df6 = run_cv(RandomForestRegressor(), 'forest', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# df6_null = run_cv(RandomForestRegressor(), 'forest_null', cv=3, y_col='succ_shuffled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfs = [df1, df2, df3, df4, df5, df6] #df1_null, df6_null\n",
    "for df_ in dfs: df_.set_index('params', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r_squared_linear</th>\n",
       "      <th>r_squared_elastic</th>\n",
       "      <th>r_squared_elastic_CV</th>\n",
       "      <th>r_squared_lasso</th>\n",
       "      <th>r_squared_tree</th>\n",
       "      <th>r_squared_forest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EC:3,REC:3</th>\n",
       "      <td>0.37799</td>\n",
       "      <td>0.377128</td>\n",
       "      <td>0.348738</td>\n",
       "      <td>0.378011</td>\n",
       "      <td>-0.297421</td>\n",
       "      <td>0.035995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            r_squared_linear  r_squared_elastic  r_squared_elastic_CV  \\\n",
       "params                                                                  \n",
       "EC:3,REC:3           0.37799           0.377128              0.348738   \n",
       "\n",
       "            r_squared_lasso  r_squared_tree  r_squared_forest  \n",
       "params                                                         \n",
       "EC:3,REC:3         0.378011       -0.297421          0.035995  "
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0].join(dfs[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EARLY_CAREER = EARLY_CAREER_LEN_LIST[0]\n",
    "# RECOGNITION_CUT = RECOGNITION_CUT_OFF_LIST[0]\n",
    "EARLY_CAREER_LEN_LIST = [3,5,7,9,11,12]\n",
    "RECOGNITION_CUT_OFF_LIST = [3,5,7,9,11,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,RobustScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,0,1]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [-1.],\n",
       "       [ 0.],\n",
       "       [-1.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RobustScaler().fit_transform(np.array([1,0,1,0,1]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [-2.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RobustScaler().fit_transform(np.array([1,0,1]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_percent = credible_authors.groupby('start_year')['dropped_after_10'].sum() / credible_authors.groupby('start_year')['dropped_after_10'].count()\n",
    "dropped_percent = dropped_percent.to_frame().T\n",
    "\n",
    "dropped_percent_agg = credible_authors['dropped_after_10'].sum() / credible_authors['dropped_after_10'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 groups of features: productivity, social capital, quality/rec and gender\n",
    "def make_cols_lists(INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC, INCLUDE_QUALITY, INCLUDE_GENDER, REMOVE_NONE_AUTHORS, \n",
    "                    INCLUDE_VENUE, EARLY_CAREER, RECOGNITION_CUT, INCLUDE_YEAR, dep_var):\n",
    "    categorical_cols = []\n",
    "    cols_std = []\n",
    "\n",
    "    if(INCLUDE_YEAR):\n",
    "        cols_std.append(\"start_year\")\n",
    "        \n",
    "    #scale dependant var\n",
    "    if dep_var == \"dropped_after_10\":\n",
    "        categorical_cols.append(dep_var)\n",
    "    else:\n",
    "        cols_std.append(dep_var)\n",
    "\n",
    "    if(INCLUDE_PROD):\n",
    "        cols_std.append(f'early_career_prod_{EARLY_CAREER}')\n",
    "\n",
    "    if(INCLUDE_SOCIAL):\n",
    "        cols_std.append(f'early_career_degree_{EARLY_CAREER}')\n",
    "        cols_std.append(f'early_career_coauthor_max_hindex_{EARLY_CAREER}')\n",
    "    #     cols_std.append(f'early_career_coauthor_max_cit_{EARLY_CAREER}')\n",
    "\n",
    "    if(INCLUDE_REC):\n",
    "        cols_std.append(f'early_career_recognition_EC{EARLY_CAREER}_RC{RECOGNITION_CUT}')\n",
    "\n",
    "    if(INCLUDE_QUALITY):\n",
    "        cols_std.append(f'early_career_qual_{EARLY_CAREER}')\n",
    "\n",
    "    if(INCLUDE_GENDER):\n",
    "        categorical_cols.append('gender')\n",
    "\n",
    "    if(INCLUDE_VENUE):\n",
    "        cols_std.extend(['quantiles_bin_3']) #'deciles_min_3''quantiles_min_3', 'quantiles_bin_3'\n",
    "    \n",
    "    return cols_std, categorical_cols #cols_all, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO we scale data every time we train. Modify to keep data and add remove parameters. Somehow separate the prep from train\n",
    "def scale_columns(X):\n",
    "    if len(X.columns) > 0:\n",
    "        standardized_cols = StandardScaler().fit_transform(X)\n",
    "    else: \n",
    "        standardized_cols = []\n",
    "    return pd.DataFrame(standardized_cols, index=X.index, columns=X.columns)\n",
    "\n",
    "def prepare_data(credible_authors, cols_std, categorical_cols):\n",
    "    X = credible_authors[credible_authors.start_year.isin(COHORT_START_YEARS)].copy()\n",
    "    \n",
    "    # Either scale OR INCLUDE start_year as control Var\n",
    "    # scale dependent variables per year --> WE SHOULD ALSO SCALE OUTCOME VAR\n",
    "#     for year in COHORT_START_YEARS:\n",
    "#         X.loc[X.start_year == year, cols_std] = scale_columns(X.loc[X.start_year == year, cols_std])\n",
    "#     scale over whole dataset\n",
    "#     X[cols_std] = scale_columns(X[cols_std])\n",
    "    \n",
    "    # make dummies of categorical cols\n",
    "    if(len(categorical_cols)>0):\n",
    "        cat_cols = pd.get_dummies(X[categorical_cols]) \n",
    "        X = X[cols_std].join(cat_cols)\n",
    "    else:\n",
    "        X = X[cols_std]\n",
    "    if(REMOVE_NONE_AUTHORS):\n",
    "        X.drop('gender_none' , axis=1)\n",
    "    X['start_year'] = credible_authors['start_year']\n",
    "    return X\n",
    "\n",
    "def run_elastic_net_aggr(credible_authors, cols_std, categorical_cols, INCLUDE_YEAR, dep_var):\n",
    "    X = prepare_data(credible_authors, cols_std, categorical_cols)\n",
    "    Y = X[dep_var].copy()\n",
    "    X = X.drop(dep_var, axis=1)\n",
    "#     Y = credible_authors[dep_var]\n",
    "   \n",
    "    if (not INCLUDE_YEAR):\n",
    "        X = X.drop('start_year' , axis=1)\n",
    "#     else:\n",
    "        # Robust scaler seems to be a poor choice here. Maybe minmax?\n",
    "#         X['start_year'] = MinMaxScaler().fit_transform(X['start_year'].to_frame())\n",
    "    \n",
    "   \n",
    "    feat_table = run_elastic_net(X, Y)\n",
    "    feat_table = feat_table.set_index(0)\n",
    "    \n",
    "    if(dep_var == 'dropped_after_10'): \n",
    "        feat_table = feat_table.append(pd.DataFrame(index=['drop_percentage'], data=[dropped_percent_agg], columns=[1]))\n",
    "    return feat_table\n",
    "\n",
    "def run_elastic_net_cohort(credible_authors, cols_std, categorical_cols, dep_var):\n",
    "    table_list = []\n",
    "    X = prepare_data(credible_authors, cols_std, categorical_cols)\n",
    "    for year in COHORT_START_YEARS:\n",
    "        X_year = X[X.start_year == year]\n",
    "#         y_year = credible_authors[credible_authors.start_year == year][dep_var]\n",
    "        y_year = X_year[dep_var].copy()\n",
    "        X_year = X_year.drop(dep_var, axis=1)\n",
    "        \n",
    "        feat_data = run_elastic_net(X_year.drop('start_year', axis=1), y_year)\n",
    "        feat_data = feat_data.set_index(0)\n",
    "        feat_data.rename(index=str, columns={1: year}, inplace=True)\n",
    "        table_list.append(feat_data)\n",
    "       \n",
    "    table = pd.DataFrame(index=table_list[0].index)\n",
    "    for x in table_list: table=table.join(x)\n",
    "    if(dep_var == 'dropped_after_10'): table = table.append(dropped_percent)\n",
    "    return table\n",
    "\n",
    "def run_elastic_net(X, y):\n",
    "    # train model and do cross validation\n",
    "\n",
    "    # add dummy var if no features are given\n",
    "    if (X.empty):\n",
    "        X = pd.DataFrame(1, index=np.arange(len(y)), columns=[\"dummy\"])\n",
    "    \n",
    "    \n",
    "    if(y.nunique()==2):   \n",
    "        y = y.astype(int)\n",
    "        #f1, average_precision, roc_auc\n",
    "        cv_dict = cross_validate(LogisticRegressionCV(cv=10, penalty='l2'), X, y, scoring=\"average_precision\", cv=10, \n",
    "                                 return_estimator=True, return_train_score=False)\n",
    "        net_coef = pd.DataFrame([es.coef_[0] for es in cv_dict['estimator']], columns=X.columns)\n",
    "#         print(cv_dict)\n",
    "        score = np.mean(cv_dict['test_score'])\n",
    "        score2 = None\n",
    "    else:\n",
    "        cv_dict = cross_validate(ElasticNetCV(cv=10), X, y, scoring=['r2', 'neg_mean_squared_error'], cv=10, return_estimator=True, return_train_score=False)\n",
    "        net_coef = pd.DataFrame([es.coef_ for es in cv_dict['estimator']], columns=X.columns)\n",
    "        score = np.mean(cv_dict['test_r2'])\n",
    "        score2 = np.mean(cv_dict['test_neg_mean_squared_error'])\n",
    "\n",
    "    # save the intercepts\n",
    "    net_intercept = np.mean([es.intercept_ for es in cv_dict['estimator']])\n",
    "    # take the mean and std from coefs\n",
    "    net_coef_mean = net_coef.mean()\n",
    "    net_coef_std = net_coef.std()\n",
    "    rounding = 2\n",
    "    net_coef_mean_std = list(zip(np.round(net_coef_mean.values,rounding), np.round(net_coef_std.values,rounding)))\n",
    "    net_coef_mean_std = [f\"{x[0]}({x[1]})\" for x in net_coef_mean_std]\n",
    "\n",
    "    cohort_size = len(y)\n",
    "    #     num_nonzero_coefs = sum(net2.coef_ != 0)\n",
    "    #     adj_score2 = 1 - (1-score2)*(cohort_size-1)/(cohort_size-num_nonzero_coefs-1)\n",
    "    if score2:\n",
    "        net_coef_mean_std.extend([np.round(net_intercept, rounding), np.round(score, rounding), np.round(score2, rounding), cohort_size])\n",
    "        feat_table = pd.DataFrame(list(zip(np.append(X.columns, ['intercept', 'r2', 'neg_mean_squared_error', 'cohort_size']), net_coef_mean_std)))\n",
    "    else:\n",
    "        net_coef_mean_std.extend([np.round(net_intercept, rounding), np.round(score, rounding), cohort_size])\n",
    "        feat_table = pd.DataFrame(list(zip(np.append(X.columns, ['intercept', 'avg_precision', 'cohort_size']), net_coef_mean_std)))\n",
    "    return feat_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Stuff that we potentially use as outcome Vars\n",
    "# dv_hindex = 'h-index_15'\n",
    "# dv_citations = 'succ_after_15y'\n",
    "\n",
    "dv_hindex_incr = f'h_index_increase_15_{EARLY_CAREER}'\n",
    "dv_citations_incr = f'citation_increase_15_{EARLY_CAREER}'\n",
    "dv_dropped = 'dropped_after_10'\n",
    "\n",
    "DV = dv_dropped\n",
    "\n",
    "# check if outcome vars are plausible\n",
    "# #print(credible_authors.columns)\n",
    "# credible_authors[[\"start_year\", \"succ_after_15y\"]].groupby(\"start_year\").mean().plot()\n",
    "# credible_authors[[\"start_year\", \"h_index_increase_15_3\"]].groupby(\"start_year\").mean().plot()\n",
    "# credible_authors[[\"start_year\", \"citation_increase_15_3\"]].groupby(\"start_year\").mean().plot()\n",
    "# credible_authors[[\"start_year\", \"avg_absence-0-15\"]].groupby(\"start_year\").mean().plot()\n",
    "# credible_authors[[\"start_year\", \"dropped_after_10\"]].groupby(\"start_year\").mean().plot()\n",
    "# credible_authors[[\"start_year\", \"total_num_pub\"]].groupby(\"start_year\").mean().plot()\n",
    "# credible_authors[[\"start_year\", \"career_length\"]].groupby(\"start_year\").mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped_after_10\n"
     ]
    }
   ],
   "source": [
    "INCLUDE_PROD = 0\n",
    "INCLUDE_SOCIAL = 0\n",
    "INCLUDE_REC = 0\n",
    "INCLUDE_QUALITY = 0\n",
    "INCLUDE_GENDER = 0\n",
    "REMOVE_NONE_AUTHORS = 0\n",
    "INCLUDE_VENUE = 0\n",
    "INCLUDE_YEAR = 1\n",
    "cols_std, categorical_cols = make_cols_lists(INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC, INCLUDE_QUALITY, INCLUDE_GENDER, \n",
    "                                             REMOVE_NONE_AUTHORS, INCLUDE_VENUE, EARLY_CAREER, RECOGNITION_CUT, INCLUDE_YEAR, DV)\n",
    "print(DV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_baseline = run_elastic_net_cohort(credible_authors, cols_std, categorical_cols, DV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_baseline_agg = run_elastic_net_aggr(credible_authors, cols_std, categorical_cols,INCLUDE_YEAR, DV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        1\n",
      "start_year       0.0(0.0)\n",
      "intercept               0\n",
      "avg_precision        0.62\n",
      "cohort_size        292659\n",
      "drop_percentage  0.631988\n"
     ]
    }
   ],
   "source": [
    "print(res_baseline_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Human Capital Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "INCLUDE_PROD = 1\n",
    "INCLUDE_SOCIAL = 0\n",
    "INCLUDE_REC = 1\n",
    "INCLUDE_QUALITY = 0\n",
    "INCLUDE_GENDER = 0\n",
    "REMOVE_NONE_AUTHORS = 0\n",
    "INCLUDE_VENUE = 0\n",
    "INCLUDE_YEAR = 1\n",
    "cols_std, categorical_cols = make_cols_lists(INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC, INCLUDE_QUALITY, INCLUDE_GENDER, \n",
    "                                             REMOVE_NONE_AUTHORS, INCLUDE_VENUE, EARLY_CAREER, RECOGNITION_CUT, INCLUDE_YEAR, DV)\n",
    "\n",
    "# res_hum_cap = run_elastic_net_cohort(credible_authors, cols_std, categorical_cols, DV)\n",
    "res_hum_cap_agg = run_elastic_net_aggr(credible_authors, cols_std, categorical_cols,INCLUDE_YEAR, DV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            1\n",
      "start_year                           0.0(0.0)\n",
      "early_career_prod_3               -0.67(0.01)\n",
      "early_career_recognition_EC3_RC3    0.02(0.0)\n",
      "intercept                                   0\n",
      "avg_precision                            0.78\n",
      "cohort_size                            292659\n",
      "drop_percentage                      0.631988\n"
     ]
    }
   ],
   "source": [
    "print(res_hum_cap_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped_after_10\n"
     ]
    }
   ],
   "source": [
    "INCLUDE_PROD = 1\n",
    "INCLUDE_SOCIAL = 0\n",
    "INCLUDE_REC = 1\n",
    "INCLUDE_GENDER = 1\n",
    "INCLUDE_QUALITY = 0\n",
    "REMOVE_NONE_AUTHORS = 0\n",
    "INCLUDE_VENUE = 0\n",
    "INCLUDE_YEAR = 1\n",
    "cols_std, categorical_cols = make_cols_lists(INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC, INCLUDE_QUALITY, INCLUDE_GENDER, \n",
    "                                             REMOVE_NONE_AUTHORS, INCLUDE_VENUE, EARLY_CAREER, RECOGNITION_CUT, INCLUDE_YEAR, DV)\n",
    "print(DV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_gender = run_elastic_net_cohort(credible_authors, cols_std, categorical_cols, DV)\n",
    "res_gender_agg = run_elastic_net_aggr(credible_authors, cols_std, categorical_cols,INCLUDE_YEAR, DV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            1\n",
      "start_year                           0.0(0.0)\n",
      "early_career_prod_3               -0.67(0.01)\n",
      "early_career_recognition_EC3_RC3    0.02(0.0)\n",
      "gender_f                           0.03(0.01)\n",
      "gender_m                          -0.05(0.01)\n",
      "gender_none                        0.01(0.01)\n",
      "intercept                                   0\n",
      "avg_precision                            0.79\n",
      "cohort_size                            292659\n",
      "drop_percentage                      0.631988\n"
     ]
    }
   ],
   "source": [
    "print(res_gender_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Social Capital Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped_after_10\n"
     ]
    }
   ],
   "source": [
    "INCLUDE_PROD = 1\n",
    "INCLUDE_SOCIAL = 1\n",
    "INCLUDE_REC = 1\n",
    "INCLUDE_GENDER = 1\n",
    "INCLUDE_QUALITY = 0\n",
    "REMOVE_NONE_AUTHORS = 0\n",
    "INCLUDE_VENUE = 0\n",
    "INCLUDE_YEAR = 1\n",
    "cols_std, categorical_cols = make_cols_lists(INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC, INCLUDE_QUALITY, INCLUDE_GENDER, \n",
    "                                             REMOVE_NONE_AUTHORS, INCLUDE_VENUE, EARLY_CAREER, RECOGNITION_CUT, INCLUDE_YEAR, DV)\n",
    "print(DV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# res_social = run_elastic_net_cohort(credible_authors, cols_std, categorical_cols, DV)\n",
    "res_social_agg = run_elastic_net_aggr(credible_authors, cols_std, categorical_cols,INCLUDE_YEAR, DV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              1\n",
      "start_year                             0.0(0.0)\n",
      "early_career_prod_3                  -0.68(0.0)\n",
      "early_career_degree_3                 0.03(0.0)\n",
      "early_career_coauthor_max_hindex_3   -0.01(0.0)\n",
      "early_career_recognition_EC3_RC3      0.01(0.0)\n",
      "gender_f                             0.03(0.01)\n",
      "gender_m                            -0.05(0.01)\n",
      "gender_none                          0.01(0.01)\n",
      "intercept                                     0\n",
      "avg_precision                              0.79\n",
      "cohort_size                              292659\n",
      "drop_percentage                        0.631988\n"
     ]
    }
   ],
   "source": [
    "print(res_social_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symbolic Capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped_after_10\n"
     ]
    }
   ],
   "source": [
    "INCLUDE_PROD = 1\n",
    "INCLUDE_SOCIAL = 1\n",
    "INCLUDE_REC = 1\n",
    "INCLUDE_GENDER = 1\n",
    "INCLUDE_QUALITY = 0\n",
    "REMOVE_NONE_AUTHORS = 0\n",
    "INCLUDE_VENUE = 1\n",
    "INCLUDE_YEAR = 1\n",
    "cols_std, categorical_cols = make_cols_lists(INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC, INCLUDE_QUALITY, INCLUDE_GENDER, \n",
    "                                             REMOVE_NONE_AUTHORS, INCLUDE_VENUE, EARLY_CAREER, RECOGNITION_CUT, INCLUDE_YEAR, DV)\n",
    "\n",
    "print(DV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# res_symbolic = run_elastic_net_cohort(credible_authors, cols_std, categorical_cols, DV)\n",
    "res_symbolic_agg = run_elastic_net_aggr(credible_authors, cols_std, categorical_cols,INCLUDE_YEAR, DV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              1\n",
      "start_year                             0.0(0.0)\n",
      "early_career_prod_3                 -0.68(0.01)\n",
      "early_career_degree_3                 0.04(0.0)\n",
      "early_career_coauthor_max_hindex_3    -0.0(0.0)\n",
      "early_career_recognition_EC3_RC3      0.02(0.0)\n",
      "quantiles_bin_3                     -0.33(0.04)\n",
      "gender_f                             0.06(0.01)\n",
      "gender_m                            -0.06(0.02)\n",
      "gender_none                          0.01(0.02)\n",
      "intercept                                     0\n",
      "avg_precision                               0.8\n",
      "cohort_size                              292659\n",
      "drop_percentage                        0.631988\n"
     ]
    }
   ],
   "source": [
    "print(res_symbolic_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Model (Extended Human Capital)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped_after_10\n"
     ]
    }
   ],
   "source": [
    "INCLUDE_PROD = 1\n",
    "INCLUDE_SOCIAL = 1\n",
    "INCLUDE_REC = 1\n",
    "INCLUDE_GENDER = 1\n",
    "INCLUDE_QUALITY = 1\n",
    "REMOVE_NONE_AUTHORS = 0\n",
    "INCLUDE_VENUE = 1\n",
    "INCLUDE_YEAR = 1\n",
    "cols_std, categorical_cols = make_cols_lists(INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC, INCLUDE_QUALITY, INCLUDE_GENDER, \n",
    "                                             REMOVE_NONE_AUTHORS, INCLUDE_VENUE, EARLY_CAREER, RECOGNITION_CUT, INCLUDE_YEAR, DV)\n",
    "\n",
    "print(DV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# res_full = run_elastic_net_cohort(credible_authors, cols_std, categorical_cols, DV)\n",
    "res_full_agg = run_elastic_net_aggr(credible_authors, cols_std, categorical_cols,INCLUDE_YEAR, DV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              1\n",
      "start_year                             0.0(0.0)\n",
      "early_career_prod_3                 -0.67(0.01)\n",
      "early_career_degree_3                 0.04(0.0)\n",
      "early_career_coauthor_max_hindex_3    -0.0(0.0)\n",
      "early_career_recognition_EC3_RC3      0.04(0.0)\n",
      "early_career_qual_3                   -0.0(0.0)\n",
      "quantiles_bin_3                     -0.34(0.03)\n",
      "gender_f                             0.06(0.01)\n",
      "gender_m                            -0.07(0.02)\n",
      "gender_none                          0.01(0.02)\n",
      "intercept                                     0\n",
      "avg_precision                              0.81\n",
      "cohort_size                              292659\n",
      "drop_percentage                        0.631988\n"
     ]
    }
   ],
   "source": [
    "print(res_full_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "res_all_agg = pd.DataFrame(index=res_full_agg.index, data=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_all_agg['baseline'] = res_baseline_agg\n",
    "res_all_agg['human'] = res_hum_cap_agg\n",
    "res_all_agg['gender'] = res_gender_agg\n",
    "res_all_agg['social'] = res_social_agg\n",
    "res_all_agg['symbolic'] = res_symbolic_agg\n",
    "res_all_agg['full_model'] = res_full_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DV == 'dropped_after_10':\n",
    "    reorderlist = ['start_year', 'early_career_prod_3', 'early_career_recognition_EC3_RC3', \n",
    "               'gender_f', 'gender_m', 'gender_none', \n",
    "               'early_career_degree_3', 'early_career_coauthor_max_hindex_3',\n",
    "               'quantiles_bin_3', 'early_career_qual_3',\n",
    "               'cohort_size', 'drop_percentage','avg_precision']\n",
    "    res_all_agg = res_all_agg.reindex(reorderlist)\n",
    "    res_all_agg = res_all_agg.fillna('')\n",
    "    res_all_agg['names'] = ['start year', 'productivity', 'recognition', \n",
    "                   'male', 'female', 'none', \n",
    "                   'degree', 'coauthor hindex',\n",
    "                   'top-venue', 'quality',\n",
    "                   'cohort size', '% dropouts','Average precision']\n",
    "else:\n",
    "    reorderlist = ['start_year', 'early_career_prod_3', 'early_career_recognition_EC3_RC3', \n",
    "               'gender_f', 'gender_m', 'gender_none', \n",
    "               'early_career_degree_3', 'early_career_coauthor_max_hindex_3',\n",
    "               'quantiles_bin_3', 'early_career_qual_3',\n",
    "               'cohort_size', 'neg_mean_squared_error', 'intercept','r2']\n",
    "    res_all_agg = res_all_agg.reindex(reorderlist)\n",
    "    res_all_agg = res_all_agg.fillna('')\n",
    "    res_all_agg['names'] = ['start year', 'productivity', 'recognition', \n",
    "                   'male', 'female', 'none', \n",
    "                   'degree', 'coauthor hindex',\n",
    "                   'top-venue', 'quality',\n",
    "                   'cohort size', 'MSE', 'intercept','R2']\n",
    "res_all_agg = res_all_agg.set_index('names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>human</th>\n",
       "      <th>gender</th>\n",
       "      <th>social</th>\n",
       "      <th>symbolic</th>\n",
       "      <th>full_model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>names</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>start year</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>productivity</th>\n",
       "      <td></td>\n",
       "      <td>-0.67(0.01)</td>\n",
       "      <td>-0.67(0.01)</td>\n",
       "      <td>-0.68(0.0)</td>\n",
       "      <td>-0.68(0.01)</td>\n",
       "      <td>-0.67(0.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recognition</th>\n",
       "      <td></td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.01(0.0)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.03(0.01)</td>\n",
       "      <td>0.03(0.01)</td>\n",
       "      <td>0.06(0.01)</td>\n",
       "      <td>0.06(0.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.05(0.01)</td>\n",
       "      <td>-0.05(0.01)</td>\n",
       "      <td>-0.06(0.02)</td>\n",
       "      <td>-0.07(0.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.01(0.01)</td>\n",
       "      <td>0.01(0.01)</td>\n",
       "      <td>0.01(0.02)</td>\n",
       "      <td>0.01(0.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coauthor hindex</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.01(0.0)</td>\n",
       "      <td>-0.0(0.0)</td>\n",
       "      <td>-0.0(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top-venue</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.33(0.04)</td>\n",
       "      <td>-0.34(0.03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.0(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohort size</th>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>% dropouts</th>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average precision</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   baseline        human       gender       social  \\\n",
       "names                                                                \n",
       "start year         0.0(0.0)     0.0(0.0)     0.0(0.0)     0.0(0.0)   \n",
       "productivity                 -0.67(0.01)  -0.67(0.01)   -0.68(0.0)   \n",
       "recognition                    0.02(0.0)    0.02(0.0)    0.01(0.0)   \n",
       "male                                       0.03(0.01)   0.03(0.01)   \n",
       "female                                    -0.05(0.01)  -0.05(0.01)   \n",
       "none                                       0.01(0.01)   0.01(0.01)   \n",
       "degree                                                   0.03(0.0)   \n",
       "coauthor hindex                                         -0.01(0.0)   \n",
       "top-venue                                                            \n",
       "quality                                                              \n",
       "cohort size          292659       292659       292659       292659   \n",
       "% dropouts         0.631988     0.631988     0.631988     0.631988   \n",
       "Average precision      0.62         0.78         0.79         0.79   \n",
       "\n",
       "                      symbolic   full_model  \n",
       "names                                        \n",
       "start year            0.0(0.0)     0.0(0.0)  \n",
       "productivity       -0.68(0.01)  -0.67(0.01)  \n",
       "recognition          0.02(0.0)    0.04(0.0)  \n",
       "male                0.06(0.01)   0.06(0.01)  \n",
       "female             -0.06(0.02)  -0.07(0.02)  \n",
       "none                0.01(0.02)   0.01(0.02)  \n",
       "degree               0.04(0.0)    0.04(0.0)  \n",
       "coauthor hindex      -0.0(0.0)    -0.0(0.0)  \n",
       "top-venue          -0.33(0.04)  -0.34(0.03)  \n",
       "quality                           -0.0(0.0)  \n",
       "cohort size             292659       292659  \n",
       "% dropouts            0.631988     0.631988  \n",
       "Average precision          0.8         0.81  "
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_all_agg\n",
    "# dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_to_latex(res_all_agg, 'agg_dropouts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>human</th>\n",
       "      <th>gender</th>\n",
       "      <th>social</th>\n",
       "      <th>symbolic</th>\n",
       "      <th>full_model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>names</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>start year</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>productivity</th>\n",
       "      <td></td>\n",
       "      <td>-0.67(0.01)</td>\n",
       "      <td>-0.67(0.01)</td>\n",
       "      <td>-0.68(0.0)</td>\n",
       "      <td>-0.68(0.01)</td>\n",
       "      <td>-0.67(0.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recognition</th>\n",
       "      <td></td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.01(0.0)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.03(0.01)</td>\n",
       "      <td>0.03(0.01)</td>\n",
       "      <td>0.06(0.01)</td>\n",
       "      <td>0.06(0.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.05(0.01)</td>\n",
       "      <td>-0.05(0.01)</td>\n",
       "      <td>-0.06(0.02)</td>\n",
       "      <td>-0.07(0.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.01(0.01)</td>\n",
       "      <td>0.01(0.01)</td>\n",
       "      <td>0.01(0.02)</td>\n",
       "      <td>0.01(0.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coauthor hindex</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.01(0.0)</td>\n",
       "      <td>-0.0(0.0)</td>\n",
       "      <td>-0.0(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top-venue</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.33(0.04)</td>\n",
       "      <td>-0.34(0.03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.0(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohort size</th>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>% dropouts</th>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average precision</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   baseline        human       gender       social  \\\n",
       "names                                                                \n",
       "start year         0.0(0.0)     0.0(0.0)     0.0(0.0)     0.0(0.0)   \n",
       "productivity                 -0.67(0.01)  -0.67(0.01)   -0.68(0.0)   \n",
       "recognition                    0.02(0.0)    0.02(0.0)    0.01(0.0)   \n",
       "male                                       0.03(0.01)   0.03(0.01)   \n",
       "female                                    -0.05(0.01)  -0.05(0.01)   \n",
       "none                                       0.01(0.01)   0.01(0.01)   \n",
       "degree                                                   0.03(0.0)   \n",
       "coauthor hindex                                         -0.01(0.0)   \n",
       "top-venue                                                            \n",
       "quality                                                              \n",
       "cohort size          292659       292659       292659       292659   \n",
       "% dropouts         0.631988     0.631988     0.631988     0.631988   \n",
       "Average precision      0.62         0.78         0.79         0.79   \n",
       "\n",
       "                      symbolic   full_model  \n",
       "names                                        \n",
       "start year            0.0(0.0)     0.0(0.0)  \n",
       "productivity       -0.68(0.01)  -0.67(0.01)  \n",
       "recognition          0.02(0.0)    0.04(0.0)  \n",
       "male                0.06(0.01)   0.06(0.01)  \n",
       "female             -0.06(0.02)  -0.07(0.02)  \n",
       "none                0.01(0.02)   0.01(0.02)  \n",
       "degree               0.04(0.0)    0.04(0.0)  \n",
       "coauthor hindex      -0.0(0.0)    -0.0(0.0)  \n",
       "top-venue          -0.33(0.04)  -0.34(0.03)  \n",
       "quality                           -0.0(0.0)  \n",
       "cohort size             292659       292659  \n",
       "% dropouts            0.631988     0.631988  \n",
       "Average precision          0.8         0.81  "
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_all_agg\n",
    "# citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_to_latex(res_all_agg, 'agg_citations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>human</th>\n",
       "      <th>gender</th>\n",
       "      <th>social</th>\n",
       "      <th>symbolic</th>\n",
       "      <th>full_model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>names</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>start year</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>productivity</th>\n",
       "      <td></td>\n",
       "      <td>-0.67(0.01)</td>\n",
       "      <td>-0.67(0.01)</td>\n",
       "      <td>-0.68(0.0)</td>\n",
       "      <td>-0.68(0.01)</td>\n",
       "      <td>-0.67(0.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recognition</th>\n",
       "      <td></td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.01(0.0)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.03(0.01)</td>\n",
       "      <td>0.03(0.01)</td>\n",
       "      <td>0.06(0.01)</td>\n",
       "      <td>0.06(0.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.05(0.01)</td>\n",
       "      <td>-0.05(0.01)</td>\n",
       "      <td>-0.06(0.02)</td>\n",
       "      <td>-0.07(0.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.01(0.01)</td>\n",
       "      <td>0.01(0.01)</td>\n",
       "      <td>0.01(0.02)</td>\n",
       "      <td>0.01(0.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coauthor hindex</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.01(0.0)</td>\n",
       "      <td>-0.0(0.0)</td>\n",
       "      <td>-0.0(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top-venue</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.33(0.04)</td>\n",
       "      <td>-0.34(0.03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.0(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohort size</th>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>% dropouts</th>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average precision</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   baseline        human       gender       social  \\\n",
       "names                                                                \n",
       "start year         0.0(0.0)     0.0(0.0)     0.0(0.0)     0.0(0.0)   \n",
       "productivity                 -0.67(0.01)  -0.67(0.01)   -0.68(0.0)   \n",
       "recognition                    0.02(0.0)    0.02(0.0)    0.01(0.0)   \n",
       "male                                       0.03(0.01)   0.03(0.01)   \n",
       "female                                    -0.05(0.01)  -0.05(0.01)   \n",
       "none                                       0.01(0.01)   0.01(0.01)   \n",
       "degree                                                   0.03(0.0)   \n",
       "coauthor hindex                                         -0.01(0.0)   \n",
       "top-venue                                                            \n",
       "quality                                                              \n",
       "cohort size          292659       292659       292659       292659   \n",
       "% dropouts         0.631988     0.631988     0.631988     0.631988   \n",
       "Average precision      0.62         0.78         0.79         0.79   \n",
       "\n",
       "                      symbolic   full_model  \n",
       "names                                        \n",
       "start year            0.0(0.0)     0.0(0.0)  \n",
       "productivity       -0.68(0.01)  -0.67(0.01)  \n",
       "recognition          0.02(0.0)    0.04(0.0)  \n",
       "male                0.06(0.01)   0.06(0.01)  \n",
       "female             -0.06(0.02)  -0.07(0.02)  \n",
       "none                0.01(0.02)   0.01(0.02)  \n",
       "degree               0.04(0.0)    0.04(0.0)  \n",
       "coauthor hindex      -0.0(0.0)    -0.0(0.0)  \n",
       "top-venue          -0.33(0.04)  -0.34(0.03)  \n",
       "quality                           -0.0(0.0)  \n",
       "cohort size             292659       292659  \n",
       "% dropouts            0.631988     0.631988  \n",
       "Average precision          0.8         0.81  "
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_all_agg\n",
    "#h index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_to_latex(res_all_agg, 'agg_hindex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Testing different scalers and ways of scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>human</th>\n",
       "      <th>gender</th>\n",
       "      <th>social</th>\n",
       "      <th>symbolic</th>\n",
       "      <th>full_model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>names</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>start year</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>productivity</th>\n",
       "      <td></td>\n",
       "      <td>-0.67(0.01)</td>\n",
       "      <td>-0.67(0.01)</td>\n",
       "      <td>-0.68(0.0)</td>\n",
       "      <td>-0.68(0.01)</td>\n",
       "      <td>-0.67(0.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recognition</th>\n",
       "      <td></td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.01(0.0)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.03(0.01)</td>\n",
       "      <td>0.03(0.01)</td>\n",
       "      <td>0.06(0.01)</td>\n",
       "      <td>0.06(0.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.05(0.01)</td>\n",
       "      <td>-0.05(0.01)</td>\n",
       "      <td>-0.06(0.02)</td>\n",
       "      <td>-0.07(0.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.01(0.01)</td>\n",
       "      <td>0.01(0.01)</td>\n",
       "      <td>0.01(0.02)</td>\n",
       "      <td>0.01(0.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coauthor hindex</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.01(0.0)</td>\n",
       "      <td>-0.0(0.0)</td>\n",
       "      <td>-0.0(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top-venue</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.33(0.04)</td>\n",
       "      <td>-0.34(0.03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.0(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohort size</th>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>% dropouts</th>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average precision</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   baseline        human       gender       social  \\\n",
       "names                                                                \n",
       "start year         0.0(0.0)     0.0(0.0)     0.0(0.0)     0.0(0.0)   \n",
       "productivity                 -0.67(0.01)  -0.67(0.01)   -0.68(0.0)   \n",
       "recognition                    0.02(0.0)    0.02(0.0)    0.01(0.0)   \n",
       "male                                       0.03(0.01)   0.03(0.01)   \n",
       "female                                    -0.05(0.01)  -0.05(0.01)   \n",
       "none                                       0.01(0.01)   0.01(0.01)   \n",
       "degree                                                   0.03(0.0)   \n",
       "coauthor hindex                                         -0.01(0.0)   \n",
       "top-venue                                                            \n",
       "quality                                                              \n",
       "cohort size          292659       292659       292659       292659   \n",
       "% dropouts         0.631988     0.631988     0.631988     0.631988   \n",
       "Average precision      0.62         0.78         0.79         0.79   \n",
       "\n",
       "                      symbolic   full_model  \n",
       "names                                        \n",
       "start year            0.0(0.0)     0.0(0.0)  \n",
       "productivity       -0.68(0.01)  -0.67(0.01)  \n",
       "recognition          0.02(0.0)    0.04(0.0)  \n",
       "male                0.06(0.01)   0.06(0.01)  \n",
       "female             -0.06(0.02)  -0.07(0.02)  \n",
       "none                0.01(0.02)   0.01(0.02)  \n",
       "degree               0.04(0.0)    0.04(0.0)  \n",
       "coauthor hindex      -0.0(0.0)    -0.0(0.0)  \n",
       "top-venue          -0.33(0.04)  -0.34(0.03)  \n",
       "quality                           -0.0(0.0)  \n",
       "cohort size             292659       292659  \n",
       "% dropouts            0.631988     0.631988  \n",
       "Average precision          0.8         0.81  "
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_all_agg\n",
    "# with columns scaled aggregated - MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>human</th>\n",
       "      <th>gender</th>\n",
       "      <th>social</th>\n",
       "      <th>symbolic</th>\n",
       "      <th>full_model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>names</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>start year</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>productivity</th>\n",
       "      <td></td>\n",
       "      <td>-0.67(0.01)</td>\n",
       "      <td>-0.67(0.01)</td>\n",
       "      <td>-0.68(0.0)</td>\n",
       "      <td>-0.68(0.01)</td>\n",
       "      <td>-0.67(0.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recognition</th>\n",
       "      <td></td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.01(0.0)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.03(0.01)</td>\n",
       "      <td>0.03(0.01)</td>\n",
       "      <td>0.06(0.01)</td>\n",
       "      <td>0.06(0.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.05(0.01)</td>\n",
       "      <td>-0.05(0.01)</td>\n",
       "      <td>-0.06(0.02)</td>\n",
       "      <td>-0.07(0.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.01(0.01)</td>\n",
       "      <td>0.01(0.01)</td>\n",
       "      <td>0.01(0.02)</td>\n",
       "      <td>0.01(0.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coauthor hindex</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.01(0.0)</td>\n",
       "      <td>-0.0(0.0)</td>\n",
       "      <td>-0.0(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top-venue</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.33(0.04)</td>\n",
       "      <td>-0.34(0.03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.0(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohort size</th>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>% dropouts</th>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average precision</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   baseline        human       gender       social  \\\n",
       "names                                                                \n",
       "start year         0.0(0.0)     0.0(0.0)     0.0(0.0)     0.0(0.0)   \n",
       "productivity                 -0.67(0.01)  -0.67(0.01)   -0.68(0.0)   \n",
       "recognition                    0.02(0.0)    0.02(0.0)    0.01(0.0)   \n",
       "male                                       0.03(0.01)   0.03(0.01)   \n",
       "female                                    -0.05(0.01)  -0.05(0.01)   \n",
       "none                                       0.01(0.01)   0.01(0.01)   \n",
       "degree                                                   0.03(0.0)   \n",
       "coauthor hindex                                         -0.01(0.0)   \n",
       "top-venue                                                            \n",
       "quality                                                              \n",
       "cohort size          292659       292659       292659       292659   \n",
       "% dropouts         0.631988     0.631988     0.631988     0.631988   \n",
       "Average precision      0.62         0.78         0.79         0.79   \n",
       "\n",
       "                      symbolic   full_model  \n",
       "names                                        \n",
       "start year            0.0(0.0)     0.0(0.0)  \n",
       "productivity       -0.68(0.01)  -0.67(0.01)  \n",
       "recognition          0.02(0.0)    0.04(0.0)  \n",
       "male                0.06(0.01)   0.06(0.01)  \n",
       "female             -0.06(0.02)  -0.07(0.02)  \n",
       "none                0.01(0.02)   0.01(0.02)  \n",
       "degree               0.04(0.0)    0.04(0.0)  \n",
       "coauthor hindex      -0.0(0.0)    -0.0(0.0)  \n",
       "top-venue          -0.33(0.04)  -0.34(0.03)  \n",
       "quality                           -0.0(0.0)  \n",
       "cohort size             292659       292659  \n",
       "% dropouts            0.631988     0.631988  \n",
       "Average precision          0.8         0.81  "
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_all_agg\n",
    "# with columns scaled aggregated - StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>human</th>\n",
       "      <th>gender</th>\n",
       "      <th>social</th>\n",
       "      <th>symbolic</th>\n",
       "      <th>full_model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>names</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>start year</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>productivity</th>\n",
       "      <td></td>\n",
       "      <td>-0.67(0.01)</td>\n",
       "      <td>-0.67(0.01)</td>\n",
       "      <td>-0.68(0.0)</td>\n",
       "      <td>-0.68(0.01)</td>\n",
       "      <td>-0.67(0.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recognition</th>\n",
       "      <td></td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.01(0.0)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.03(0.01)</td>\n",
       "      <td>0.03(0.01)</td>\n",
       "      <td>0.06(0.01)</td>\n",
       "      <td>0.06(0.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.05(0.01)</td>\n",
       "      <td>-0.05(0.01)</td>\n",
       "      <td>-0.06(0.02)</td>\n",
       "      <td>-0.07(0.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.01(0.01)</td>\n",
       "      <td>0.01(0.01)</td>\n",
       "      <td>0.01(0.02)</td>\n",
       "      <td>0.01(0.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coauthor hindex</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.01(0.0)</td>\n",
       "      <td>-0.0(0.0)</td>\n",
       "      <td>-0.0(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top-venue</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.33(0.04)</td>\n",
       "      <td>-0.34(0.03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.0(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohort size</th>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>% dropouts</th>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average precision</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   baseline        human       gender       social  \\\n",
       "names                                                                \n",
       "start year         0.0(0.0)     0.0(0.0)     0.0(0.0)     0.0(0.0)   \n",
       "productivity                 -0.67(0.01)  -0.67(0.01)   -0.68(0.0)   \n",
       "recognition                    0.02(0.0)    0.02(0.0)    0.01(0.0)   \n",
       "male                                       0.03(0.01)   0.03(0.01)   \n",
       "female                                    -0.05(0.01)  -0.05(0.01)   \n",
       "none                                       0.01(0.01)   0.01(0.01)   \n",
       "degree                                                   0.03(0.0)   \n",
       "coauthor hindex                                         -0.01(0.0)   \n",
       "top-venue                                                            \n",
       "quality                                                              \n",
       "cohort size          292659       292659       292659       292659   \n",
       "% dropouts         0.631988     0.631988     0.631988     0.631988   \n",
       "Average precision      0.62         0.78         0.79         0.79   \n",
       "\n",
       "                      symbolic   full_model  \n",
       "names                                        \n",
       "start year            0.0(0.0)     0.0(0.0)  \n",
       "productivity       -0.68(0.01)  -0.67(0.01)  \n",
       "recognition          0.02(0.0)    0.04(0.0)  \n",
       "male                0.06(0.01)   0.06(0.01)  \n",
       "female             -0.06(0.02)  -0.07(0.02)  \n",
       "none                0.01(0.02)   0.01(0.02)  \n",
       "degree               0.04(0.0)    0.04(0.0)  \n",
       "coauthor hindex      -0.0(0.0)    -0.0(0.0)  \n",
       "top-venue          -0.33(0.04)  -0.34(0.03)  \n",
       "quality                           -0.0(0.0)  \n",
       "cohort size             292659       292659  \n",
       "% dropouts            0.631988     0.631988  \n",
       "Average precision          0.8         0.81  "
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_all_agg\n",
    "# with columns scaled cohortly -  MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>human</th>\n",
       "      <th>gender</th>\n",
       "      <th>social</th>\n",
       "      <th>symbolic</th>\n",
       "      <th>full_model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>names</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>start year</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>productivity</th>\n",
       "      <td></td>\n",
       "      <td>-0.67(0.01)</td>\n",
       "      <td>-0.67(0.01)</td>\n",
       "      <td>-0.68(0.0)</td>\n",
       "      <td>-0.68(0.01)</td>\n",
       "      <td>-0.67(0.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recognition</th>\n",
       "      <td></td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.01(0.0)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.03(0.01)</td>\n",
       "      <td>0.03(0.01)</td>\n",
       "      <td>0.06(0.01)</td>\n",
       "      <td>0.06(0.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.05(0.01)</td>\n",
       "      <td>-0.05(0.01)</td>\n",
       "      <td>-0.06(0.02)</td>\n",
       "      <td>-0.07(0.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.01(0.01)</td>\n",
       "      <td>0.01(0.01)</td>\n",
       "      <td>0.01(0.02)</td>\n",
       "      <td>0.01(0.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coauthor hindex</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.01(0.0)</td>\n",
       "      <td>-0.0(0.0)</td>\n",
       "      <td>-0.0(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top-venue</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.33(0.04)</td>\n",
       "      <td>-0.34(0.03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.0(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohort size</th>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>% dropouts</th>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average precision</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   baseline        human       gender       social  \\\n",
       "names                                                                \n",
       "start year         0.0(0.0)     0.0(0.0)     0.0(0.0)     0.0(0.0)   \n",
       "productivity                 -0.67(0.01)  -0.67(0.01)   -0.68(0.0)   \n",
       "recognition                    0.02(0.0)    0.02(0.0)    0.01(0.0)   \n",
       "male                                       0.03(0.01)   0.03(0.01)   \n",
       "female                                    -0.05(0.01)  -0.05(0.01)   \n",
       "none                                       0.01(0.01)   0.01(0.01)   \n",
       "degree                                                   0.03(0.0)   \n",
       "coauthor hindex                                         -0.01(0.0)   \n",
       "top-venue                                                            \n",
       "quality                                                              \n",
       "cohort size          292659       292659       292659       292659   \n",
       "% dropouts         0.631988     0.631988     0.631988     0.631988   \n",
       "Average precision      0.62         0.78         0.79         0.79   \n",
       "\n",
       "                      symbolic   full_model  \n",
       "names                                        \n",
       "start year            0.0(0.0)     0.0(0.0)  \n",
       "productivity       -0.68(0.01)  -0.67(0.01)  \n",
       "recognition          0.02(0.0)    0.04(0.0)  \n",
       "male                0.06(0.01)   0.06(0.01)  \n",
       "female             -0.06(0.02)  -0.07(0.02)  \n",
       "none                0.01(0.02)   0.01(0.02)  \n",
       "degree               0.04(0.0)    0.04(0.0)  \n",
       "coauthor hindex      -0.0(0.0)    -0.0(0.0)  \n",
       "top-venue          -0.33(0.04)  -0.34(0.03)  \n",
       "quality                           -0.0(0.0)  \n",
       "cohort size             292659       292659  \n",
       "% dropouts            0.631988     0.631988  \n",
       "Average precision          0.8         0.81  "
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_all_agg\n",
    "# no column scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-513-4f76a9dad686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     17,
     29
    ]
   },
   "outputs": [],
   "source": [
    "def OLD_run_elastic_net_cohort(credible_authors,cols_all, cols_std, categorical_cols, EARLY_CAREER):\n",
    "    aggregated = False\n",
    "    hindex_table = pd.DataFrame(cols_all, columns=['feature']).set_index('feature')\n",
    "    citation_table = pd.DataFrame(cols_all, columns=['feature']).set_index('feature')\n",
    "    dropout_table = pd.DataFrame(cols_all, columns=['feature']).set_index('feature')\n",
    "    for year in cohort_start_years:\n",
    "        credible_authors_year = credible_authors[credible_authors.start_year == year]\n",
    "        X = credible_authors_year.copy()\n",
    "        \n",
    "        hindex_data, citation_data, dropout_data = run_elastic_net(X, cols_std, categorical_cols, EARLY_CAREER, year, aggregated)\n",
    "       \n",
    "        hindex_table = hindex_table.join(hindex_data)\n",
    "        citation_table = citation_table.join(citation_data)\n",
    "        dropout_table = dropout_table.join(dropout_data)\n",
    "        \n",
    "    return hindex_table, citation_table, dropout_table\n",
    "\n",
    "def OLD_run_elastic_net_aggr(credible_authors, cols_std, categorical_cols, EARLY_CAREER):\n",
    "        \n",
    "    aggregated = True\n",
    "    #add cohort start year as var\n",
    "    categorical_cols.append(\"start_year\")\n",
    "    \n",
    "    X = credible_authors.copy()\n",
    "    \n",
    "    return run_elastic_net(X, cols_std, categorical_cols, EARLY_CAREER, year=0, aggregated)\n",
    "    \n",
    "\n",
    "\n",
    "def OLD_run_elastic_net(X, cols_std, categorical_cols, EARLY_CAREER, year=0, aggregated):\n",
    "   \n",
    "    #remove non-gender rows\n",
    "    if(REMOVE_NONE_AUTHORS):\n",
    "        X = X[X[\"gender\"]!=\"none\"]\n",
    "\n",
    "   \n",
    "    # Make dummy values for categorical columns\n",
    "    cat_cols = pd.get_dummies(X[categorical_cols])\n",
    "\n",
    "    \n",
    "    #if(not REMOVE_NONE_AUTHORS):\n",
    "        # drop gender none?\n",
    "         # this is removing rows gender_none col\n",
    "        #gender_cols.drop('gender_none', axis=1, inplace=True)\n",
    "\n",
    "    #standardize cols_std\n",
    "    if len(cols_std)>0:\n",
    "        standardized_cols = RobustScaler().fit_transform(X[cols_std])\n",
    "        H = pd.DataFrame(standardized_cols, index=X.index, columns=cols_std)\n",
    "    else:\n",
    "        H = pd.DataFrame(index=X.index, columns=cols_std)\n",
    "       \n",
    "    H = H.join(cat_cols) \n",
    "    if(not INCLUDE_GENDER):\n",
    "        H = H.drop(columns=['gender_f',  'gender_m',  'gender_none'])\n",
    "    \n",
    "    print(H.head())\n",
    "    \n",
    "    y = X[f'h_index_increase_15_{EARLY_CAREER}']\n",
    "    y2 = X[f'citation_increase_15_{EARLY_CAREER}']\n",
    "    y3 = X['dropped_after_10'].astype(int)\n",
    "\n",
    "    #cv_dict = cross_validate(LinearRegressionCV(cv=3), H, y, scoring='r2', cv=10, return_estimator=True, return_train_score=False)\n",
    "    #cv2_dict = cross_validate(LinearRegressionCV(cv=3), H, y2, scoring='r2', cv=10, return_estimator=True, return_train_score=False)\n",
    "    #cv3_dict = cross_validate(LogisticRegressionCV(cv=3, penalty='l2'), H, y3, scoring=\"f1\", cv=10, return_estimator=True, return_train_score=False)\n",
    "    cv_dict = cross_validate(ElasticNetCV(cv=3), H, y, scoring='r2', cv=10, return_estimator=True, return_train_score=False)\n",
    "    cv2_dict = cross_validate(ElasticNetCV(cv=3), H, y2, scoring='r2', cv=10, return_estimator=True, return_train_score=False)\n",
    "    cv3_dict = cross_validate(LogisticRegressionCV(cv=3, penalty='l2'), H, y3, scoring=\"f1\", cv=10, return_estimator=True, return_train_score=False)\n",
    "          \n",
    "    score = np.mean(cv_dict['test_score'])\n",
    "    score2 = np.mean(cv2_dict['test_score'])\n",
    "    score3 = np.mean(cv3_dict['test_score'])\n",
    "\n",
    "    net_coef = pd.DataFrame([es.coef_ for es in cv_dict['estimator']], columns=H.columns)\n",
    "    net2_coef = pd.DataFrame([es.coef_ for es in cv2_dict['estimator']], columns=H.columns)\n",
    "    net3_coef = pd.DataFrame([es.coef_[0] for es in cv3_dict['estimator']], columns=H.columns)\n",
    "\n",
    "    net_intercept = np.mean([es.intercept_ for es in cv_dict['estimator']])\n",
    "    net2_intercept = np.mean([es.intercept_ for es in cv2_dict['estimator']])\n",
    "    net3_intercept = np.mean([es.intercept_ for es in cv3_dict['estimator']])\n",
    "\n",
    "    net_coef_mean, net2_coef_mean, net3_coef_mean = net_coef.mean(), net2_coef.mean(), net3_coef.mean()\n",
    "    net_coef_std, net2_coef_std, net3_coef_std = net_coef.std(), net2_coef.std(), net3_coef.std()\n",
    "\n",
    "    rounding = 2\n",
    "\n",
    "    net_coef_mean_std = list(zip(np.round(net_coef_mean.values,rounding), np.round(net_coef_std.values,rounding)))\n",
    "    net2_coef_mean_std = list(zip(np.round(net2_coef_mean.values,rounding), np.round(net2_coef_std.values,rounding)))\n",
    "    net3_coef_mean_std = list(zip(np.round(net3_coef_mean.values,rounding), np.round(net3_coef_std.values,rounding)))\n",
    "        \n",
    "    net_coef_mean_std = [f\"{x[0]}({x[1]})\" for x in net_coef_mean_std]\n",
    "    net2_coef_mean_std = [f\"{x[0]}({x[1]})\" for x in net2_coef_mean_std]\n",
    "    net3_coef_mean_std = [f\"{x[0]}({x[1]})\" for x in net3_coef_mean_std]\n",
    "\n",
    "    cohort_size = len(y2)\n",
    "    #     num_nonzero_coefs = sum(net2.coef_ != 0)\n",
    "    #     adj_score2 = 1 - (1-score2)*(cohort_size-1)/(cohort_size-num_nonzero_coefs-1)\n",
    "    net_coef_mean_std.extend([np.round(net_intercept, rounding), np.round(score, rounding), cohort_size])\n",
    "    net2_coef_mean_std.extend([np.round(net2_intercept, rounding), np.round(score2, rounding), cohort_size])\n",
    "    net3_coef_mean_std.extend([np.round(net3_intercept, rounding), np.round(score3, rounding), cohort_size])\n",
    "\n",
    "    if(year>0):\n",
    "        hindex_data = pd.DataFrame(list(zip(np.append(H.columns, ['intercept', 'r2', 'cohort_size']), \n",
    "                                              net_coef_mean_std)), \n",
    "                                     columns=['year', year]).set_index('year')\n",
    "        citation_data = pd.DataFrame(list(zip(np.append(H.columns, ['intercept', 'r2', 'cohort_size']), \n",
    "                                              net2_coef_mean_std)), \n",
    "                                     columns=['year', year]).set_index('year')\n",
    "        dropout_data = pd.DataFrame(list(zip(np.append(H.columns, ['intercept', 'r2', 'cohort_size']), \n",
    "                                              net3_coef_mean_std)),\n",
    "                                     columns=['year', year]).set_index('year')\n",
    "    else:\n",
    "        hindex_data = pd.DataFrame(list(zip(np.append(H.columns, ['intercept', 'r2', 'cohort_size']), \n",
    "                                              net_coef_mean_std)))\n",
    "        citation_data = pd.DataFrame(list(zip(np.append(H.columns, ['intercept', 'r2', 'cohort_size']), \n",
    "                                              net2_coef_mean_std)))                                  \n",
    "        dropout_data = pd.DataFrame(list(zip(np.append(H.columns, ['intercept', 'r2', 'cohort_size']), \n",
    "                                              net3_coef_mean_std)))\n",
    "    \n",
    "    return hindex_data, citation_data, dropout_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_result_table(feature_table):\n",
    "    results = feature_table.transpose()\n",
    "    #shorten column names\n",
    "    new_cols = dict(zip(results.columns, [col.replace('early_career', 'ec') for col in results.columns]))\n",
    "\n",
    "    results.rename(new_cols, axis='columns', inplace=True)\n",
    "    results.rename({'feature':'cohort','ec_coauthor_max_cit_3': 'ec_coauth_max_cit_3', 'ec_recognition_EC3_RC5':'ec_recog_EC3_RC5'}, axis='columns', inplace=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_to_latex(results, name):\n",
    "    ltx_file = open(f\"results_{name}.tex\", \"w\")\n",
    "    ltx_file.write('\\n'.join(results.to_latex().split('\\n')[5:-7]))\n",
    "    ltx_file.write('\\hline \\n')\n",
    "    ltx_file.write('\\n'.join(results.to_latex().split('\\n')[-7:-3]))\n",
    "    ltx_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EARLY_CAREER = 3\n",
    "RECOGNITION_CUT = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Aggregated Elastic Net Models\n",
    "First we test the effect of different groups of features (human capital, social capital and gender) on success/dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#MODEL 1: null model\n",
    "\n",
    "INCLUDE_PROD = 0\n",
    "INCLUDE_SOCIAL = 0\n",
    "INCLUDE_REC = 0\n",
    "INCLUDE_GENDER = 0\n",
    "INCLUDE_QUALITY = 0\n",
    "cols_all, cols_std, categorical_cols = make_cols_lists(INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC, INCLUDE_QUALITY, \n",
    "                                                       INCLUDE_GENDER, REMOVE_NONE_AUTHORS, EARLY_CAREER, RECOGNITION_CUT)\n",
    "\n",
    "#hindex_table, citation_table, dropout_table =  run_elastic_predictions(cols_all, cols_std, categorical_cols, EARLY_CAREER)\n",
    "\n",
    "\n",
    "hindex_table, citation_table, dropout_table = run_elastic_net_aggr(credible_authors, cols_std, categorical_cols, EARLY_CAREER)\n",
    "\n",
    "\n",
    "\n",
    "#hindex_table, citation_table, dropout_table =  run_elastic_net_cohort(credible_authors, cols_all, cols_std, categorical_cols, EARLY_CAREER)\n",
    "#results_hindex = make_result_table(hindex_table)\n",
    "#results_citation = make_result_table(citation_table)\n",
    "#results_dropouts = make_result_table(dropout_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"hindex_table\")\n",
    "print(hindex_table)\n",
    "print(\"citation_table\")\n",
    "print(citation_table)\n",
    "print(\"dropout_table\")\n",
    "print(dropout_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#MODEL 2: gender effect model\n",
    "\n",
    "INCLUDE_PROD = 1\n",
    "INCLUDE_SOCIAL = 0\n",
    "INCLUDE_REC = 1\n",
    "INCLUDE_GENDER = 1\n",
    "INCLUDE_QUALITY = 0\n",
    "cols_all, cols_std, categorical_cols = make_cols_lists(INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC, INCLUDE_QUALITY, \n",
    "                                                       INCLUDE_GENDER, REMOVE_NONE_AUTHORS, EARLY_CAREER, RECOGNITION_CUT)\n",
    "\n",
    "hindex_table, citation_table, dropout_table = run_elastic_net_aggr(credible_authors, cols_std, categorical_cols, EARLY_CAREER)\n",
    "print(\"hindex_table\")\n",
    "print(hindex_table)\n",
    "print(\"citation_table\")\n",
    "print(citation_table)\n",
    "print(\"dropout_table\")\n",
    "print(dropout_table)\n",
    "\n",
    "#feature_table, feature_table2, feature_table3 = run_elastic_net_cohort(cols_all, cols_std, categorical_cols, EARLY_CAREER)\n",
    "#results = make_result_table(feature_table)\n",
    "#results2 = make_result_table(feature_table2)\n",
    "#results3 = make_result_table(feature_table3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#MODEL 3: social capital effect model\n",
    "\n",
    "INCLUDE_PROD = 1\n",
    "INCLUDE_SOCIAL = 1\n",
    "INCLUDE_REC = 1\n",
    "INCLUDE_GENDER = 1\n",
    "INCLUDE_QUALITY = 0\n",
    "cols_all, cols_std, categorical_cols = make_cols_lists(INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC, INCLUDE_QUALITY, \n",
    "                                                       INCLUDE_GENDER, REMOVE_NONE_AUTHORS, EARLY_CAREER, RECOGNITION_CUT)\n",
    "\n",
    "#feature_table, feature_table2, feature_table3 = run_elastic_bet_cohort(cols_all, cols_std, categorical_cols, EARLY_CAREER)\n",
    "#results = make_result_table(feature_table)\n",
    "#results2 = make_result_table(feature_table2)\n",
    "#results3 = make_result_table(feature_table3)\n",
    "\n",
    "hindex_table, citation_table, dropout_table = run_elastic_net_aggr(credible_authors, cols_std, categorical_cols, EARLY_CAREER)\n",
    "print(\"hindex_table\")\n",
    "print(hindex_table)\n",
    "print(\"citation_table\")\n",
    "print(citation_table)\n",
    "print(\"dropout_table\")\n",
    "print(dropout_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#MODEL 4: full model\n",
    "INCLUDE_PROD = 1\n",
    "INCLUDE_SOCIAL = 1\n",
    "INCLUDE_REC = 1\n",
    "INCLUDE_GENDER = 1\n",
    "INCLUDE_QUALITY = 1\n",
    "cols_all, cols_std, categorical_cols = make_cols_lists(INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC, INCLUDE_QUALITY, \n",
    "                                                       INCLUDE_GENDER, REMOVE_NONE_AUTHORS, EARLY_CAREER, RECOGNITION_CUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hindex_table, citation_table, dropout_table = run_elastic_net_aggr(credible_authors, cols_std, categorical_cols, EARLY_CAREER)\n",
    "print(\"hindex_table\")\n",
    "print(hindex_table)\n",
    "print(\"citation_table\")\n",
    "print(citation_table)\n",
    "print(\"dropout_table\")\n",
    "print(dropout_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort Elastic Net Models\n",
    "Second we compare the predictive performance across cohorts. We should plot R2 and F1 over cohorts.\n",
    "Is predictive performance stable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full model\n",
    "INCLUDE_PROD = 1\n",
    "INCLUDE_SOCIAL = 1\n",
    "INCLUDE_REC = 1\n",
    "INCLUDE_GENDER = 1\n",
    "INCLUDE_QUALITY = 1\n",
    "cols_all, cols_std, categorical_cols = make_cols_lists(INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC, INCLUDE_QUALITY, \n",
    "                                                       INCLUDE_GENDER, REMOVE_NONE_AUTHORS, EARLY_CAREER, RECOGNITION_CUT)\n",
    "feature_table, feature_table2, feature_table3 = run_elastic_net_cohort(credible_authors, cols_all, cols_std, categorical_cols, EARLY_CAREER)\n",
    "\n",
    "results = make_result_table(feature_table)\n",
    "results2 = make_result_table(feature_table2)\n",
    "results3 = make_result_table(feature_table3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(results.index, results[[\"r2\"]])\n",
    "ax.set(xlabel='cohorts', ylabel='R2',\n",
    "       title='h-index increase prediction')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(results2.index, results2[[\"r2\"]])\n",
    "ax.set(xlabel='cohorts', ylabel='R2',\n",
    "       title='citation increase prediction')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(results3.index, results3[[\"r2\"]])\n",
    "ax.set(xlabel='cohorts', ylabel='F1',\n",
    "       title='dropout prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model without quality \n",
    "INCLUDE_PROD = 1\n",
    "INCLUDE_SOCIAL = 1\n",
    "INCLUDE_REC = 1\n",
    "INCLUDE_GENDER = 1\n",
    "INCLUDE_QUALITY = 0\n",
    "cols_all, cols_std, categorical_cols = make_cols_lists(INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC, \n",
    "                                                       INCLUDE_QUALITY, INCLUDE_GENDER, REMOVE_NONE_AUTHORS, EARLY_CAREER, RECOGNITION_CUT)\n",
    "feature_table, feature_table2, feature_table3 = run_elastic_net_cohort(credible_authors, cols_all, cols_std, categorical_cols, EARLY_CAREER)\n",
    "results_no_qual = make_result_table(feature_table)\n",
    "results2_no_qual = make_result_table(feature_table2)\n",
    "results3_no_qual = make_result_table(feature_table3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results3_no_qual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INCLUDE_PROD = 1\n",
    "INCLUDE_SOCIAL = 1\n",
    "INCLUDE_REC = 1\n",
    "INCLUDE_GENDER = 0\n",
    "INCLUDE_QUALITY = 1\n",
    "cols_all, cols_std, categorical_cols = make_cols_lists(INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC,\n",
    "                                                       INCLUDE_QUALITY, INCLUDE_GENDER, REMOVE_NONE_AUTHORS, EARLY_CAREER, RECOGNITION_CUT)\n",
    "feature_table, feature_table2, feature_table3 = run_elastic_net_cohort(credible_authors, cols_all, cols_std, categorical_cols, EARLY_CAREER)\n",
    "results_no_gen = make_result_table(feature_table)\n",
    "results2_no_gen = make_result_table(feature_table2)\n",
    "results3_no_gen = make_result_table(feature_table3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results3_no_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INCLUDE_PROD = 1\n",
    "INCLUDE_SOCIAL = 1\n",
    "INCLUDE_REC = 1\n",
    "INCLUDE_GENDER = 0\n",
    "INCLUDE_QUALITY = 0\n",
    "cols_all, cols_std, categorical_cols = make_cols_lists(INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC,\n",
    "                                                       INCLUDE_QUALITY, INCLUDE_GENDER, REMOVE_NONE_AUTHORS, EARLY_CAREER, RECOGNITION_CUT)\n",
    "feature_table, feature_table2, feature_table3 = run_elastic_net_cohort(credible_authors, cols_all, cols_std, categorical_cols, EARLY_CAREER)\n",
    "results_no_qual_no_gen = make_result_table(feature_table)\n",
    "results2_no_qual_no_gen = make_result_table(feature_table2)\n",
    "results3_no_qual_no_gen = make_result_table(feature_table3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results3_no_qual_no_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['r2_no_qual_no_gen'] = results_no_qual_no_gen['r2']\n",
    "results2['r2_no_qual_no_gen'] = results2_no_qual_no_gen['r2']\n",
    "results3['f1_no_qual_no_gen'] = results3_no_qual_no_gen['r2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['r2_no_qual'] = results_no_qual['r2']\n",
    "results2['r2_no_qual'] = results2_no_qual['r2']\n",
    "results3['f1_no_qual'] = results3_no_qual['r2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['r2_no_gen'] = results_no_gen['r2']\n",
    "results2['r2_no_gen'] = results2_no_gen['r2']\n",
    "results3['f1_no_gen'] = results3_no_gen['r2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_percent = credible_authors.groupby('start_year')['dropped_after_10'].sum() / credible_authors.groupby('start_year')['dropped_after_10'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results3['drop_percentage'] = dropped_percent.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results3 = results3.reindex([results3.columns[0]] + [results3.columns[-1]] + list(results3.columns[1:-1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.tail()\n",
    "#h_index_increase\n",
    "# train_test results, compare with 'r2' col\n",
    "# Year: 1999, r2: 0.29575585145072425\n",
    "# Year: 2000, r2: 0.3288047075331689\n",
    "# Year: 2001, r2: 0.32359617501275245\n",
    "# Year: 2002, r2: 0.32367401156648834"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2.tail()\n",
    "#citation_increase\n",
    "# train_test results\n",
    "# Year: 1999, r2: 0.26267137837811527\n",
    "# Year: 2000, r2: 0.3229074740899605\n",
    "# Year: 2001, r2: 0.2866603572613974\n",
    "# Year: 2002, r2: 0.30948376141611045"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results3.tail(4)\n",
    "#dropouts\n",
    "# train_test results\n",
    "# Year: 1999, r2: 0.7871975797159264\n",
    "# Year: 2000, r2: 0.7755906039107061\n",
    "# Year: 2001, r2: 0.7776091854493229\n",
    "# Year: 2002, r2: 0.7783668951214104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_to_latex(results, 'hindex')\n",
    "results_to_latex(results2, 'cit')\n",
    "results_to_latex(results3, 'dropout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results\n",
    "# h index increase\n",
    "#results.to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2\n",
    "# citation increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results3\n",
    "# coefficients are not exponentiated\n",
    "# positive means bigger change to drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test train split 80-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def run_elastic_predictions_test_train(cols_all, cols_std, categorical_cols, EARLY_CAREER):\n",
    "    feature_table = pd.DataFrame(cols_all, columns=['feature']).set_index('feature')\n",
    "    feature_table2 = pd.DataFrame(cols_all, columns=['feature']).set_index('feature')\n",
    "    feature_table3 = pd.DataFrame(cols_all, columns=['feature']).set_index('feature')\n",
    " \n",
    "    for year in [1970,1999,2000,2001,2002]:\n",
    "        credible_authors_year = credible_authors[credible_authors.start_year == year]\n",
    "\n",
    "        X = credible_authors_year.copy()\n",
    "\n",
    "        #remove non-gender rows\n",
    "        if(REMOVE_NONE_AUTHORS):\n",
    "            X = X[X[\"gender\"]!=\"none\"]\n",
    "\n",
    "        # Make dummy values for categorical columns\n",
    "        gender_cols = pd.get_dummies(X[categorical_cols])\n",
    "\n",
    "        #if(not REMOVE_NONE_AUTHORS):\n",
    "            # drop gender none?\n",
    "            # this is removing rows gender_none col\n",
    "            #gender_cols.drop('gender_none', axis=1, inplace=True)\n",
    "\n",
    "        #standardize cols_std\n",
    "        if len(cols_std)>0:\n",
    "            standardized_cols = RobustScaler().fit_transform(X[cols_std])\n",
    "\n",
    "\n",
    "        # claudia: here we could do a 20:80 split and save 20% for later test\n",
    "\n",
    "        #combine\n",
    "        H = pd.DataFrame(standardized_cols, index=X.index, columns=cols_std)\n",
    "        if(INCLUDE_GENDER):\n",
    "            H = H.join(gender_cols)\n",
    "\n",
    "        y = X[f'h_index_increase_15_{EARLY_CAREER}']\n",
    "        y2 = X[f'citation_increase_15_{EARLY_CAREER}']\n",
    "        y3 = X['dropped_after_10'].astype(int)\n",
    "        \n",
    "        f1_dropout_list=[]\n",
    "        r2_hindex_list=[]\n",
    "        for i in range(10):\n",
    "            #dropouts\n",
    "            X_train, X_test, y_train, y_test = train_test_split(H, y3, test_size=0.2)\n",
    "            rgs = LogisticRegressionCV(cv=3) #, penalty='l2', solver='liblinear'\n",
    "            #rgs = SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
    "            #           early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
    "            #           l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=1000,\n",
    "            #           n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
    "            #           power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
    "            #           validation_fraction=0.1, verbose=0, warm_start=False)\n",
    "        \n",
    "            rgs.fit(X_train, y_train)\n",
    "            f1_dropout = f1_score(y_test, rgs.predict(X_test))\n",
    "            f1_dropout_list.append(f1_dropout)\n",
    "            \n",
    "            #h-index increase\n",
    "            X_train, X_test, y_train, y_test = train_test_split(H, y, test_size=0.2)\n",
    "            rgs = ElasticNetCV(cv=3)\n",
    "            #rgs = ElasticNetCV(cv=3, random_state=1000, max_iter=10000,\n",
    "            #       alphas=[1.0], l1_ratio=0.5)\n",
    "            rgs.fit(X_train, y_train)\n",
    "            r2_hindex = r2_score(y_test, rgs.predict(X_test))\n",
    "            print(rgs.alpha_)\n",
    "            r2_hindex_list.append(r2_hindex)\n",
    "            \n",
    "        print(f\"Year: {year}, f1_dropout: {np.mean(f1_dropout_list)}\")\n",
    "        print(f\"Year: {year}, r2_hindex: {np.mean(r2_hindex_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INCLUDE_PROD = 1\n",
    "INCLUDE_SOCIAL = 1\n",
    "INCLUDE_REC = 1\n",
    "INCLUDE_GENDER = 1\n",
    "INCLUDE_QUALITY = 1\n",
    "cols_all, cols_std, categorical_cols = make_cols_lists(INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC,\n",
    "                                                       INCLUDE_QUALITY, INCLUDE_GENDER, REMOVE_NONE_AUTHORS, EARLY_CAREER, RECOGNITION_CUT)\n",
    "run_elastic_predictions_test_train(cols_all, cols_std, categorical_cols, EARLY_CAREER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test predictive power over different number of observed years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INCLUDE_PROD = 1\n",
    "INCLUDE_SOCIAL = 1\n",
    "INCLUDE_REC = 1\n",
    "INCLUDE_GENDER = 1\n",
    "INCLUDE_QUALITY = 0\n",
    "\n",
    "EARLY_CAREER_LEN_LIST_EXT = [3,5,7,9,11,12]\n",
    "RECOGNITION_CUT_OFF_LIST_EXT = [3,5,7,9,11,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_authors.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_increase = pd.DataFrame(index=years)\n",
    "for EARLY_CAREER, RECOGNITION_CUT in zip(EARLY_CAREER_LEN_LIST_EXT, RECOGNITION_CUT_OFF_LIST_EXT):\n",
    "    cols_all, cols_std, categorical_cols = make_cols_lists(INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC, INCLUDE_QUALITY, INCLUDE_GENDER, \n",
    "                                         REMOVE_NONE_AUTHORS, EARLY_CAREER, RECOGNITION_CUT)\n",
    "    feature_table, feature_table2, feature_table3 = run_elastic_net_cohort(credible_authors, cols_all, cols_std, categorical_cols, EARLY_CAREER)\n",
    "    results= make_result_table(feature_table)\n",
    "    results2 = make_result_table(feature_table2)\n",
    "    results3 = make_result_table(feature_table3)\n",
    "    r2_increase[f'h_ind_{EARLY_CAREER}'] = results['r2']\n",
    "    r2_increase[f'cit_{EARLY_CAREER}'] = results2['r2']\n",
    "    r2_increase[f'drop_{EARLY_CAREER}'] = results3['r2']\n",
    "    print(f\"Year: {EARLY_CAREER}\")\n",
    "    print(cols_all)\n",
    "    print(r2_increase[f'h_ind_{EARLY_CAREER}'][2002])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_hind_increase = r2_increase[[f\"h_ind_{x}\" for x in EARLY_CAREER_LEN_LIST]]\n",
    "r2_cit_increase = r2_increase[[f\"cit_{x}\" for x in EARLY_CAREER_LEN_LIST]]\n",
    "r2_drop_increase = r2_increase[[f\"drop_{x}\" for x in EARLY_CAREER_LEN_LIST]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_hind_increase.columns = ['3','5','7','9','11','12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt = plot.init_plotting()\n",
    "fig2 = plt.figure()\n",
    "fig2.patch.set_facecolor('white')\n",
    "ax2 = fig2.add_subplot(1,1,1) #, axisbg=\"white\"\n",
    "colors = ('#DE4C2C', '#3BD64C', '#3B9ED6', '#B73BD6', '#F39C12', '#FFC0CB', '#27AE60', '#48C9B0', '#071019') #'#AAB7B8',\n",
    "markers = []\n",
    "for m in Line2D.markers:\n",
    "    try:\n",
    "        if m != ' ' and m != '':\n",
    "            markers.append(m)\n",
    "    except TypeError:\n",
    "        print(\"Typeerror occured\")\n",
    "        pass\n",
    "p=0\n",
    "for row in r2_hind_increase.index:\n",
    "\n",
    "    cohort = r2_hind_increase.loc[year]\n",
    "    \n",
    "    if row % 5 == 0:\n",
    "        ax2.plot(r2_hind_increase.loc[row], label=row, color=colors[p],\n",
    "                     marker=markers[p], markersize=10)\n",
    "        p = p+1 \n",
    "    else:\n",
    "        ax2.plot(r2_hind_increase.loc[row].values, label=None ,color='grey', alpha=0.5)\n",
    "\n",
    "plt.title(\"Predicting h-index increase\")\n",
    "ax2.set_ylabel(\"R sqaured\", fontweight='bold')\n",
    "ax2.set_xlabel('Number of years observed', fontweight='bold')\n",
    "\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_hind_increase\n",
    "\n",
    "for row in r2_hind_increase.index:\n",
    "    plt.plot(r2_hind_increase.loc[row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_cit_increase.T.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_drop_increase.T.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### predictor diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "h_index = feature_table.transpose().copy()\n",
    "citations = feature_table2.transpose().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(h_index['r2'], label='Increase H index')\n",
    "plt.plot(citations['r2'], label='Increase Citations')\n",
    "print(\"Average difference in r squared\", sum(citations['r2']-h_index['r2'])/len(h_index['r2']))\n",
    "# quality was used as a feature!\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### gender diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# gender coefs\n",
    "plt.plot(results3['gender_m'], label=\"Male\")\n",
    "plt.plot(results3['gender_f'], label=\"Female\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(results3['gender_m'] - results3['gender_f'], label=\"Male-Female diff\")\n",
    "plt.plot(results.index ,np.zeros(len(results)))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### cohort size diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "# ax1.plot(results['r2'], label='r2')\n",
    "ax1.plot(results['adj_r2'], label='adjusted r2', color='C2')\n",
    "ax1.set_ylim([0,1])\n",
    "ax1.set_xlabel('Years')\n",
    "ax1.set_ylabel('R squared', color='C2')\n",
    "ax1.legend(loc=2)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(results['cohort_size'], label='Cohort size', color='C3')\n",
    "ax2.set_ylabel('Cohort size', color='C3')\n",
    "ax2.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### cheating diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "no_cheating = feature_table2.transpose().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cheat_RC5 = feature_table2.transpose().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cheat_quality = feature_table2.transpose().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# How does removing the quality affect the r squared?\n",
    "plt.plot(with_quality['adj_r2'], label='With quality')\n",
    "plt.plot(cheat_RC5['adj_r2'], label='With recognition year 5')\n",
    "plt.plot(no_cheating['adj_r2'], label='No cheating')\n",
    "print(\"Average difference in r squared\", sum(with_quality['adj_r2']-no_cheating['adj_r2'])/len(cheat_quality))\n",
    "print(np.mean)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "avg = sum(cheat_quality['adj_r2']-no_cheating['adj_r2'])/len(no_cheating)\n",
    "plt.plot(cheat_quality['adj_r2']-no_cheating['adj_r2'], label='Difference')\n",
    "plt.plot(no_cheating.index, [avg]*len(no_cheating), label='Average diff')\n",
    "plt.title(\"Difference between quality(15y) and recognition(3y)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### scaler diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "std_scaler = feature_table2.transpose().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rob_scaler = feature_table2.transpose().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# How does changing the scaler affect the r squared?\n",
    "plt.plot(std_scaler['adj_r2'], label='Std')\n",
    "plt.plot(rob_scaler['adj_r2'], label='Rob')\n",
    "print(\"Average difference in r squared\", sum(std_scaler['adj_r2']-rob_scaler['adj_r2'])/len(rob_scaler))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# almost no difference\n",
    "\n",
    "avg = sum(std_scaler['adj_r2']-rob_scaler['adj_r2'])/len(std_scaler)\n",
    "plt.plot(std_scaler['adj_r2']-rob_scaler['adj_r2'], label='Difference')\n",
    "plt.plot(std_scaler.index, [avg]*len(std_scaler), label='Average diff')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# feature_table3.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Best feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression, RFE, RFECV\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def show_kbest(data_frame, target, linear_rel=True, k=4):\n",
    "    \"\"\"\n",
    "    Selecting K-Best features for classification\n",
    "    :param data_frame: A pandas dataFrame with the training data\n",
    "    :param target: target variable name in DataFrame\n",
    "    :param k: desired number of features from the data\n",
    "    :returns feature_scores: scores for each feature in the data as \n",
    "    pandas DataFrame\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    if linear_rel == True: \n",
    "        feat_selector = SelectKBest(f_regression, k=k)\n",
    "        col_name = \"F Score\"\n",
    "    else:\n",
    "        feat_selector = SelectKBest(mutual_info_regression, k=k)\n",
    "        col_name = \"Mutual Information\"\n",
    "    \n",
    "    feat_selector = feat_selector.fit(data_frame, target)\n",
    "    feat_scores = pd.DataFrame()\n",
    "    feat_scores[col_name] = feat_selector.scores_\n",
    "    feat_scores[\"P Value\"] = feat_selector.pvalues_\n",
    "    feat_scores[\"Support\"] = feat_selector.get_support()\n",
    "    feat_scores[\"Attribute\"] = data_frame.columns\n",
    "    \n",
    "    return feat_scores \n",
    "\n",
    "def get_features_rfe(data_frame, target, model,k=5):\n",
    "    \"\"\"\n",
    "    Returns list of features (k specified) selected using RFE for\n",
    "    :param data_frame: A pandas dataFrame with features and labels\n",
    "    :param k: top k features to select  \n",
    "    :returns list: most relevant features \n",
    "    \"\"\"\n",
    "    X = data_frame\n",
    "    y = target\n",
    "    selector = RFE(model, k, step=1)\n",
    "    selector = selector.fit(X, y)\n",
    "#     print(selector.support_)\n",
    "    df = pd.DataFrame({\n",
    "        \"feature\": X.columns,\n",
    "        \"support\": selector.support_\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def get_features_rfecv(data_frame, target, model, cv=3):\n",
    "    \"\"\"\n",
    "    Returns list of features (k specified) selected using RFE for\n",
    "    :param data_frame: A pandas dataFrame with features and labels\n",
    "    :param k: top k features to select  \n",
    "    :returns list: most relevant features \n",
    "    \"\"\"\n",
    "    X = data_frame\n",
    "    y = target\n",
    "    selector = RFECV(model, step=1, cv=cv)\n",
    "    selector = selector.fit(X, y)\n",
    "#     print(selector.support_)\n",
    "    df = pd.DataFrame({\n",
    "        \"feature\": X.columns,\n",
    "        \"support\": selector.support_\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "years = credible_authors.start_year.unique()\n",
    "years = sorted(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = credible_authors.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "categorical_cols = ['gender']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df = df.join(pd.get_dummies(df[categorical_cols]))\n",
    "\n",
    "df.drop(categorical_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Show k best - F regression or mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "linear = True\n",
    "# true - fregression\n",
    "# false - mutual info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params = []\n",
    "for year in years:\n",
    "    df_year = df[df.start_year == year]\n",
    "    df_year = df_year.drop('start_year', axis=1)\n",
    "#     for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "#         for RECOGNITION_CUT in RECOGNITION_CUT_OFF_LIST:\n",
    "#             if RECOGNITION_CUT < EARLY_CAREER: continue\n",
    "    EARLY_CAREER = 3\n",
    "    RECOGNITION_CUT= 5\n",
    "    X_year = df_year[['max_absence-0-3', 'avg_absence-0-3', \n",
    "           'gender_f', 'gender_m', 'gender_none',\n",
    "           f'early_career_degree_{EARLY_CAREER}', \n",
    "           f'early_career_prod_{EARLY_CAREER}',\n",
    "           f'early_career_qual_{EARLY_CAREER}', f'early_career_recognition_EC{EARLY_CAREER}_RC{RECOGNITION_CUT}']]\n",
    "    y_year = df_year['succ_after_15y']\n",
    "    params.append(show_kbest(X_year, y_year, linear, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "selected_f = defaultdict(int)\n",
    "for param in params:\n",
    "    selected = param[param.Support == True]['Attribute'].values\n",
    "    selected_f['total'] += 1\n",
    "#     print(selected)\n",
    "    for select in selected:\n",
    "        selected_f[select] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "selected_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params_rfe = []\n",
    "for year in years:\n",
    "    df_year = df[df.start_year == year]\n",
    "    df_year = df_year.drop('start_year', axis=1)\n",
    "#     for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "#         for RECOGNITION_CUT in RECOGNITION_CUT_OFF_LIST:\n",
    "#             if RECOGNITION_CUT < EARLY_CAREER: continue\n",
    "    EARLY_CAREER = 3\n",
    "    RECOGNITION_CUT= 5\n",
    "    X_year = df_year[[\n",
    "        #'max_absence-0-3', 'avg_absence-0-3', \n",
    "           'gender_f', 'gender_m', 'gender_none',\n",
    "           f'early_career_degree_{EARLY_CAREER}', \n",
    "           f'early_career_prod_{EARLY_CAREER}',\n",
    "           f'early_career_qual_{EARLY_CAREER}', f'early_career_recognition_EC{EARLY_CAREER}_RC{RECOGNITION_CUT}']]\n",
    "    y_year = df_year['succ_after_15y']\n",
    "    params_rfe.append(get_features_rfe(X_year, y_year, LinearRegression(),k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "selected_f = defaultdict(int)\n",
    "for param in params_rfe:\n",
    "    selected = param[param.support == True]['feature'].values\n",
    "    selected_f['total'] += 1\n",
    "#     print(selected)\n",
    "    for select in selected:\n",
    "        selected_f[select] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "selected_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### RFE CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params_rfecv = []\n",
    "for year in years:\n",
    "    df_year = df[df.start_year == year]\n",
    "    df_year = df_year.drop('start_year', axis=1)\n",
    "#     for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "#         for RECOGNITION_CUT in RECOGNITION_CUT_OFF_LIST:\n",
    "#             if RECOGNITION_CUT < EARLY_CAREER: continue\n",
    "    EARLY_CAREER = 3\n",
    "    RECOGNITION_CUT= 5\n",
    "    X_year = df_year[['max_absence-0-3', 'avg_absence-0-3', \n",
    "           'gender_f', 'gender_m', 'gender_none',\n",
    "           f'early_career_degree_{EARLY_CAREER}', \n",
    "           f'early_career_prod_{EARLY_CAREER}',\n",
    "           f'early_career_qual_{EARLY_CAREER}', f'early_career_recognition_EC{EARLY_CAREER}_RC{RECOGNITION_CUT}']]\n",
    "    y_year = df_year['succ_after_15y']\n",
    "    params_rfecv.append(get_features_rfecv(X_year, y_year, LinearRegression(),cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "selected_f = defaultdict(int)\n",
    "for param in params_rfecv:\n",
    "    selected = param[param.support == True]['feature'].values\n",
    "    selected_f['total'] += 1\n",
    "#     print(selected)\n",
    "    for select in selected:\n",
    "        selected_f[select] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "selected_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations_per_year = pd.read_csv('derived-data/paper-citation-count.csv', header=None, names=['pub_id', 'cit_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publications = pd.read_csv('derived-data/author-publications.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# publications.sort_values(by='author').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove authors by career_len, and add start year\n",
    "publications = publications.merge(credible_authors[['author', 'start_year']], on='author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publications = publications[publications.year <= publications.year + MAX_CAREER_LEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# citations_per_year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publications['pub_id'] = shuffle(publications['pub_id']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# publications.sort_values(by='author').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publications = publications.merge(citations_per_year, on='pub_id', how='left')\n",
    "publications = publications.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publications.sort_values(by='author').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_authors[credible_authors.author == \"a min tjoa\"]['succ_after_15y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_authors.set_index('author', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_authors['succ_shuffled'] = publications.groupby('author')['cit_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_authors[['succ_shuffled', 'succ_after_15y']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_authors.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
