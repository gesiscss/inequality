{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, ElasticNet, ElasticNetCV, Lasso, LogisticRegressionCV, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, f1_score, matthews_corrcoef\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "CAREER_LENGTH = 1\n",
    "\n",
    "#EARLY_CAREER_LEN_LIST = [1, 2, 3, 4, 5]\n",
    "EARLY_CAREER_LEN_LIST = [3]\n",
    "EARLY_CAREER = 3\n",
    "#RECOGNITION_CUT_OFF_LIST = [3, 4, 5, 6, 7, 8, 9]\n",
    "RECOGNITION_CUT_OFF_LIST = [3]\n",
    "RECOGNITION_CUT = 3\n",
    "\n",
    "MAX_CAREER_LEN = 15\n",
    "END_YEAR = 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1699352, 83)\n"
     ]
    }
   ],
   "source": [
    "credible_authors = pd.read_csv('derived-data/authors-scientific-extended.csv')\n",
    "print(credible_authors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa4e08692b0>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(credible_authors['h-index_15'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "years = sorted(credible_authors.start_year.unique())\n",
    "COHORT_START_YEARS = [y for y in years if y < (END_YEAR - MAX_CAREER_LEN)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#credible_authors.columns\n",
    "#print(credible_authors.groupby(\"start_year\")['dropped_after_10'].agg('sum'))\n",
    "#print(credible_authors.groupby(\"start_year\")['author'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1699352, 83)\n",
      "1\n",
      "[2001 2009 2011 1992 2017 2002 2003 2010 2008 1979 2007 1995 2016 2015\n",
      " 1986 2005 2012 1998 2006 2013 1999 1980 2014 1988 1996 1970 2004 1994\n",
      " 1997 1987 1982 2000 1990 1989 1985 1974 1977 1993 1991 1975 1984 1983\n",
      " 1973 1972 1971 1981 1978 1976 2018]\n",
      "(292659, 83)\n",
      "[1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000]\n"
     ]
    }
   ],
   "source": [
    "credible_authors = credible_authors[credible_authors.career_length >= CAREER_LENGTH]\n",
    "print(credible_authors.shape)\n",
    "print(CAREER_LENGTH)\n",
    "print(credible_authors.start_year.unique())\n",
    "\n",
    "credible_authors = credible_authors[credible_authors.start_year.isin(COHORT_START_YEARS)]\n",
    "\n",
    "print(credible_authors.shape)\n",
    "print(COHORT_START_YEARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author', 'start_year', 'end_year', 'total_num_pub', 'career_length',\n",
       "       'max_absence-0-15', 'avg_absence-0-15', 'dropped_after_10', 'gender',\n",
       "       'team_size_median_3', 'team_size_mean_3', 'team_size_median_5',\n",
       "       'team_size_mean_5', 'team_size_median_7', 'team_size_mean_7',\n",
       "       'team_size_median_9', 'team_size_mean_9', 'team_size_median_11',\n",
       "       'team_size_mean_11', 'team_size_median_12', 'team_size_mean_12',\n",
       "       'h5_index_max_3', 'deciles_min_3', 'quantiles_min_3', 'quantiles_bin_3',\n",
       "       'h5_index_max_5', 'deciles_min_5', 'quantiles_min_5', 'quantiles_bin_5',\n",
       "       'h5_index_max_7', 'deciles_min_7', 'quantiles_min_7', 'quantiles_bin_7',\n",
       "       'h5_index_max_9', 'deciles_min_9', 'quantiles_min_9', 'quantiles_bin_9',\n",
       "       'h5_index_max_11', 'deciles_min_11', 'quantiles_min_11',\n",
       "       'quantiles_bin_11', 'h5_index_max_12', 'deciles_min_12',\n",
       "       'quantiles_min_12', 'quantiles_bin_12', 'early_career_degree_3',\n",
       "       'early_career_degree_5', 'early_career_degree_7',\n",
       "       'early_career_degree_9', 'early_career_degree_11',\n",
       "       'early_career_degree_12', 'early_career_qual_3', 'early_career_qual_5',\n",
       "       'early_career_qual_7', 'early_career_qual_9', 'early_career_qual_11',\n",
       "       'early_career_qual_12', 'early_career_recognition_EC3_RC3',\n",
       "       'early_career_recognition_EC5_RC5', 'early_career_recognition_EC7_RC7',\n",
       "       'early_career_recognition_EC9_RC9',\n",
       "       'early_career_recognition_EC11_RC11',\n",
       "       'early_career_recognition_EC12_RC12', 'succ_after_15y', 'h-index_3',\n",
       "       'h-index_5', 'h-index_7', 'h-index_9', 'h-index_11', 'h-index_12',\n",
       "       'h-index_15', 'early_career_prod_3', 'early_career_prod_5',\n",
       "       'early_career_prod_7', 'early_career_prod_9', 'early_career_prod_11',\n",
       "       'early_career_prod_12', 'early_career_coauthor_max_hindex_3',\n",
       "       'early_career_coauthor_max_hindex_5',\n",
       "       'early_career_coauthor_max_hindex_7',\n",
       "       'early_career_coauthor_max_hindex_9',\n",
       "       'early_career_coauthor_max_hindex_11',\n",
       "       'early_career_coauthor_max_hindex_12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credible_authors.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: move this to 0. also check it \n",
    "EARLY_CAREER_LEN_LIST_EXT = [3,5,7,9,11,12]\n",
    "RECOGNITION_CUT_OFF_LIST_EXT = [3,5,7,9,11,12]\n",
    "# EARLY_CAREER_LEN_LIST_EXT = [3]\n",
    "# RECOGNITION_CUT_OFF_LIST_EXT = [3]\n",
    "\n",
    "for year in EARLY_CAREER_LEN_LIST_EXT:\n",
    "    credible_authors[f'citation_increase_15_{year}'] = credible_authors['succ_after_15y'] - credible_authors[\n",
    "        f'early_career_recognition_EC{year}_RC{year}']\n",
    "    credible_authors[f'h_index_increase_{year}_{EARLY_CAREER}'] = credible_authors[\n",
    "        f'h-index_{year}'] - credible_authors[f'h-index_{EARLY_CAREER}']\n",
    "    credible_authors[f'h_index_increase_15_{EARLY_CAREER}'] = credible_authors[\n",
    "        f'h-index_15'] - credible_authors[f'h-index_{EARLY_CAREER}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in EARLY_CAREER_LEN_LIST_EXT[1:]:\n",
    "    credible_authors[f'citation_increase_{year}_{EARLY_CAREER}'] = credible_authors[\n",
    "        f'early_career_recognition_EC{year}_RC{year}'] - credible_authors[f'early_career_recognition_EC{EARLY_CAREER}_RC{EARLY_CAREER}']\n",
    "    credible_authors[f'h_index_increase_{year}_{EARLY_CAREER}'] = credible_authors[f'h-index_{year}'] - credible_authors[f'h-index_{EARLY_CAREER}']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true,
    "lines_to_next_cell": 2,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "cols = ['succ_after_15y', 'h_index_increase_15_3', 'citation_increase_15_3', 'max_absence-0-15', \n",
    "        'early_career_prod_3', 'early_career_degree_3', 'early_career_coauthor_max_hindex_12', \n",
    "        'early_career_recognition_EC3_RC3', 'early_career_qual_12']\n",
    "\n",
    "col_names_short = ['succ', 'hindex_incr', 'cit_incr', 'max_abs', \n",
    "        'prod_3', 'degree_3', 'maxh_3', \n",
    "        'rec_3', 'qual_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "cor_qual = credible_authors[cols].corr(method='kendall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>succ_after_15y</th>\n",
       "      <th>h_index_increase_15_3</th>\n",
       "      <th>citation_increase_15_3</th>\n",
       "      <th>max_absence-0-15</th>\n",
       "      <th>early_career_prod_3</th>\n",
       "      <th>early_career_degree_3</th>\n",
       "      <th>early_career_coauthor_max_hindex_12</th>\n",
       "      <th>early_career_recognition_EC3_RC3</th>\n",
       "      <th>early_career_qual_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>succ_after_15y</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.644757</td>\n",
       "      <td>0.960224</td>\n",
       "      <td>-0.542337</td>\n",
       "      <td>0.477676</td>\n",
       "      <td>0.413726</td>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.502084</td>\n",
       "      <td>0.982328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_index_increase_15_3</th>\n",
       "      <td>0.644757</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.686337</td>\n",
       "      <td>-0.666190</td>\n",
       "      <td>0.502945</td>\n",
       "      <td>0.280664</td>\n",
       "      <td>0.509254</td>\n",
       "      <td>0.111535</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citation_increase_15_3</th>\n",
       "      <td>0.960224</td>\n",
       "      <td>0.686337</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.557741</td>\n",
       "      <td>0.474961</td>\n",
       "      <td>0.389224</td>\n",
       "      <td>0.571958</td>\n",
       "      <td>0.435173</td>\n",
       "      <td>0.942939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_absence-0-15</th>\n",
       "      <td>-0.542337</td>\n",
       "      <td>-0.666190</td>\n",
       "      <td>-0.557741</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.555907</td>\n",
       "      <td>-0.187729</td>\n",
       "      <td>-0.455013</td>\n",
       "      <td>-0.203186</td>\n",
       "      <td>-0.529727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>early_career_prod_3</th>\n",
       "      <td>0.477676</td>\n",
       "      <td>0.502945</td>\n",
       "      <td>0.474961</td>\n",
       "      <td>-0.555907</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.322134</td>\n",
       "      <td>0.401059</td>\n",
       "      <td>0.349846</td>\n",
       "      <td>0.478984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>early_career_degree_3</th>\n",
       "      <td>0.413726</td>\n",
       "      <td>0.280664</td>\n",
       "      <td>0.389224</td>\n",
       "      <td>-0.187729</td>\n",
       "      <td>0.322134</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.405335</td>\n",
       "      <td>0.435229</td>\n",
       "      <td>0.420423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>early_career_coauthor_max_hindex_12</th>\n",
       "      <td>0.579609</td>\n",
       "      <td>0.509254</td>\n",
       "      <td>0.571958</td>\n",
       "      <td>-0.455013</td>\n",
       "      <td>0.401059</td>\n",
       "      <td>0.405335</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.374420</td>\n",
       "      <td>0.580100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>early_career_recognition_EC3_RC3</th>\n",
       "      <td>0.502084</td>\n",
       "      <td>0.111535</td>\n",
       "      <td>0.435173</td>\n",
       "      <td>-0.203186</td>\n",
       "      <td>0.349846</td>\n",
       "      <td>0.435229</td>\n",
       "      <td>0.374420</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.509829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>early_career_qual_12</th>\n",
       "      <td>0.982328</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.942939</td>\n",
       "      <td>-0.529727</td>\n",
       "      <td>0.478984</td>\n",
       "      <td>0.420423</td>\n",
       "      <td>0.580100</td>\n",
       "      <td>0.509829</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     succ_after_15y  h_index_increase_15_3  \\\n",
       "succ_after_15y                             1.000000               0.644757   \n",
       "h_index_increase_15_3                      0.644757               1.000000   \n",
       "citation_increase_15_3                     0.960224               0.686337   \n",
       "max_absence-0-15                          -0.542337              -0.666190   \n",
       "early_career_prod_3                        0.477676               0.502945   \n",
       "early_career_degree_3                      0.413726               0.280664   \n",
       "early_career_coauthor_max_hindex_12        0.579609               0.509254   \n",
       "early_career_recognition_EC3_RC3           0.502084               0.111535   \n",
       "early_career_qual_12                       0.982328               0.631579   \n",
       "\n",
       "                                     citation_increase_15_3  max_absence-0-15  \\\n",
       "succ_after_15y                                     0.960224         -0.542337   \n",
       "h_index_increase_15_3                              0.686337         -0.666190   \n",
       "citation_increase_15_3                             1.000000         -0.557741   \n",
       "max_absence-0-15                                  -0.557741          1.000000   \n",
       "early_career_prod_3                                0.474961         -0.555907   \n",
       "early_career_degree_3                              0.389224         -0.187729   \n",
       "early_career_coauthor_max_hindex_12                0.571958         -0.455013   \n",
       "early_career_recognition_EC3_RC3                   0.435173         -0.203186   \n",
       "early_career_qual_12                               0.942939         -0.529727   \n",
       "\n",
       "                                     early_career_prod_3  \\\n",
       "succ_after_15y                                  0.477676   \n",
       "h_index_increase_15_3                           0.502945   \n",
       "citation_increase_15_3                          0.474961   \n",
       "max_absence-0-15                               -0.555907   \n",
       "early_career_prod_3                             1.000000   \n",
       "early_career_degree_3                           0.322134   \n",
       "early_career_coauthor_max_hindex_12             0.401059   \n",
       "early_career_recognition_EC3_RC3                0.349846   \n",
       "early_career_qual_12                            0.478984   \n",
       "\n",
       "                                     early_career_degree_3  \\\n",
       "succ_after_15y                                    0.413726   \n",
       "h_index_increase_15_3                             0.280664   \n",
       "citation_increase_15_3                            0.389224   \n",
       "max_absence-0-15                                 -0.187729   \n",
       "early_career_prod_3                               0.322134   \n",
       "early_career_degree_3                             1.000000   \n",
       "early_career_coauthor_max_hindex_12               0.405335   \n",
       "early_career_recognition_EC3_RC3                  0.435229   \n",
       "early_career_qual_12                              0.420423   \n",
       "\n",
       "                                     early_career_coauthor_max_hindex_12  \\\n",
       "succ_after_15y                                                  0.579609   \n",
       "h_index_increase_15_3                                           0.509254   \n",
       "citation_increase_15_3                                          0.571958   \n",
       "max_absence-0-15                                               -0.455013   \n",
       "early_career_prod_3                                             0.401059   \n",
       "early_career_degree_3                                           0.405335   \n",
       "early_career_coauthor_max_hindex_12                             1.000000   \n",
       "early_career_recognition_EC3_RC3                                0.374420   \n",
       "early_career_qual_12                                            0.580100   \n",
       "\n",
       "                                     early_career_recognition_EC3_RC3  \\\n",
       "succ_after_15y                                               0.502084   \n",
       "h_index_increase_15_3                                        0.111535   \n",
       "citation_increase_15_3                                       0.435173   \n",
       "max_absence-0-15                                            -0.203186   \n",
       "early_career_prod_3                                          0.349846   \n",
       "early_career_degree_3                                        0.435229   \n",
       "early_career_coauthor_max_hindex_12                          0.374420   \n",
       "early_career_recognition_EC3_RC3                             1.000000   \n",
       "early_career_qual_12                                         0.509829   \n",
       "\n",
       "                                     early_career_qual_12  \n",
       "succ_after_15y                                   0.982328  \n",
       "h_index_increase_15_3                            0.631579  \n",
       "citation_increase_15_3                           0.942939  \n",
       "max_absence-0-15                                -0.529727  \n",
       "early_career_prod_3                              0.478984  \n",
       "early_career_degree_3                            0.420423  \n",
       "early_career_coauthor_max_hindex_12              0.580100  \n",
       "early_career_recognition_EC3_RC3                 0.509829  \n",
       "early_career_qual_12                             1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor_qual\n",
    "#cor_qual['succ_after_15y'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true,
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cor_qual, vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,9,1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(col_names_short, rotation=45)\n",
    "ax.set_yticklabels(col_names_short)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#cor = credible_authors.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#cor_qual[f'h_index_increase_15_{EARLY_CAREER}'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sns.heatmap(cor, center=0,\n",
    "#             square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test different predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# test different early career lenghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "year = 1995\n",
    "\n",
    "credible_authors_1991 = credible_authors[credible_authors.start_year == year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "X = credible_authors_1991.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "categorical_cols = ['gender']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    X = X.join(pd.get_dummies(X[categorical_cols]))\n",
    "\n",
    "X.drop(categorical_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def run_linear(func, name):\n",
    "    df = pd.DataFrame(columns=['params', f'r_squared_{name}'])\n",
    "    for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "        for RECOGNITION_CUT in RECOGNITION_CUT_OFF_LIST:\n",
    "            if RECOGNITION_CUT < EARLY_CAREER: continue\n",
    "            H = X[[\n",
    "                #'max_absence-0-3', 'avg_absence-0-3',\n",
    "                   'gender_f', 'gender_m', 'gender_none',\n",
    "                   f'early_career_degree_{EARLY_CAREER}', \n",
    "                   f'early_career_prod_{EARLY_CAREER}',\n",
    "                   f'early_career_qual_{EARLY_CAREER}', f'early_career_recognition_EC{EARLY_CAREER}_RC{RECOGNITION_CUT}']]\n",
    "            reg = func.fit(H, y)\n",
    "            df = df.append({'params': f'EC:{EARLY_CAREER},REC:{RECOGNITION_CUT}',\n",
    "                            f'r_squared_{name}': reg.score(H, y)}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def run_cv(func, name, cv, y_col='succ_after_15y'):\n",
    "    df = pd.DataFrame(columns=['params', f'r_squared_{name}'])\n",
    "    for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "        for RECOGNITION_CUT in RECOGNITION_CUT_OFF_LIST:\n",
    "            if RECOGNITION_CUT < EARLY_CAREER: continue\n",
    "            H = X[[\n",
    "                #'max_absence-0-3', 'avg_absence-0-3',\n",
    "                   'gender_f', 'gender_m', 'gender_none',\n",
    "                   f'early_career_degree_{EARLY_CAREER}', \n",
    "                   f'early_career_prod_{EARLY_CAREER}',\n",
    "                   f'early_career_qual_{EARLY_CAREER}', f'early_career_recognition_EC{EARLY_CAREER}_RC{RECOGNITION_CUT}']]\n",
    "            y = X[y_col]\n",
    "            score = np.mean(cross_val_score(func, H, y, cv=cv, scoring='r2'))\n",
    "            df = df.append({'params': f'EC:{EARLY_CAREER},REC:{RECOGNITION_CUT}',\n",
    "                            f'r_squared_{name}': score}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1 = run_cv(LinearRegression(), 'linear', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# df1_null = run_cv(LinearRegression(), 'linear_null', cv=3, y_col='succ_shuffled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2 = run_cv(ElasticNet(), 'elastic', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df3 = run_cv(ElasticNetCV(cv=3), 'elastic_CV', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df4 = run_cv(Lasso(alpha=0.1), 'lasso', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Decision tree overfits pretty bad. Maybe GridParam Search?\n",
    "df5 = run_cv(DecisionTreeRegressor(), 'tree', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/danielkostic/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df6 = run_cv(RandomForestRegressor(), 'forest', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# df6_null = run_cv(RandomForestRegressor(), 'forest_null', cv=3, y_col='succ_shuffled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfs = [df1, df2, df3, df4, df5, df6] #df1_null, df6_null\n",
    "for df_ in dfs: df_.set_index('params', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r_squared_linear</th>\n",
       "      <th>r_squared_elastic</th>\n",
       "      <th>r_squared_elastic_CV</th>\n",
       "      <th>r_squared_lasso</th>\n",
       "      <th>r_squared_tree</th>\n",
       "      <th>r_squared_forest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EC:3,REC:3</th>\n",
       "      <td>0.37799</td>\n",
       "      <td>0.377128</td>\n",
       "      <td>0.348738</td>\n",
       "      <td>0.378011</td>\n",
       "      <td>-1.332539</td>\n",
       "      <td>0.144151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            r_squared_linear  r_squared_elastic  r_squared_elastic_CV  \\\n",
       "params                                                                  \n",
       "EC:3,REC:3           0.37799           0.377128              0.348738   \n",
       "\n",
       "            r_squared_lasso  r_squared_tree  r_squared_forest  \n",
       "params                                                         \n",
       "EC:3,REC:3         0.378011       -1.332539          0.144151  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0].join(dfs[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EARLY_CAREER = EARLY_CAREER_LEN_LIST[0]\n",
    "# RECOGNITION_CUT = RECOGNITION_CUT_OFF_LIST[0]\n",
    "EARLY_CAREER_LEN_LIST = [3,5,7,9,11,12]\n",
    "RECOGNITION_CUT_OFF_LIST = [3,5,7,9,11,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,RobustScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_percent = credible_authors.groupby('start_year')['dropped_after_10'].sum() / credible_authors.groupby('start_year')['dropped_after_10'].count()\n",
    "dropped_percent = dropped_percent.to_frame().T\n",
    "\n",
    "dropped_percent_agg = credible_authors['dropped_after_10'].sum() / credible_authors['dropped_after_10'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 groups of features: productivity, social capital, quality/rec and gender\n",
    "def make_cols_lists(INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC, INCLUDE_QUALITY, INCLUDE_GENDER, REMOVE_NONE_AUTHORS, \n",
    "                    INCLUDE_VENUE, INCLUDE_YEAR, EARLY_CAREER, RECOGNITION_CUT, dep_var):\n",
    "    categorical_cols = []\n",
    "    cols_std = []\n",
    "\n",
    "    if INCLUDE_YEAR:\n",
    "        cols_std.append(\"start_year\")\n",
    "        \n",
    "    #scale dependant var\n",
    "    if dep_var == \"dropped_after_10\":\n",
    "        categorical_cols.append(dep_var)\n",
    "    else:\n",
    "        cols_std.append(dep_var)\n",
    "\n",
    "    if INCLUDE_PROD:\n",
    "        cols_std.append(f'early_career_prod_{EARLY_CAREER}')\n",
    "\n",
    "    if INCLUDE_SOCIAL:\n",
    "        cols_std.append(f'early_career_degree_{EARLY_CAREER}')\n",
    "        cols_std.append(f'early_career_coauthor_max_hindex_{EARLY_CAREER}')\n",
    "        cols_std.append(f'team_size_median_{EARLY_CAREER}')\n",
    "    #     cols_std.append(f'early_career_coauthor_max_cit_{EARLY_CAREER}')\n",
    "\n",
    "    if INCLUDE_REC:\n",
    "        cols_std.append(f'early_career_recognition_EC{EARLY_CAREER}_RC{RECOGNITION_CUT}')\n",
    "\n",
    "    if INCLUDE_QUALITY:\n",
    "        cols_std.append(f'early_career_qual_{EARLY_CAREER}')\n",
    "\n",
    "    if INCLUDE_GENDER:\n",
    "        categorical_cols.append('gender')\n",
    "\n",
    "    if INCLUDE_VENUE:\n",
    "        cols_std.extend([f'quantiles_bin_{EARLY_CAREER}']) #'deciles_min_3''quantiles_min_3', 'quantiles_bin_3'\n",
    "    \n",
    "    return cols_std, categorical_cols #cols_all, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO we scale data every time we train. Modify to keep data and add remove parameters. Somehow separate the prep from train\n",
    "def scale_columns(X):\n",
    "    if len(X.columns) > 0:\n",
    "        standardized_cols = StandardScaler().fit_transform(X)\n",
    "    else: \n",
    "        standardized_cols = []\n",
    "    return pd.DataFrame(standardized_cols, index=X.index, columns=X.columns)\n",
    "\n",
    "def prepare_data(credible_authors, cols_std, categorical_cols, REMOVE_NONE_AUTHORS):\n",
    "    X = credible_authors[credible_authors.start_year.isin(COHORT_START_YEARS)].copy()\n",
    "    \n",
    "    # Either scale OR INCLUDE start_year as control Var\n",
    "    # scale dependent variables per year --> WE SHOULD ALSO SCALE OUTCOME VAR\n",
    "#     for year in COHORT_START_YEARS:\n",
    "#         X.loc[X.start_year == year, cols_std] = scale_columns(X.loc[X.start_year == year, cols_std])\n",
    "#     scale over whole dataset\n",
    "#     X[cols_std] = scale_columns(X[cols_std])\n",
    "    \n",
    "    # make dummies of categorical cols\n",
    "    if len(categorical_cols)>0:\n",
    "        cat_cols = pd.get_dummies(X[categorical_cols]) \n",
    "        X = X[cols_std].join(cat_cols)\n",
    "    else:\n",
    "        X = X[cols_std]\n",
    "    if REMOVE_NONE_AUTHORS:\n",
    "        X.drop('gender_none' , axis=1)\n",
    "    X['start_year'] = credible_authors['start_year']\n",
    "    return X\n",
    "\n",
    "def run_elastic_net_aggr(credible_authors, cols_std, categorical_cols, INCLUDE_YEAR, REMOVE_NONE_AUTHORS, dep_var):\n",
    "    X = prepare_data(credible_authors, cols_std, categorical_cols, REMOVE_NONE_AUTHORS)\n",
    "    Y = X[dep_var].copy()\n",
    "    X = X.drop(dep_var, axis=1)\n",
    "#     Y = credible_authors[dep_var]\n",
    "   \n",
    "    if not INCLUDE_YEAR:\n",
    "        X = X.drop('start_year' , axis=1)\n",
    "#     else:\n",
    "#         # Robust scaler seems to be a poor choice here. Maybe minmax?\n",
    "#         X['start_year'] = MinMaxScaler().fit_transform(X['start_year'].to_frame())\n",
    "    \n",
    "   \n",
    "    feat_table = run_elastic_net(X, Y)\n",
    "    feat_table = feat_table.set_index(0)\n",
    "    \n",
    "    if dep_var == 'dropped_after_10': \n",
    "        feat_table = feat_table.append(pd.DataFrame(index=['drop_percentage'], data=[dropped_percent_agg], columns=[1]))\n",
    "    return feat_table\n",
    "\n",
    "def run_elastic_net_cohort(credible_authors, cols_std, categorical_cols, REMOVE_NONE_AUTHORS, dep_var):\n",
    "    table_list = []\n",
    "    X = prepare_data(credible_authors, cols_std, categorical_cols, REMOVE_NONE_AUTHORS)\n",
    "    for year in COHORT_START_YEARS:\n",
    "        X_year = X[X.start_year == year]\n",
    "#         y_year = credible_authors[credible_authors.start_year == year][dep_var]\n",
    "        y_year = X_year[dep_var].copy()\n",
    "        X_year = X_year.drop(dep_var, axis=1)\n",
    "        print(year, end=' ')\n",
    "        feat_data = run_elastic_net(X_year.drop('start_year', axis=1), y_year)\n",
    "        feat_data = feat_data.set_index(0)\n",
    "        feat_data.rename(index=str, columns={1: year}, inplace=True)\n",
    "        table_list.append(feat_data)\n",
    "       \n",
    "    table = pd.DataFrame(index=table_list[0].index)\n",
    "    for x in table_list: table=table.join(x)\n",
    "    if dep_var == 'dropped_after_10': table = table.append(dropped_percent)\n",
    "    return table\n",
    "\n",
    "def run_elastic_net(X, y):\n",
    "    # train model and do cross validation\n",
    "\n",
    "    # add dummy var if no features are given\n",
    "    # TODO is this still used?\n",
    "    if X.empty:\n",
    "        X = pd.DataFrame(1, index=np.arange(len(y)), columns=[\"dummy\"])\n",
    "    \n",
    "    \n",
    "    if y.nunique()==2:   \n",
    "        y = y.astype(int)\n",
    "        #f1, average_precision, roc_auc\n",
    "        cv_dict = cross_validate(LogisticRegressionCV(cv=10, penalty='l2', max_iter=200), X, y, scoring=\"average_precision\", cv=10, \n",
    "                                 return_estimator=True, return_train_score=False)\n",
    "        net_coef = pd.DataFrame([es.coef_[0] for es in cv_dict['estimator']], columns=X.columns)\n",
    "#         print(cv_dict)\n",
    "        score = np.mean(cv_dict['test_score'])\n",
    "        score2 = None\n",
    "    else:\n",
    "        cv_dict = cross_validate(ElasticNetCV(cv=10), X, y, scoring=['r2', 'neg_mean_squared_error'], \n",
    "                                 cv=10, return_estimator=True, return_train_score=False)\n",
    "        net_coef = pd.DataFrame([es.coef_ for es in cv_dict['estimator']], columns=X.columns)\n",
    "        score = np.mean(cv_dict['test_r2'])\n",
    "        score2 = np.mean(cv_dict['test_neg_mean_squared_error'])\n",
    "\n",
    "    # save the intercepts\n",
    "    net_intercept = np.mean([es.intercept_ for es in cv_dict['estimator']])\n",
    "    # take the mean and std from coefs\n",
    "    net_coef_mean = net_coef.mean()\n",
    "    net_coef_std = net_coef.std()\n",
    "    rounding = 2\n",
    "    net_coef_mean_std = list(zip(np.round(net_coef_mean.values,rounding), np.round(net_coef_std.values,rounding)))\n",
    "    net_coef_mean_std = [f\"{x[0]}({x[1]})\" for x in net_coef_mean_std]\n",
    "\n",
    "    cohort_size = len(y)\n",
    "    #     num_nonzero_coefs = sum(net2.coef_ != 0)\n",
    "    #     adj_score2 = 1 - (1-score2)*(cohort_size-1)/(cohort_size-num_nonzero_coefs-1)\n",
    "    if score2:\n",
    "        net_coef_mean_std.extend([np.round(net_intercept, rounding), np.round(score, rounding), np.round(score2, rounding), cohort_size])\n",
    "        feat_table = pd.DataFrame(list(zip(np.append(X.columns, ['intercept', 'r2', 'neg_mean_squared_error', 'cohort_size']), net_coef_mean_std)))\n",
    "    else:\n",
    "        net_coef_mean_std.extend([np.round(net_intercept, rounding), np.round(score, rounding), cohort_size])\n",
    "        feat_table = pd.DataFrame(list(zip(np.append(X.columns, ['intercept', 'avg_precision', 'cohort_size']), net_coef_mean_std)))\n",
    "    return feat_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Stuff that we potentially use as outcome Vars\n",
    "# dv_hindex = 'h-index_15'\n",
    "# dv_citations = 'succ_after_15y'\n",
    "\n",
    "dv_hindex_incr = f'h_index_increase_15_{EARLY_CAREER}'\n",
    "dv_citations_incr = f'citation_increase_15_{EARLY_CAREER}'\n",
    "dv_dropped = 'dropped_after_10'\n",
    "\n",
    "DV = dv_hindex_incr\n",
    "\n",
    "# check if outcome vars are plausible\n",
    "# #print(credible_authors.columns)\n",
    "# credible_authors[[\"start_year\", \"succ_after_15y\"]].groupby(\"start_year\").mean().plot()\n",
    "# credible_authors[[\"start_year\", \"h_index_increase_15_3\"]].groupby(\"start_year\").mean().plot()\n",
    "# credible_authors[[\"start_year\", \"citation_increase_15_3\"]].groupby(\"start_year\").mean().plot()\n",
    "# credible_authors[[\"start_year\", \"avg_absence-0-15\"]].groupby(\"start_year\").mean().plot()\n",
    "# credible_authors[[\"start_year\", \"dropped_after_10\"]].groupby(\"start_year\").mean().plot()\n",
    "# credible_authors[[\"start_year\", \"total_num_pub\"]].groupby(\"start_year\").mean().plot()\n",
    "# credible_authors[[\"start_year\", \"career_length\"]].groupby(\"start_year\").mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort Elastic Net Models\n",
    "We compare the predictive performance across cohorts. We should plot R2 and F1 over cohorts.\n",
    "Is predictive performance stable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "code_folding": [
     0,
     8
    ]
   },
   "outputs": [],
   "source": [
    "def make_result_table(feature_table):\n",
    "    results = feature_table.transpose()\n",
    "    #shorten column names\n",
    "    new_cols = dict(zip(results.columns, [col.replace('early_career', 'ec') for col in results.columns]))\n",
    "\n",
    "    results.rename(new_cols, axis='columns', inplace=True)\n",
    "    results.rename({'feature':'cohort','ec_coauthor_max_cit_3': 'ec_coauth_max_cit_3', 'ec_recognition_EC3_RC5':'ec_recog_EC3_RC5'}, axis='columns', inplace=True)\n",
    "    return results\n",
    "def results_to_latex(results, name):\n",
    "    ltx_file = open(f\"results_{name}.tex\", \"w\")\n",
    "    ltx_file.write('\\n'.join(results.to_latex().split('\\n')[5:-7]))\n",
    "    ltx_file.write('\\hline \\n')\n",
    "    ltx_file.write('\\n'.join(results.to_latex().split('\\n')[-7:-3]))\n",
    "    ltx_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "code_folding": [
     0,
     10,
     20,
     30,
     40,
     50,
     61
    ]
   },
   "outputs": [],
   "source": [
    "def get_baseline_vars():\n",
    "    INCLUDE_PROD = 0\n",
    "    INCLUDE_SOCIAL = 0\n",
    "    INCLUDE_REC = 0\n",
    "    INCLUDE_QUALITY = 0\n",
    "    INCLUDE_GENDER = 0\n",
    "    REMOVE_NONE_AUTHORS = 0\n",
    "    INCLUDE_VENUE = 0\n",
    "    INCLUDE_YEAR = 1\n",
    "    return INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC, INCLUDE_QUALITY, INCLUDE_GENDER, REMOVE_NONE_AUTHORS,INCLUDE_VENUE,INCLUDE_YEAR\n",
    "def get_human_cap_vars():\n",
    "    INCLUDE_PROD = 1\n",
    "    INCLUDE_SOCIAL = 0\n",
    "    INCLUDE_REC = 1\n",
    "    INCLUDE_QUALITY = 0\n",
    "    INCLUDE_GENDER = 0\n",
    "    REMOVE_NONE_AUTHORS = 0\n",
    "    INCLUDE_VENUE = 0\n",
    "    INCLUDE_YEAR = 1\n",
    "    return INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC, INCLUDE_QUALITY, INCLUDE_GENDER, REMOVE_NONE_AUTHORS,INCLUDE_VENUE,INCLUDE_YEAR\n",
    "def get_gender_vars():\n",
    "    INCLUDE_PROD = 1\n",
    "    INCLUDE_SOCIAL = 0\n",
    "    INCLUDE_REC = 1\n",
    "    INCLUDE_GENDER = 1\n",
    "    INCLUDE_QUALITY = 0\n",
    "    REMOVE_NONE_AUTHORS = 0\n",
    "    INCLUDE_VENUE = 0\n",
    "    INCLUDE_YEAR = 1\n",
    "    return INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC, INCLUDE_QUALITY, INCLUDE_GENDER, REMOVE_NONE_AUTHORS,INCLUDE_VENUE,INCLUDE_YEAR\n",
    "def get_social_vars():\n",
    "    INCLUDE_PROD = 1\n",
    "    INCLUDE_SOCIAL = 1\n",
    "    INCLUDE_REC = 1\n",
    "    INCLUDE_GENDER = 1\n",
    "    INCLUDE_QUALITY = 0\n",
    "    REMOVE_NONE_AUTHORS = 0\n",
    "    INCLUDE_VENUE = 0\n",
    "    INCLUDE_YEAR = 1\n",
    "    return INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC, INCLUDE_QUALITY, INCLUDE_GENDER, REMOVE_NONE_AUTHORS,INCLUDE_VENUE,INCLUDE_YEAR\n",
    "def get_symbolic_vars():\n",
    "    INCLUDE_PROD = 1\n",
    "    INCLUDE_SOCIAL = 1\n",
    "    INCLUDE_REC = 1\n",
    "    INCLUDE_GENDER = 1\n",
    "    INCLUDE_QUALITY = 0\n",
    "    REMOVE_NONE_AUTHORS = 0\n",
    "    INCLUDE_VENUE = 1\n",
    "    INCLUDE_YEAR = 1\n",
    "    return INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC, INCLUDE_QUALITY, INCLUDE_GENDER, REMOVE_NONE_AUTHORS,INCLUDE_VENUE,INCLUDE_YEAR\n",
    "def get_full_vars():\n",
    "    INCLUDE_PROD = 1\n",
    "    INCLUDE_SOCIAL = 1\n",
    "    INCLUDE_REC = 1\n",
    "    INCLUDE_GENDER = 1\n",
    "    INCLUDE_QUALITY = 1\n",
    "    REMOVE_NONE_AUTHORS = 0\n",
    "    INCLUDE_VENUE = 1\n",
    "    INCLUDE_YEAR = 1\n",
    "    return INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC, INCLUDE_QUALITY, INCLUDE_GENDER, REMOVE_NONE_AUTHORS,INCLUDE_VENUE,INCLUDE_YEAR\n",
    "\n",
    "def elastic_cohort(params_func,EARLY_CAREER, RECOGNITION_CUT, DV):\n",
    "    params = params_func()\n",
    "    cols_std, categorical_cols = make_cols_lists(*params, EARLY_CAREER, RECOGNITION_CUT, DV)\n",
    "    print(cols_std)\n",
    "    REMOVE_NONE_AUTHORS = params[-3]\n",
    "    res = run_elastic_net_cohort(credible_authors, cols_std, categorical_cols, REMOVE_NONE_AUTHORS, DV)\n",
    "    res = make_result_table(res)\n",
    "    return res\n",
    "def elastic_agg(params_func,EARLY_CAREER, RECOGNITION_CUT, DV):\n",
    "    params = params_func()\n",
    "    cols_std, categorical_cols = make_cols_lists(*params, EARLY_CAREER, RECOGNITION_CUT, DV)\n",
    "    INCLUDE_YEAR = params[-1]\n",
    "    REMOVE_NONE_AUTHORS = params[-3]\n",
    "    res_agg = run_elastic_net_aggr(credible_authors, cols_std, categorical_cols, INCLUDE_YEAR, REMOVE_NONE_AUTHORS, DV)\n",
    "    return res_agg\n",
    "# TODO: fix this, add team_size\n",
    "def elastic_agg_all(EARLY_CAREER, RECOGNITION_CUT, DV):\n",
    "    params_func_list = [get_baseline_vars, get_human_cap_vars, get_gender_vars, get_social_vars, get_symbolic_vars, get_full_vars]\n",
    "    res_agg_list = [elastic_agg(params_func,EARLY_CAREER, RECOGNITION_CUT, DV) for params_func in params_func_list]\n",
    "    res_all_agg = pd.DataFrame(index=res_agg_list[-1].index, data=[])\n",
    "    res_all_agg['baseline'] = res_agg_list[0]\n",
    "    res_all_agg['human'] = res_agg_list[1]\n",
    "    res_all_agg['gender'] = res_agg_list[2]\n",
    "    res_all_agg['social'] = res_agg_list[3]\n",
    "    res_all_agg['symbolic'] = res_agg_list[4]\n",
    "    res_all_agg['full_model'] = res_agg_list[5]\n",
    "    if DV == 'dropped_after_10':\n",
    "        reorderlist = ['start_year', 'early_career_prod_3', 'early_career_recognition_EC3_RC3', \n",
    "                   'gender_f', 'gender_m', 'gender_none', \n",
    "                   'early_career_degree_3', 'early_career_coauthor_max_hindex_3', 'team_size_median_3',\n",
    "                   'quantiles_bin_3', 'early_career_qual_3',\n",
    "                   'cohort_size', 'drop_percentage','avg_precision']\n",
    "        res_all_agg = res_all_agg.reindex(reorderlist)\n",
    "        res_all_agg = res_all_agg.fillna('')\n",
    "        res_all_agg['names'] = ['start year', 'productivity', 'recognition', \n",
    "                       'male', 'female', 'none', \n",
    "                       'degree', 'coauthor hindex', 'median team size',\n",
    "                       'top-venue', 'quality',\n",
    "                       'cohort size', '% dropouts','Average precision']\n",
    "    else:\n",
    "        reorderlist = ['start_year', 'early_career_prod_3', 'early_career_recognition_EC3_RC3', \n",
    "                   'gender_f', 'gender_m', 'gender_none', \n",
    "                   'early_career_degree_3', 'early_career_coauthor_max_hindex_3', 'team_size_median_3',\n",
    "                   'quantiles_bin_3', 'early_career_qual_3',\n",
    "                   'cohort_size', 'neg_mean_squared_error', 'intercept','r2']\n",
    "        res_all_agg = res_all_agg.reindex(reorderlist)\n",
    "        res_all_agg = res_all_agg.fillna('')\n",
    "        res_all_agg['names'] = ['start year', 'productivity', 'recognition', \n",
    "                       'male', 'female', 'none', \n",
    "                       'degree', 'coauthor hindex', 'median team size',\n",
    "                       'top-venue', 'quality',\n",
    "                       'cohort size', 'MSE', 'intercept','R2']\n",
    "    res_all_agg = res_all_agg.set_index('names')\n",
    "    return res_all_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['start_year', 'h_index_increase_15_3']\n",
      "1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 ['start_year', 'citation_increase_15_3']\n",
      "1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 "
     ]
    }
   ],
   "source": [
    "res_cohort_base_hind = elastic_cohort(get_baseline_vars, EARLY_CAREER, RECOGNITION_CUT, dv_hindex_incr)\n",
    "res_cohort_base_cita = elastic_cohort(get_baseline_vars, EARLY_CAREER, RECOGNITION_CUT, dv_citations_incr)\n",
    "# res_cohort_base_drop = elastic_cohort(get_baseline_vars, EARLY_CAREER, RECOGNITION_CUT, dv_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "      <th>intercept</th>\n",
       "      <th>r2</th>\n",
       "      <th>neg_mean_squared_error</th>\n",
       "      <th>cohort_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.74</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-1.64</td>\n",
       "      <td>763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.74</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-1.44</td>\n",
       "      <td>981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-1.55</td>\n",
       "      <td>1207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.83</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-1.88</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.72</td>\n",
       "      <td>-0</td>\n",
       "      <td>-1.86</td>\n",
       "      <td>1830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.79</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-1.78</td>\n",
       "      <td>1599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.82</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-2.07</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>1.04</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-2.82</td>\n",
       "      <td>1929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-2.33</td>\n",
       "      <td>1907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>1.06</td>\n",
       "      <td>-0</td>\n",
       "      <td>-3.18</td>\n",
       "      <td>2352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>1.11</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-3.37</td>\n",
       "      <td>2458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>1.11</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-3.65</td>\n",
       "      <td>2817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>3262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>1.28</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-4.23</td>\n",
       "      <td>3721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-3.64</td>\n",
       "      <td>4668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>1.35</td>\n",
       "      <td>-0</td>\n",
       "      <td>-4.72</td>\n",
       "      <td>4821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>1.35</td>\n",
       "      <td>-0</td>\n",
       "      <td>-4.76</td>\n",
       "      <td>5857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>1.36</td>\n",
       "      <td>-0</td>\n",
       "      <td>-4.59</td>\n",
       "      <td>6624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>1.35</td>\n",
       "      <td>-0</td>\n",
       "      <td>-4.73</td>\n",
       "      <td>8364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>1.38</td>\n",
       "      <td>-0</td>\n",
       "      <td>-4.73</td>\n",
       "      <td>9293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>1.37</td>\n",
       "      <td>-0</td>\n",
       "      <td>-5.06</td>\n",
       "      <td>10871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>1.42</td>\n",
       "      <td>-0</td>\n",
       "      <td>-5.02</td>\n",
       "      <td>12430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>1.51</td>\n",
       "      <td>-0</td>\n",
       "      <td>-5.53</td>\n",
       "      <td>13769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>1.55</td>\n",
       "      <td>-0</td>\n",
       "      <td>-5.85</td>\n",
       "      <td>16379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>1.58</td>\n",
       "      <td>-0</td>\n",
       "      <td>-6.24</td>\n",
       "      <td>18423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>1.57</td>\n",
       "      <td>-0</td>\n",
       "      <td>-6.1</td>\n",
       "      <td>19223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>1.61</td>\n",
       "      <td>-0</td>\n",
       "      <td>-6.26</td>\n",
       "      <td>20823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>1.65</td>\n",
       "      <td>-0</td>\n",
       "      <td>-6.46</td>\n",
       "      <td>23263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>1.68</td>\n",
       "      <td>-0</td>\n",
       "      <td>-6.83</td>\n",
       "      <td>26813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>1.75</td>\n",
       "      <td>-0</td>\n",
       "      <td>-7.15</td>\n",
       "      <td>29225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>1.88</td>\n",
       "      <td>-0</td>\n",
       "      <td>-8.09</td>\n",
       "      <td>33591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0        dummy intercept    r2 neg_mean_squared_error cohort_size\n",
       "1970  0.0(0.0)      0.74 -0.01                  -1.64         763\n",
       "1971  0.0(0.0)      0.74 -0.01                  -1.44         981\n",
       "1972  0.0(0.0)      0.76 -0.01                  -1.55        1207\n",
       "1973  0.0(0.0)      0.83 -0.01                  -1.88        1400\n",
       "1974  0.0(0.0)      0.72    -0                  -1.86        1830\n",
       "1975  0.0(0.0)      0.79 -0.01                  -1.78        1599\n",
       "1976  0.0(0.0)      0.82 -0.01                  -2.07        1996\n",
       "1977  0.0(0.0)      1.04 -0.01                  -2.82        1929\n",
       "1978  0.0(0.0)       0.9 -0.01                  -2.33        1907\n",
       "1979  0.0(0.0)      1.06    -0                  -3.18        2352\n",
       "1980  0.0(0.0)      1.11 -0.01                  -3.37        2458\n",
       "1981  0.0(0.0)      1.11 -0.01                  -3.65        2817\n",
       "1982  0.0(0.0)       1.2 -0.01                   -3.9        3262\n",
       "1983  0.0(0.0)      1.28 -0.01                  -4.23        3721\n",
       "1984  0.0(0.0)       1.2 -0.01                  -3.64        4668\n",
       "1985  0.0(0.0)      1.35    -0                  -4.72        4821\n",
       "1986  0.0(0.0)      1.35    -0                  -4.76        5857\n",
       "1987  0.0(0.0)      1.36    -0                  -4.59        6624\n",
       "1988  0.0(0.0)      1.35    -0                  -4.73        8364\n",
       "1989  0.0(0.0)      1.38    -0                  -4.73        9293\n",
       "1990  0.0(0.0)      1.37    -0                  -5.06       10871\n",
       "1991  0.0(0.0)      1.42    -0                  -5.02       12430\n",
       "1992  0.0(0.0)      1.51    -0                  -5.53       13769\n",
       "1993  0.0(0.0)      1.55    -0                  -5.85       16379\n",
       "1994  0.0(0.0)      1.58    -0                  -6.24       18423\n",
       "1995  0.0(0.0)      1.57    -0                   -6.1       19223\n",
       "1996  0.0(0.0)      1.61    -0                  -6.26       20823\n",
       "1997  0.0(0.0)      1.65    -0                  -6.46       23263\n",
       "1998  0.0(0.0)      1.68    -0                  -6.83       26813\n",
       "1999  0.0(0.0)      1.75    -0                  -7.15       29225\n",
       "2000  0.0(0.0)      1.88    -0                  -8.09       33591"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_cohort_base_hind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Human Capital Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['start_year', 'h_index_increase_15_3', 'early_career_prod_3', 'early_career_recognition_EC3_RC3']\n",
      "1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 ['start_year', 'citation_increase_15_3', 'early_career_prod_3', 'early_career_recognition_EC3_RC3']\n",
      "1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 "
     ]
    }
   ],
   "source": [
    "res_cohort_humcap_hind = elastic_cohort(get_human_cap_vars, EARLY_CAREER, RECOGNITION_CUT, dv_hindex_incr)\n",
    "res_cohort_humcap_cita = elastic_cohort(get_human_cap_vars, EARLY_CAREER, RECOGNITION_CUT, dv_citations_incr)\n",
    "# res_cohort_humcap_drop = elastic_cohort(get_human_cap_vars, EARLY_CAREER, RECOGNITION_CUT, dv_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ec_prod_3</th>\n",
       "      <th>ec_recognition_EC3_RC3</th>\n",
       "      <th>intercept</th>\n",
       "      <th>r2</th>\n",
       "      <th>neg_mean_squared_error</th>\n",
       "      <th>cohort_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>0.43(0.02)</td>\n",
       "      <td>0.01(0.0)</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>0.52(0.02)</td>\n",
       "      <td>-0.03(0.01)</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>0.56(0.01)</td>\n",
       "      <td>-0.04(0.01)</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>1207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>0.51(0.02)</td>\n",
       "      <td>-0.0(0.01)</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>0.6(0.01)</td>\n",
       "      <td>0.01(0.0)</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>1830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>0.51(0.01)</td>\n",
       "      <td>0.01(0.01)</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-1.14</td>\n",
       "      <td>1599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>0.61(0.02)</td>\n",
       "      <td>0.04(0.01)</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>0.49(0.05)</td>\n",
       "      <td>0.04(0.01)</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-2.17</td>\n",
       "      <td>1929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>0.57(0.02)</td>\n",
       "      <td>-0.0(0.01)</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-1.53</td>\n",
       "      <td>1907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>0.67(0.02)</td>\n",
       "      <td>0.01(0.0)</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-2.19</td>\n",
       "      <td>2352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>0.7(0.01)</td>\n",
       "      <td>-0.03(0.01)</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-2.29</td>\n",
       "      <td>2458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>0.76(0.03)</td>\n",
       "      <td>-0.01(0.01)</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.34</td>\n",
       "      <td>-2.33</td>\n",
       "      <td>2817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>0.69(0.02)</td>\n",
       "      <td>0.03(0.01)</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-2.55</td>\n",
       "      <td>3262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>0.75(0.01)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-2.89</td>\n",
       "      <td>3721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>0.7(0.01)</td>\n",
       "      <td>0.02(0.01)</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-2.44</td>\n",
       "      <td>4668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>0.72(0.03)</td>\n",
       "      <td>0.03(0.01)</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-3</td>\n",
       "      <td>4821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>0.45(0.12)</td>\n",
       "      <td>0.04(0.01)</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-3.85</td>\n",
       "      <td>5857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>0.72(0.01)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-2.89</td>\n",
       "      <td>6624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>0.71(0.01)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-2.94</td>\n",
       "      <td>8364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>0.7(0.01)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-3</td>\n",
       "      <td>9293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>0.72(0.01)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-3.14</td>\n",
       "      <td>10871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>0.67(0.01)</td>\n",
       "      <td>0.01(0.0)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-3.15</td>\n",
       "      <td>12430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>0.68(0.01)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.34</td>\n",
       "      <td>-3.66</td>\n",
       "      <td>13769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>0.69(0.01)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-3.78</td>\n",
       "      <td>16379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>0.72(0.01)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>-0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-4.01</td>\n",
       "      <td>18423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.71(0.0)</td>\n",
       "      <td>0.01(0.0)</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-4.08</td>\n",
       "      <td>19223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.68(0.0)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.34</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>20823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.69(0.01)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>23263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.72(0.01)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>26813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.69(0.0)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-4.53</td>\n",
       "      <td>29225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>0.71(0.0)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-4.82</td>\n",
       "      <td>33591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0      ec_prod_3 ec_recognition_EC3_RC3 intercept    r2  \\\n",
       "1970  0.43(0.02)              0.01(0.0)      0.02  0.27   \n",
       "1971  0.52(0.02)            -0.03(0.01)     -0.11  0.28   \n",
       "1972  0.56(0.01)            -0.04(0.01)     -0.12  0.32   \n",
       "1973  0.51(0.02)             -0.0(0.01)     -0.04   0.3   \n",
       "1974   0.6(0.01)              0.01(0.0)     -0.25  0.39   \n",
       "1975  0.51(0.01)             0.01(0.01)     -0.13  0.33   \n",
       "1976  0.61(0.02)             0.04(0.01)     -0.23  0.32   \n",
       "1977  0.49(0.05)             0.04(0.01)      0.13  0.22   \n",
       "1978  0.57(0.02)             -0.0(0.01)     -0.07  0.29   \n",
       "1979  0.67(0.02)              0.01(0.0)     -0.12   0.3   \n",
       "1980   0.7(0.01)            -0.03(0.01)     -0.09  0.32   \n",
       "1981  0.76(0.03)            -0.01(0.01)     -0.19  0.34   \n",
       "1982  0.69(0.02)             0.03(0.01)     -0.07  0.33   \n",
       "1983  0.75(0.01)              0.03(0.0)     -0.09  0.31   \n",
       "1984   0.7(0.01)             0.02(0.01)     -0.07  0.32   \n",
       "1985  0.72(0.03)             0.03(0.01)     -0.06  0.37   \n",
       "1986  0.45(0.12)             0.04(0.01)       0.4  0.18   \n",
       "1987  0.72(0.01)              0.03(0.0)     -0.09  0.36   \n",
       "1988  0.71(0.01)              0.03(0.0)     -0.09  0.37   \n",
       "1989   0.7(0.01)              0.03(0.0)     -0.08  0.36   \n",
       "1990  0.72(0.01)              0.03(0.0)     -0.14  0.38   \n",
       "1991  0.67(0.01)              0.01(0.0)      0.01  0.37   \n",
       "1992  0.68(0.01)              0.02(0.0)      0.03  0.34   \n",
       "1993  0.69(0.01)              0.03(0.0)     -0.01  0.35   \n",
       "1994  0.72(0.01)              0.02(0.0)        -0  0.36   \n",
       "1995   0.71(0.0)              0.01(0.0)      0.04  0.33   \n",
       "1996   0.68(0.0)              0.02(0.0)      0.09  0.34   \n",
       "1997  0.69(0.01)              0.02(0.0)      0.12  0.35   \n",
       "1998  0.72(0.01)              0.02(0.0)      0.06  0.37   \n",
       "1999   0.69(0.0)              0.03(0.0)      0.14  0.37   \n",
       "2000   0.71(0.0)              0.03(0.0)      0.16   0.4   \n",
       "\n",
       "0    neg_mean_squared_error cohort_size  \n",
       "1970                   -1.2         763  \n",
       "1971                  -0.96         981  \n",
       "1972                  -1.03        1207  \n",
       "1973                  -1.25        1400  \n",
       "1974                  -1.09        1830  \n",
       "1975                  -1.14        1599  \n",
       "1976                  -1.36        1996  \n",
       "1977                  -2.17        1929  \n",
       "1978                  -1.53        1907  \n",
       "1979                  -2.19        2352  \n",
       "1980                  -2.29        2458  \n",
       "1981                  -2.33        2817  \n",
       "1982                  -2.55        3262  \n",
       "1983                  -2.89        3721  \n",
       "1984                  -2.44        4668  \n",
       "1985                     -3        4821  \n",
       "1986                  -3.85        5857  \n",
       "1987                  -2.89        6624  \n",
       "1988                  -2.94        8364  \n",
       "1989                     -3        9293  \n",
       "1990                  -3.14       10871  \n",
       "1991                  -3.15       12430  \n",
       "1992                  -3.66       13769  \n",
       "1993                  -3.78       16379  \n",
       "1994                  -4.01       18423  \n",
       "1995                  -4.08       19223  \n",
       "1996                   -4.1       20823  \n",
       "1997                   -4.2       23263  \n",
       "1998                   -4.3       26813  \n",
       "1999                  -4.53       29225  \n",
       "2000                  -4.82       33591  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_cohort_humcap_hind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Gender Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['start_year', 'h_index_increase_15_3', 'early_career_prod_3', 'early_career_recognition_EC3_RC3']\n",
      "1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 ['start_year', 'citation_increase_15_3', 'early_career_prod_3', 'early_career_recognition_EC3_RC3']\n",
      "1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 "
     ]
    }
   ],
   "source": [
    "res_cohort_gender_hind = elastic_cohort(get_gender_vars, EARLY_CAREER, RECOGNITION_CUT, dv_hindex_incr)\n",
    "res_cohort_gender_cita = elastic_cohort(get_gender_vars, EARLY_CAREER, RECOGNITION_CUT, dv_citations_incr)\n",
    "# res_cohort_gender_drop = elastic_cohort(get_gender_vars, EARLY_CAREER, RECOGNITION_CUT, dv_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ec_prod_3</th>\n",
       "      <th>ec_recognition_EC3_RC3</th>\n",
       "      <th>gender_f</th>\n",
       "      <th>gender_m</th>\n",
       "      <th>gender_none</th>\n",
       "      <th>intercept</th>\n",
       "      <th>r2</th>\n",
       "      <th>neg_mean_squared_error</th>\n",
       "      <th>cohort_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>0.43(0.02)</td>\n",
       "      <td>0.01(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>0.51(0.02)</td>\n",
       "      <td>-0.03(0.01)</td>\n",
       "      <td>0.03(0.07)</td>\n",
       "      <td>-0.03(0.03)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>0.54(0.01)</td>\n",
       "      <td>-0.03(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>1207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>0.51(0.02)</td>\n",
       "      <td>-0.0(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>0.58(0.01)</td>\n",
       "      <td>0.01(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.02(0.04)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>1830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>0.51(0.01)</td>\n",
       "      <td>0.01(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.04(0.04)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-1.14</td>\n",
       "      <td>1599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>0.6(0.02)</td>\n",
       "      <td>0.04(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>0.49(0.05)</td>\n",
       "      <td>0.04(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.02(0.05)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-2.17</td>\n",
       "      <td>1929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>0.58(0.02)</td>\n",
       "      <td>-0.0(0.01)</td>\n",
       "      <td>-0.23(0.03)</td>\n",
       "      <td>0.03(0.02)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-1.53</td>\n",
       "      <td>1907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>0.66(0.02)</td>\n",
       "      <td>0.01(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-2.19</td>\n",
       "      <td>2352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>0.68(0.02)</td>\n",
       "      <td>-0.02(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>-0.01(0.02)</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-2.29</td>\n",
       "      <td>2458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>0.75(0.03)</td>\n",
       "      <td>-0.0(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.01(0.02)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.34</td>\n",
       "      <td>-2.33</td>\n",
       "      <td>2817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>0.69(0.01)</td>\n",
       "      <td>0.03(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-2.55</td>\n",
       "      <td>3262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>0.74(0.01)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-2.89</td>\n",
       "      <td>3721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>0.69(0.01)</td>\n",
       "      <td>0.02(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.01(0.01)</td>\n",
       "      <td>-0.11(0.05)</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-2.44</td>\n",
       "      <td>4668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>0.72(0.02)</td>\n",
       "      <td>0.03(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.01(0.03)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-3</td>\n",
       "      <td>4821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>0.45(0.11)</td>\n",
       "      <td>0.04(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-3.84</td>\n",
       "      <td>5857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>0.71(0.01)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>-0.0(0.01)</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-2.89</td>\n",
       "      <td>6624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>0.7(0.01)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.01(0.03)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-2.94</td>\n",
       "      <td>8364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>0.69(0.01)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>-0.04(0.05)</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-3</td>\n",
       "      <td>9293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>0.72(0.01)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.04(0.03)</td>\n",
       "      <td>-0.02(0.02)</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-3.14</td>\n",
       "      <td>10871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>0.66(0.01)</td>\n",
       "      <td>0.01(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-3.15</td>\n",
       "      <td>12430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>0.68(0.01)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.01(0.02)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.34</td>\n",
       "      <td>-3.67</td>\n",
       "      <td>13769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>0.69(0.01)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>-0.0(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-3.78</td>\n",
       "      <td>16379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>0.72(0.01)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.04(0.02)</td>\n",
       "      <td>-0.01(0.01)</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-4.01</td>\n",
       "      <td>18423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.71(0.0)</td>\n",
       "      <td>0.01(0.0)</td>\n",
       "      <td>-0.0(0.01)</td>\n",
       "      <td>0.01(0.02)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-4.08</td>\n",
       "      <td>19223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.67(0.01)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>-0.01(0.02)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.01)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.34</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>20823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.68(0.01)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>23263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.72(0.01)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>-0.05(0.03)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.06(0.03)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>26813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.69(0.0)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>-0.05(0.02)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.09(0.04)</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-4.53</td>\n",
       "      <td>29225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>0.71(0.0)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>-0.13(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.09(0.03)</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-4.81</td>\n",
       "      <td>33591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0      ec_prod_3 ec_recognition_EC3_RC3     gender_f     gender_m  \\\n",
       "1970  0.43(0.02)              0.01(0.0)     0.0(0.0)     0.0(0.0)   \n",
       "1971  0.51(0.02)            -0.03(0.01)   0.03(0.07)  -0.03(0.03)   \n",
       "1972  0.54(0.01)            -0.03(0.01)     0.0(0.0)     0.0(0.0)   \n",
       "1973  0.51(0.02)             -0.0(0.01)     0.0(0.0)     0.0(0.0)   \n",
       "1974  0.58(0.01)              0.01(0.0)     0.0(0.0)   0.02(0.04)   \n",
       "1975  0.51(0.01)             0.01(0.01)     0.0(0.0)   0.04(0.04)   \n",
       "1976   0.6(0.02)             0.04(0.01)     0.0(0.0)     0.0(0.0)   \n",
       "1977  0.49(0.05)             0.04(0.01)     0.0(0.0)   0.02(0.05)   \n",
       "1978  0.58(0.02)             -0.0(0.01)  -0.23(0.03)   0.03(0.02)   \n",
       "1979  0.66(0.02)              0.01(0.0)     0.0(0.0)     0.0(0.0)   \n",
       "1980  0.68(0.02)            -0.02(0.01)     0.0(0.0)     0.0(0.0)   \n",
       "1981  0.75(0.03)             -0.0(0.01)     0.0(0.0)   0.01(0.02)   \n",
       "1982  0.69(0.01)             0.03(0.01)     0.0(0.0)     0.0(0.0)   \n",
       "1983  0.74(0.01)              0.03(0.0)     0.0(0.0)     0.0(0.0)   \n",
       "1984  0.69(0.01)             0.02(0.01)     0.0(0.0)   0.01(0.01)   \n",
       "1985  0.72(0.02)             0.03(0.01)     0.0(0.0)   0.01(0.03)   \n",
       "1986  0.45(0.11)             0.04(0.01)     0.0(0.0)     0.0(0.0)   \n",
       "1987  0.71(0.01)              0.03(0.0)     0.0(0.0)     0.0(0.0)   \n",
       "1988   0.7(0.01)              0.03(0.0)     0.0(0.0)   0.01(0.03)   \n",
       "1989  0.69(0.01)              0.03(0.0)     0.0(0.0)     0.0(0.0)   \n",
       "1990  0.72(0.01)              0.03(0.0)     0.0(0.0)   0.04(0.03)   \n",
       "1991  0.66(0.01)              0.01(0.0)     0.0(0.0)     0.0(0.0)   \n",
       "1992  0.68(0.01)              0.02(0.0)     0.0(0.0)   0.01(0.02)   \n",
       "1993  0.69(0.01)              0.03(0.0)   -0.0(0.01)     0.0(0.0)   \n",
       "1994  0.72(0.01)              0.02(0.0)     0.0(0.0)   0.04(0.02)   \n",
       "1995   0.71(0.0)              0.01(0.0)   -0.0(0.01)   0.01(0.02)   \n",
       "1996  0.67(0.01)              0.02(0.0)  -0.01(0.02)     0.0(0.0)   \n",
       "1997  0.68(0.01)              0.02(0.0)     0.0(0.0)     0.0(0.0)   \n",
       "1998  0.72(0.01)              0.02(0.0)  -0.05(0.03)     0.0(0.0)   \n",
       "1999   0.69(0.0)              0.03(0.0)  -0.05(0.02)     0.0(0.0)   \n",
       "2000   0.71(0.0)              0.03(0.0)  -0.13(0.01)     0.0(0.0)   \n",
       "\n",
       "0     gender_none intercept    r2 neg_mean_squared_error cohort_size  \n",
       "1970     0.0(0.0)      0.02  0.27                   -1.2         763  \n",
       "1971     0.0(0.0)     -0.08  0.28                  -0.97         981  \n",
       "1972     0.0(0.0)      -0.1  0.32                  -1.03        1207  \n",
       "1973     0.0(0.0)     -0.04   0.3                  -1.25        1400  \n",
       "1974     0.0(0.0)     -0.24  0.39                  -1.09        1830  \n",
       "1975     0.0(0.0)     -0.14  0.33                  -1.14        1599  \n",
       "1976     0.0(0.0)      -0.2  0.32                  -1.36        1996  \n",
       "1977     0.0(0.0)      0.12  0.22                  -2.17        1929  \n",
       "1978     0.0(0.0)     -0.09  0.29                  -1.53        1907  \n",
       "1979     0.0(0.0)      -0.1   0.3                  -2.19        2352  \n",
       "1980  -0.01(0.02)     -0.07  0.32                  -2.29        2458  \n",
       "1981     0.0(0.0)     -0.18  0.34                  -2.33        2817  \n",
       "1982     0.0(0.0)     -0.07  0.33                  -2.55        3262  \n",
       "1983     0.0(0.0)     -0.08  0.31                  -2.89        3721  \n",
       "1984  -0.11(0.05)     -0.03  0.32                  -2.44        4668  \n",
       "1985     0.0(0.0)     -0.06  0.37                     -3        4821  \n",
       "1986     0.0(0.0)      0.41  0.18                  -3.84        5857  \n",
       "1987   -0.0(0.01)     -0.07  0.36                  -2.89        6624  \n",
       "1988     0.0(0.0)     -0.08  0.37                  -2.94        8364  \n",
       "1989  -0.04(0.05)     -0.05  0.36                     -3        9293  \n",
       "1990  -0.02(0.02)     -0.15  0.38                  -3.14       10871  \n",
       "1991     0.0(0.0)      0.02  0.37                  -3.15       12430  \n",
       "1992     0.0(0.0)      0.04  0.34                  -3.67       13769  \n",
       "1993     0.0(0.0)         0  0.35                  -3.78       16379  \n",
       "1994  -0.01(0.01)     -0.01  0.36                  -4.01       18423  \n",
       "1995     0.0(0.0)      0.05  0.33                  -4.08       19223  \n",
       "1996    0.0(0.01)       0.1  0.34                   -4.1       20823  \n",
       "1997     0.0(0.0)      0.13  0.35                   -4.2       23263  \n",
       "1998   0.06(0.03)      0.05  0.37                   -4.3       26813  \n",
       "1999   0.09(0.04)      0.12  0.37                  -4.53       29225  \n",
       "2000   0.09(0.03)      0.14  0.41                  -4.81       33591  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_cohort_gender_hind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Social Capital Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['start_year', 'h_index_increase_15_3', 'early_career_prod_3', 'early_career_degree_3', 'early_career_coauthor_max_hindex_3', 'early_career_recognition_EC3_RC3']\n",
      "1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 ['start_year', 'citation_increase_15_3', 'early_career_prod_3', 'early_career_degree_3', 'early_career_coauthor_max_hindex_3', 'early_career_recognition_EC3_RC3']\n",
      "1970 1971 1972 1973 1974 1975 1976 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-534489490d66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mres_cohort_soccap_hind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melastic_cohort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_social_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEARLY_CAREER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRECOGNITION_CUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdv_hindex_incr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mres_cohort_soccap_cita\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melastic_cohort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_social_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEARLY_CAREER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRECOGNITION_CUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdv_citations_incr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# res_cohort_soccap_drop = elastic_cohort(get_social_vars, EARLY_CAREER, RECOGNITION_CUT, dv_dropped)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-49e001c31ba0>\u001b[0m in \u001b[0;36melastic_cohort\u001b[0;34m(params_func, EARLY_CAREER, RECOGNITION_CUT, DV)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mREMOVE_NONE_AUTHORS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_elastic_net_cohort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcredible_authors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mREMOVE_NONE_AUTHORS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_result_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-378346bc1316>\u001b[0m in \u001b[0;36mrun_elastic_net_cohort\u001b[0;34m(credible_authors, cols_std, categorical_cols, REMOVE_NONE_AUTHORS, dep_var)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mX_year\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_year\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdep_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mfeat_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_elastic_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_year\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'start_year'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_year\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mfeat_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeat_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mfeat_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-378346bc1316>\u001b[0m in \u001b[0;36mrun_elastic_net\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         cv_dict = cross_validate(ElasticNetCV(cv=10), X, y, scoring=['r2', 'neg_mean_squared_error'], \n\u001b[0;32m---> 88\u001b[0;31m                                  cv=10, return_estimator=True, return_train_score=False)\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mnet_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcv_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'estimator'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_r2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 240\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1205\u001b[0m                 for train, test in folds)\n\u001b[1;32m   1206\u001b[0m         mse_paths = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0;32m-> 1207\u001b[0;31m                              **_joblib_parallel_args(prefer=\"threads\"))(jobs)\n\u001b[0m\u001b[1;32m   1208\u001b[0m         \u001b[0mmse_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_l1_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m         \u001b[0mmean_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py\u001b[0m in \u001b[0;36m_path_residuals\u001b[0;34m(X, y, train, test, path, path_params, alphas, l1_ratio, X_order, dtype)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;31m# X is copied and a reference is kept here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m     \u001b[0malphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpath_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py\u001b[0m in \u001b[0;36menet_path\u001b[0;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[1;32m    472\u001b[0m             model = cd_fast.enet_coordinate_descent_gram(\n\u001b[1;32m    473\u001b[0m                 \u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecompute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m                 tol, rng, random, positive)\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mprecompute\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             model = cd_fast.enet_coordinate_descent(\n",
      "\u001b[0;32msklearn/linear_model/cd_fast.pyx\u001b[0m in \u001b[0;36msklearn.linear_model.cd_fast.enet_coordinate_descent_gram\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mset_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'numpy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \"\"\"Convert the input to an array.\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res_cohort_soccap_hind = elastic_cohort(get_social_vars, EARLY_CAREER, RECOGNITION_CUT, dv_hindex_incr)\n",
    "res_cohort_soccap_cita = elastic_cohort(get_social_vars, EARLY_CAREER, RECOGNITION_CUT, dv_citations_incr)\n",
    "# res_cohort_soccap_drop = elastic_cohort(get_social_vars, EARLY_CAREER, RECOGNITION_CUT, dv_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "res_cohort_soccap_hind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Symbolic Capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "res_cohort_symcap_hind = elastic_cohort(get_symbolic_vars, EARLY_CAREER, RECOGNITION_CUT, dv_hindex_incr)\n",
    "res_cohort_symcap_cita = elastic_cohort(get_symbolic_vars, EARLY_CAREER, RECOGNITION_CUT, dv_citations_incr)\n",
    "# res_cohort_symcap_drop = elastic_cohort(get_symbolic_vars, EARLY_CAREER, RECOGNITION_CUT, dv_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_cohort_symcap_hind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Model (Extended Human Capital)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['start_year', 'h_index_increase_15_3', 'early_career_prod_3', 'early_career_degree_3', 'early_career_coauthor_max_hindex_3', 'team_size_median_3', 'early_career_recognition_EC3_RC3', 'early_career_qual_3', 'quantiles_bin_3']\n",
      "1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 ['start_year', 'citation_increase_15_3', 'early_career_prod_3', 'early_career_degree_3', 'early_career_coauthor_max_hindex_3', 'team_size_median_3', 'early_career_recognition_EC3_RC3', 'early_career_qual_3', 'quantiles_bin_3']\n",
      "1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 "
     ]
    }
   ],
   "source": [
    "res_cohort_full_hind = elastic_cohort(get_full_vars, EARLY_CAREER, RECOGNITION_CUT, dv_hindex_incr)\n",
    "res_cohort_full_cita = elastic_cohort(get_full_vars, EARLY_CAREER, RECOGNITION_CUT, dv_citations_incr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['start_year', 'early_career_prod_3', 'early_career_degree_3', 'early_career_coauthor_max_hindex_3', 'early_career_recognition_EC3_RC3', 'early_career_qual_3', 'quantiles_bin_3']\n",
      "1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ec_prod_3</th>\n",
       "      <th>ec_degree_3</th>\n",
       "      <th>ec_coauthor_max_hindex_3</th>\n",
       "      <th>ec_recognition_EC3_RC3</th>\n",
       "      <th>ec_qual_3</th>\n",
       "      <th>quantiles_bin_3</th>\n",
       "      <th>gender_f</th>\n",
       "      <th>gender_m</th>\n",
       "      <th>gender_none</th>\n",
       "      <th>intercept</th>\n",
       "      <th>avg_precision</th>\n",
       "      <th>cohort_size</th>\n",
       "      <th>dropped_after_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>-0.8(0.04)</td>\n",
       "      <td>0.04(0.03)</td>\n",
       "      <td>-0.26(0.08)</td>\n",
       "      <td>0.05(0.05)</td>\n",
       "      <td>-0.03(0.01)</td>\n",
       "      <td>-0.47(0.08)</td>\n",
       "      <td>-0.21(0.1)</td>\n",
       "      <td>-0.08(0.07)</td>\n",
       "      <td>0.3(0.08)</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.87</td>\n",
       "      <td>763</td>\n",
       "      <td>0.748362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>-1.0(0.08)</td>\n",
       "      <td>0.13(0.03)</td>\n",
       "      <td>0.04(0.06)</td>\n",
       "      <td>0.04(0.01)</td>\n",
       "      <td>-0.01(0.0)</td>\n",
       "      <td>-0.61(0.15)</td>\n",
       "      <td>0.01(0.04)</td>\n",
       "      <td>-0.1(0.05)</td>\n",
       "      <td>0.09(0.05)</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.87</td>\n",
       "      <td>981</td>\n",
       "      <td>0.706422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>-0.77(0.03)</td>\n",
       "      <td>0.29(0.03)</td>\n",
       "      <td>-0.17(0.04)</td>\n",
       "      <td>0.36(0.03)</td>\n",
       "      <td>-0.1(0.01)</td>\n",
       "      <td>-0.54(0.07)</td>\n",
       "      <td>-0.01(0.11)</td>\n",
       "      <td>-0.15(0.07)</td>\n",
       "      <td>0.17(0.06)</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1207</td>\n",
       "      <td>0.731566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>-0.78(0.04)</td>\n",
       "      <td>0.13(0.03)</td>\n",
       "      <td>0.11(0.04)</td>\n",
       "      <td>0.13(0.04)</td>\n",
       "      <td>-0.05(0.01)</td>\n",
       "      <td>-0.39(0.08)</td>\n",
       "      <td>0.12(0.07)</td>\n",
       "      <td>-0.13(0.04)</td>\n",
       "      <td>0.02(0.04)</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1400</td>\n",
       "      <td>0.697143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>-0.9(0.04)</td>\n",
       "      <td>0.03(0.03)</td>\n",
       "      <td>0.01(0.03)</td>\n",
       "      <td>0.13(0.02)</td>\n",
       "      <td>-0.05(0.01)</td>\n",
       "      <td>-0.55(0.06)</td>\n",
       "      <td>0.1(0.06)</td>\n",
       "      <td>-0.06(0.03)</td>\n",
       "      <td>-0.03(0.05)</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1830</td>\n",
       "      <td>0.74918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>-0.94(0.06)</td>\n",
       "      <td>0.0(0.01)</td>\n",
       "      <td>0.0(0.02)</td>\n",
       "      <td>0.18(0.04)</td>\n",
       "      <td>-0.01(0.0)</td>\n",
       "      <td>-0.59(0.11)</td>\n",
       "      <td>-0.0(0.06)</td>\n",
       "      <td>-0.11(0.04)</td>\n",
       "      <td>0.11(0.06)</td>\n",
       "      <td>2.89</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1599</td>\n",
       "      <td>0.699187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>-0.85(0.03)</td>\n",
       "      <td>0.02(0.02)</td>\n",
       "      <td>-0.11(0.03)</td>\n",
       "      <td>0.04(0.02)</td>\n",
       "      <td>-0.01(0.0)</td>\n",
       "      <td>-0.52(0.09)</td>\n",
       "      <td>0.05(0.05)</td>\n",
       "      <td>-0.17(0.04)</td>\n",
       "      <td>0.12(0.05)</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.716433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>-0.87(0.13)</td>\n",
       "      <td>0.02(0.03)</td>\n",
       "      <td>-0.03(0.02)</td>\n",
       "      <td>0.01(0.03)</td>\n",
       "      <td>-0.01(0.01)</td>\n",
       "      <td>-0.27(0.08)</td>\n",
       "      <td>0.05(0.04)</td>\n",
       "      <td>-0.16(0.04)</td>\n",
       "      <td>0.11(0.02)</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1929</td>\n",
       "      <td>0.661483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>-0.83(0.04)</td>\n",
       "      <td>0.1(0.02)</td>\n",
       "      <td>-0.05(0.02)</td>\n",
       "      <td>0.1(0.03)</td>\n",
       "      <td>-0.0(0.0)</td>\n",
       "      <td>-0.41(0.09)</td>\n",
       "      <td>0.27(0.08)</td>\n",
       "      <td>-0.29(0.07)</td>\n",
       "      <td>0.03(0.03)</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1907</td>\n",
       "      <td>0.691662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>-0.9(0.03)</td>\n",
       "      <td>0.08(0.02)</td>\n",
       "      <td>-0.02(0.03)</td>\n",
       "      <td>0.08(0.02)</td>\n",
       "      <td>-0.03(0.0)</td>\n",
       "      <td>-0.69(0.12)</td>\n",
       "      <td>-0.03(0.05)</td>\n",
       "      <td>-0.11(0.02)</td>\n",
       "      <td>0.14(0.04)</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.86</td>\n",
       "      <td>2352</td>\n",
       "      <td>0.673469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>-0.88(0.03)</td>\n",
       "      <td>0.1(0.01)</td>\n",
       "      <td>-0.0(0.03)</td>\n",
       "      <td>0.18(0.03)</td>\n",
       "      <td>-0.02(0.0)</td>\n",
       "      <td>-0.56(0.05)</td>\n",
       "      <td>0.15(0.07)</td>\n",
       "      <td>-0.18(0.04)</td>\n",
       "      <td>0.05(0.04)</td>\n",
       "      <td>2.57</td>\n",
       "      <td>0.84</td>\n",
       "      <td>2458</td>\n",
       "      <td>0.66843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>-0.87(0.09)</td>\n",
       "      <td>0.11(0.02)</td>\n",
       "      <td>-0.09(0.01)</td>\n",
       "      <td>0.1(0.03)</td>\n",
       "      <td>-0.03(0.0)</td>\n",
       "      <td>-0.4(0.11)</td>\n",
       "      <td>0.18(0.08)</td>\n",
       "      <td>-0.2(0.06)</td>\n",
       "      <td>0.02(0.04)</td>\n",
       "      <td>2.66</td>\n",
       "      <td>0.86</td>\n",
       "      <td>2817</td>\n",
       "      <td>0.689031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>-0.84(0.07)</td>\n",
       "      <td>0.01(0.01)</td>\n",
       "      <td>0.05(0.02)</td>\n",
       "      <td>0.13(0.02)</td>\n",
       "      <td>-0.04(0.0)</td>\n",
       "      <td>-0.45(0.11)</td>\n",
       "      <td>-0.08(0.04)</td>\n",
       "      <td>-0.07(0.03)</td>\n",
       "      <td>0.16(0.05)</td>\n",
       "      <td>2.46</td>\n",
       "      <td>0.84</td>\n",
       "      <td>3262</td>\n",
       "      <td>0.656039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>-0.92(0.02)</td>\n",
       "      <td>0.06(0.01)</td>\n",
       "      <td>-0.09(0.01)</td>\n",
       "      <td>0.11(0.02)</td>\n",
       "      <td>-0.02(0.0)</td>\n",
       "      <td>-0.74(0.05)</td>\n",
       "      <td>-0.16(0.04)</td>\n",
       "      <td>-0.06(0.03)</td>\n",
       "      <td>0.24(0.03)</td>\n",
       "      <td>2.71</td>\n",
       "      <td>0.84</td>\n",
       "      <td>3721</td>\n",
       "      <td>0.642032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>-0.9(0.03)</td>\n",
       "      <td>0.05(0.01)</td>\n",
       "      <td>-0.03(0.01)</td>\n",
       "      <td>0.1(0.01)</td>\n",
       "      <td>-0.03(0.0)</td>\n",
       "      <td>-0.51(0.04)</td>\n",
       "      <td>-0.03(0.04)</td>\n",
       "      <td>-0.11(0.04)</td>\n",
       "      <td>0.17(0.04)</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.83</td>\n",
       "      <td>4668</td>\n",
       "      <td>0.648243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>-0.86(0.02)</td>\n",
       "      <td>0.06(0.01)</td>\n",
       "      <td>-0.1(0.01)</td>\n",
       "      <td>0.09(0.01)</td>\n",
       "      <td>-0.02(0.0)</td>\n",
       "      <td>-0.47(0.04)</td>\n",
       "      <td>0.1(0.04)</td>\n",
       "      <td>-0.22(0.02)</td>\n",
       "      <td>0.13(0.03)</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.84</td>\n",
       "      <td>4821</td>\n",
       "      <td>0.636175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>-0.84(0.01)</td>\n",
       "      <td>0.06(0.01)</td>\n",
       "      <td>-0.08(0.01)</td>\n",
       "      <td>0.09(0.01)</td>\n",
       "      <td>-0.01(0.0)</td>\n",
       "      <td>-0.42(0.04)</td>\n",
       "      <td>0.04(0.03)</td>\n",
       "      <td>-0.13(0.02)</td>\n",
       "      <td>0.12(0.02)</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.82</td>\n",
       "      <td>5857</td>\n",
       "      <td>0.637528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>-0.8(0.06)</td>\n",
       "      <td>0.06(0.02)</td>\n",
       "      <td>-0.01(0.01)</td>\n",
       "      <td>0.03(0.01)</td>\n",
       "      <td>-0.02(0.0)</td>\n",
       "      <td>-0.31(0.09)</td>\n",
       "      <td>-0.01(0.02)</td>\n",
       "      <td>-0.05(0.02)</td>\n",
       "      <td>0.07(0.02)</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.81</td>\n",
       "      <td>6624</td>\n",
       "      <td>0.63119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>-0.71(0.03)</td>\n",
       "      <td>0.06(0.01)</td>\n",
       "      <td>-0.07(0.01)</td>\n",
       "      <td>0.1(0.01)</td>\n",
       "      <td>-0.01(0.0)</td>\n",
       "      <td>-0.34(0.08)</td>\n",
       "      <td>0.07(0.03)</td>\n",
       "      <td>-0.1(0.04)</td>\n",
       "      <td>0.05(0.02)</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.81</td>\n",
       "      <td>8364</td>\n",
       "      <td>0.638451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>-0.78(0.03)</td>\n",
       "      <td>0.07(0.01)</td>\n",
       "      <td>-0.06(0.01)</td>\n",
       "      <td>0.01(0.01)</td>\n",
       "      <td>-0.0(0.0)</td>\n",
       "      <td>-0.25(0.05)</td>\n",
       "      <td>-0.07(0.02)</td>\n",
       "      <td>-0.02(0.03)</td>\n",
       "      <td>0.09(0.02)</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.81</td>\n",
       "      <td>9293</td>\n",
       "      <td>0.631335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>-0.73(0.02)</td>\n",
       "      <td>0.03(0.01)</td>\n",
       "      <td>-0.02(0.0)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>-0.01(0.0)</td>\n",
       "      <td>-0.26(0.04)</td>\n",
       "      <td>0.08(0.03)</td>\n",
       "      <td>-0.11(0.02)</td>\n",
       "      <td>0.03(0.02)</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.82</td>\n",
       "      <td>10871</td>\n",
       "      <td>0.645939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>-0.71(0.01)</td>\n",
       "      <td>0.06(0.0)</td>\n",
       "      <td>-0.03(0.01)</td>\n",
       "      <td>0.1(0.01)</td>\n",
       "      <td>-0.01(0.0)</td>\n",
       "      <td>-0.34(0.02)</td>\n",
       "      <td>0.02(0.02)</td>\n",
       "      <td>-0.07(0.02)</td>\n",
       "      <td>0.06(0.03)</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.81</td>\n",
       "      <td>12430</td>\n",
       "      <td>0.629928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>-0.64(0.01)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "      <td>-0.0(0.01)</td>\n",
       "      <td>0.02(0.01)</td>\n",
       "      <td>-0.0(0.0)</td>\n",
       "      <td>-0.31(0.02)</td>\n",
       "      <td>0.05(0.02)</td>\n",
       "      <td>-0.08(0.02)</td>\n",
       "      <td>0.04(0.02)</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.8</td>\n",
       "      <td>13769</td>\n",
       "      <td>0.630547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>-0.64(0.01)</td>\n",
       "      <td>0.05(0.0)</td>\n",
       "      <td>-0.01(0.0)</td>\n",
       "      <td>0.1(0.01)</td>\n",
       "      <td>-0.01(0.0)</td>\n",
       "      <td>-0.28(0.02)</td>\n",
       "      <td>0.12(0.01)</td>\n",
       "      <td>-0.11(0.02)</td>\n",
       "      <td>0.01(0.02)</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.81</td>\n",
       "      <td>16379</td>\n",
       "      <td>0.633006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>-0.59(0.01)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "      <td>-0.01(0.0)</td>\n",
       "      <td>0.08(0.01)</td>\n",
       "      <td>-0.01(0.0)</td>\n",
       "      <td>-0.42(0.02)</td>\n",
       "      <td>0.08(0.02)</td>\n",
       "      <td>-0.06(0.02)</td>\n",
       "      <td>-0.01(0.02)</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.8</td>\n",
       "      <td>18423</td>\n",
       "      <td>0.637735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>-0.62(0.01)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.12(0.01)</td>\n",
       "      <td>-0.01(0.0)</td>\n",
       "      <td>-0.3(0.02)</td>\n",
       "      <td>-0.0(0.02)</td>\n",
       "      <td>-0.02(0.02)</td>\n",
       "      <td>0.04(0.02)</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>19223</td>\n",
       "      <td>0.641627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>-0.56(0.0)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>-0.02(0.0)</td>\n",
       "      <td>0.09(0.01)</td>\n",
       "      <td>-0.01(0.0)</td>\n",
       "      <td>-0.29(0.01)</td>\n",
       "      <td>0.09(0.02)</td>\n",
       "      <td>-0.05(0.02)</td>\n",
       "      <td>0.0(0.02)</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.8</td>\n",
       "      <td>20823</td>\n",
       "      <td>0.631369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>-0.62(0.01)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>-0.0(0.0)</td>\n",
       "      <td>0.08(0.0)</td>\n",
       "      <td>-0.01(0.0)</td>\n",
       "      <td>-0.29(0.03)</td>\n",
       "      <td>0.05(0.02)</td>\n",
       "      <td>-0.02(0.02)</td>\n",
       "      <td>0.0(0.02)</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.8</td>\n",
       "      <td>23263</td>\n",
       "      <td>0.631045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>-0.62(0.01)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.01(0.0)</td>\n",
       "      <td>0.12(0.01)</td>\n",
       "      <td>-0.01(0.0)</td>\n",
       "      <td>-0.32(0.02)</td>\n",
       "      <td>0.15(0.02)</td>\n",
       "      <td>-0.06(0.02)</td>\n",
       "      <td>-0.05(0.01)</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.8</td>\n",
       "      <td>26813</td>\n",
       "      <td>0.622571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>-0.62(0.01)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.07(0.01)</td>\n",
       "      <td>-0.0(0.0)</td>\n",
       "      <td>-0.34(0.03)</td>\n",
       "      <td>0.08(0.02)</td>\n",
       "      <td>0.01(0.02)</td>\n",
       "      <td>-0.06(0.01)</td>\n",
       "      <td>1.97</td>\n",
       "      <td>0.79</td>\n",
       "      <td>29225</td>\n",
       "      <td>0.612113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>-0.59(0.01)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.06(0.0)</td>\n",
       "      <td>-0.0(0.0)</td>\n",
       "      <td>-0.34(0.03)</td>\n",
       "      <td>0.16(0.02)</td>\n",
       "      <td>-0.05(0.02)</td>\n",
       "      <td>-0.08(0.02)</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0.79</td>\n",
       "      <td>33591</td>\n",
       "      <td>0.595814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ec_prod_3 ec_degree_3 ec_coauthor_max_hindex_3 ec_recognition_EC3_RC3  \\\n",
       "1970   -0.8(0.04)  0.04(0.03)              -0.26(0.08)             0.05(0.05)   \n",
       "1971   -1.0(0.08)  0.13(0.03)               0.04(0.06)             0.04(0.01)   \n",
       "1972  -0.77(0.03)  0.29(0.03)              -0.17(0.04)             0.36(0.03)   \n",
       "1973  -0.78(0.04)  0.13(0.03)               0.11(0.04)             0.13(0.04)   \n",
       "1974   -0.9(0.04)  0.03(0.03)               0.01(0.03)             0.13(0.02)   \n",
       "1975  -0.94(0.06)   0.0(0.01)                0.0(0.02)             0.18(0.04)   \n",
       "1976  -0.85(0.03)  0.02(0.02)              -0.11(0.03)             0.04(0.02)   \n",
       "1977  -0.87(0.13)  0.02(0.03)              -0.03(0.02)             0.01(0.03)   \n",
       "1978  -0.83(0.04)   0.1(0.02)              -0.05(0.02)              0.1(0.03)   \n",
       "1979   -0.9(0.03)  0.08(0.02)              -0.02(0.03)             0.08(0.02)   \n",
       "1980  -0.88(0.03)   0.1(0.01)               -0.0(0.03)             0.18(0.03)   \n",
       "1981  -0.87(0.09)  0.11(0.02)              -0.09(0.01)              0.1(0.03)   \n",
       "1982  -0.84(0.07)  0.01(0.01)               0.05(0.02)             0.13(0.02)   \n",
       "1983  -0.92(0.02)  0.06(0.01)              -0.09(0.01)             0.11(0.02)   \n",
       "1984   -0.9(0.03)  0.05(0.01)              -0.03(0.01)              0.1(0.01)   \n",
       "1985  -0.86(0.02)  0.06(0.01)               -0.1(0.01)             0.09(0.01)   \n",
       "1986  -0.84(0.01)  0.06(0.01)              -0.08(0.01)             0.09(0.01)   \n",
       "1987   -0.8(0.06)  0.06(0.02)              -0.01(0.01)             0.03(0.01)   \n",
       "1988  -0.71(0.03)  0.06(0.01)              -0.07(0.01)              0.1(0.01)   \n",
       "1989  -0.78(0.03)  0.07(0.01)              -0.06(0.01)             0.01(0.01)   \n",
       "1990  -0.73(0.02)  0.03(0.01)               -0.02(0.0)              0.02(0.0)   \n",
       "1991  -0.71(0.01)   0.06(0.0)              -0.03(0.01)              0.1(0.01)   \n",
       "1992  -0.64(0.01)   0.04(0.0)               -0.0(0.01)             0.02(0.01)   \n",
       "1993  -0.64(0.01)   0.05(0.0)               -0.01(0.0)              0.1(0.01)   \n",
       "1994  -0.59(0.01)   0.04(0.0)               -0.01(0.0)             0.08(0.01)   \n",
       "1995  -0.62(0.01)   0.02(0.0)                0.02(0.0)             0.12(0.01)   \n",
       "1996   -0.56(0.0)   0.03(0.0)               -0.02(0.0)             0.09(0.01)   \n",
       "1997  -0.62(0.01)   0.03(0.0)                -0.0(0.0)              0.08(0.0)   \n",
       "1998  -0.62(0.01)   0.03(0.0)                0.01(0.0)             0.12(0.01)   \n",
       "1999  -0.62(0.01)   0.03(0.0)                 0.0(0.0)             0.07(0.01)   \n",
       "2000  -0.59(0.01)   0.02(0.0)                 0.0(0.0)              0.06(0.0)   \n",
       "\n",
       "        ec_qual_3 quantiles_bin_3     gender_f     gender_m  gender_none  \\\n",
       "1970  -0.03(0.01)     -0.47(0.08)   -0.21(0.1)  -0.08(0.07)    0.3(0.08)   \n",
       "1971   -0.01(0.0)     -0.61(0.15)   0.01(0.04)   -0.1(0.05)   0.09(0.05)   \n",
       "1972   -0.1(0.01)     -0.54(0.07)  -0.01(0.11)  -0.15(0.07)   0.17(0.06)   \n",
       "1973  -0.05(0.01)     -0.39(0.08)   0.12(0.07)  -0.13(0.04)   0.02(0.04)   \n",
       "1974  -0.05(0.01)     -0.55(0.06)    0.1(0.06)  -0.06(0.03)  -0.03(0.05)   \n",
       "1975   -0.01(0.0)     -0.59(0.11)   -0.0(0.06)  -0.11(0.04)   0.11(0.06)   \n",
       "1976   -0.01(0.0)     -0.52(0.09)   0.05(0.05)  -0.17(0.04)   0.12(0.05)   \n",
       "1977  -0.01(0.01)     -0.27(0.08)   0.05(0.04)  -0.16(0.04)   0.11(0.02)   \n",
       "1978    -0.0(0.0)     -0.41(0.09)   0.27(0.08)  -0.29(0.07)   0.03(0.03)   \n",
       "1979   -0.03(0.0)     -0.69(0.12)  -0.03(0.05)  -0.11(0.02)   0.14(0.04)   \n",
       "1980   -0.02(0.0)     -0.56(0.05)   0.15(0.07)  -0.18(0.04)   0.05(0.04)   \n",
       "1981   -0.03(0.0)      -0.4(0.11)   0.18(0.08)   -0.2(0.06)   0.02(0.04)   \n",
       "1982   -0.04(0.0)     -0.45(0.11)  -0.08(0.04)  -0.07(0.03)   0.16(0.05)   \n",
       "1983   -0.02(0.0)     -0.74(0.05)  -0.16(0.04)  -0.06(0.03)   0.24(0.03)   \n",
       "1984   -0.03(0.0)     -0.51(0.04)  -0.03(0.04)  -0.11(0.04)   0.17(0.04)   \n",
       "1985   -0.02(0.0)     -0.47(0.04)    0.1(0.04)  -0.22(0.02)   0.13(0.03)   \n",
       "1986   -0.01(0.0)     -0.42(0.04)   0.04(0.03)  -0.13(0.02)   0.12(0.02)   \n",
       "1987   -0.02(0.0)     -0.31(0.09)  -0.01(0.02)  -0.05(0.02)   0.07(0.02)   \n",
       "1988   -0.01(0.0)     -0.34(0.08)   0.07(0.03)   -0.1(0.04)   0.05(0.02)   \n",
       "1989    -0.0(0.0)     -0.25(0.05)  -0.07(0.02)  -0.02(0.03)   0.09(0.02)   \n",
       "1990   -0.01(0.0)     -0.26(0.04)   0.08(0.03)  -0.11(0.02)   0.03(0.02)   \n",
       "1991   -0.01(0.0)     -0.34(0.02)   0.02(0.02)  -0.07(0.02)   0.06(0.03)   \n",
       "1992    -0.0(0.0)     -0.31(0.02)   0.05(0.02)  -0.08(0.02)   0.04(0.02)   \n",
       "1993   -0.01(0.0)     -0.28(0.02)   0.12(0.01)  -0.11(0.02)   0.01(0.02)   \n",
       "1994   -0.01(0.0)     -0.42(0.02)   0.08(0.02)  -0.06(0.02)  -0.01(0.02)   \n",
       "1995   -0.01(0.0)      -0.3(0.02)   -0.0(0.02)  -0.02(0.02)   0.04(0.02)   \n",
       "1996   -0.01(0.0)     -0.29(0.01)   0.09(0.02)  -0.05(0.02)    0.0(0.02)   \n",
       "1997   -0.01(0.0)     -0.29(0.03)   0.05(0.02)  -0.02(0.02)    0.0(0.02)   \n",
       "1998   -0.01(0.0)     -0.32(0.02)   0.15(0.02)  -0.06(0.02)  -0.05(0.01)   \n",
       "1999    -0.0(0.0)     -0.34(0.03)   0.08(0.02)   0.01(0.02)  -0.06(0.01)   \n",
       "2000    -0.0(0.0)     -0.34(0.03)   0.16(0.02)  -0.05(0.02)  -0.08(0.02)   \n",
       "\n",
       "     intercept avg_precision cohort_size dropped_after_10  \n",
       "1970      2.79          0.87         763         0.748362  \n",
       "1971      2.96          0.87         981         0.706422  \n",
       "1972      2.58          0.88        1207         0.731566  \n",
       "1973      2.45          0.85        1400         0.697143  \n",
       "1974      3.02          0.88        1830          0.74918  \n",
       "1975      2.89          0.88        1599         0.699187  \n",
       "1976      2.79          0.85        1996         0.716433  \n",
       "1977      2.45          0.83        1929         0.661483  \n",
       "1978      2.55          0.85        1907         0.691662  \n",
       "1979       2.8          0.86        2352         0.673469  \n",
       "1980      2.57          0.84        2458          0.66843  \n",
       "1981      2.66          0.86        2817         0.689031  \n",
       "1982      2.46          0.84        3262         0.656039  \n",
       "1983      2.71          0.84        3721         0.642032  \n",
       "1984      2.54          0.83        4668         0.648243  \n",
       "1985      2.55          0.84        4821         0.636175  \n",
       "1986       2.4          0.82        5857         0.637528  \n",
       "1987      2.22          0.81        6624          0.63119  \n",
       "1988      2.18          0.81        8364         0.638451  \n",
       "1989      2.16          0.81        9293         0.631335  \n",
       "1990      2.27          0.82       10871         0.645939  \n",
       "1991      2.15          0.81       12430         0.629928  \n",
       "1992      2.04           0.8       13769         0.630547  \n",
       "1993      2.07          0.81       16379         0.633006  \n",
       "1994      2.08           0.8       18423         0.637735  \n",
       "1995         2           0.8       19223         0.641627  \n",
       "1996      1.91           0.8       20823         0.631369  \n",
       "1997      1.98           0.8       23263         0.631045  \n",
       "1998      1.99           0.8       26813         0.622571  \n",
       "1999      1.97          0.79       29225         0.612113  \n",
       "2000      1.94          0.79       33591         0.595814  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_cohort_full_drop = elastic_cohort(get_full_vars, EARLY_CAREER, RECOGNITION_CUT, dv_dropped)\n",
    "res_cohort_full_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ec_prod_3</th>\n",
       "      <th>ec_degree_3</th>\n",
       "      <th>ec_coauthor_max_hindex_3</th>\n",
       "      <th>team_size_median_3</th>\n",
       "      <th>ec_recognition_EC3_RC3</th>\n",
       "      <th>ec_qual_3</th>\n",
       "      <th>quantiles_bin_3</th>\n",
       "      <th>gender_f</th>\n",
       "      <th>gender_m</th>\n",
       "      <th>gender_none</th>\n",
       "      <th>intercept</th>\n",
       "      <th>r2</th>\n",
       "      <th>neg_mean_squared_error</th>\n",
       "      <th>cohort_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>0.26(0.02)</td>\n",
       "      <td>0.12(0.02)</td>\n",
       "      <td>0.15(0.02)</td>\n",
       "      <td>-0.15(0.01)</td>\n",
       "      <td>-0.28(0.02)</td>\n",
       "      <td>0.06(0.01)</td>\n",
       "      <td>0.09(0.02)</td>\n",
       "      <td>0.06(0.06)</td>\n",
       "      <td>-0.03(0.02)</td>\n",
       "      <td>0.0(0.01)</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>0.29(0.02)</td>\n",
       "      <td>0.07(0.01)</td>\n",
       "      <td>0.07(0.02)</td>\n",
       "      <td>-0.06(0.0)</td>\n",
       "      <td>-0.23(0.01)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "      <td>0.21(0.02)</td>\n",
       "      <td>0.06(0.05)</td>\n",
       "      <td>-0.05(0.02)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>0.28(0.01)</td>\n",
       "      <td>0.1(0.01)</td>\n",
       "      <td>0.05(0.02)</td>\n",
       "      <td>-0.07(0.01)</td>\n",
       "      <td>-0.27(0.01)</td>\n",
       "      <td>0.06(0.0)</td>\n",
       "      <td>0.13(0.01)</td>\n",
       "      <td>-0.02(0.02)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.43</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>1207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>0.3(0.01)</td>\n",
       "      <td>0.11(0.01)</td>\n",
       "      <td>-0.0(0.01)</td>\n",
       "      <td>-0.05(0.01)</td>\n",
       "      <td>-0.26(0.02)</td>\n",
       "      <td>0.06(0.0)</td>\n",
       "      <td>0.13(0.02)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>0.33(0.01)</td>\n",
       "      <td>0.02(0.01)</td>\n",
       "      <td>0.07(0.01)</td>\n",
       "      <td>-0.03(0.0)</td>\n",
       "      <td>-0.13(0.01)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.29(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.01(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.43</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>1830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>0.3(0.01)</td>\n",
       "      <td>0.11(0.01)</td>\n",
       "      <td>0.1(0.01)</td>\n",
       "      <td>-0.07(0.0)</td>\n",
       "      <td>-0.17(0.02)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.27(0.01)</td>\n",
       "      <td>-0.03(0.03)</td>\n",
       "      <td>0.03(0.02)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.43</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>1599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>0.38(0.01)</td>\n",
       "      <td>0.06(0.0)</td>\n",
       "      <td>0.12(0.01)</td>\n",
       "      <td>-0.06(0.0)</td>\n",
       "      <td>-0.15(0.01)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.21(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.01)</td>\n",
       "      <td>-0.01(0.01)</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>0.29(0.03)</td>\n",
       "      <td>0.11(0.01)</td>\n",
       "      <td>0.07(0.01)</td>\n",
       "      <td>-0.11(0.01)</td>\n",
       "      <td>-0.19(0.01)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "      <td>0.18(0.03)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.03(0.03)</td>\n",
       "      <td>-0.0(0.0)</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-1.01</td>\n",
       "      <td>1929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>0.28(0.01)</td>\n",
       "      <td>0.06(0.01)</td>\n",
       "      <td>0.1(0.01)</td>\n",
       "      <td>-0.05(0.01)</td>\n",
       "      <td>-0.21(0.01)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "      <td>0.27(0.01)</td>\n",
       "      <td>-0.05(0.02)</td>\n",
       "      <td>0.04(0.02)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>1907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>0.37(0.01)</td>\n",
       "      <td>0.05(0.01)</td>\n",
       "      <td>0.1(0.01)</td>\n",
       "      <td>-0.08(0.01)</td>\n",
       "      <td>-0.28(0.01)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "      <td>0.32(0.02)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.02(0.02)</td>\n",
       "      <td>-0.0(0.01)</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>2352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>0.38(0.01)</td>\n",
       "      <td>0.03(0.01)</td>\n",
       "      <td>0.13(0.01)</td>\n",
       "      <td>-0.06(0.0)</td>\n",
       "      <td>-0.24(0.01)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.32(0.02)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>-0.0(0.0)</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>2458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>0.39(0.01)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.06(0.01)</td>\n",
       "      <td>-0.08(0.0)</td>\n",
       "      <td>-0.24(0.01)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "      <td>0.25(0.02)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.04(0.02)</td>\n",
       "      <td>-0.03(0.02)</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>2817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>0.33(0.01)</td>\n",
       "      <td>0.05(0.01)</td>\n",
       "      <td>0.09(0.01)</td>\n",
       "      <td>-0.04(0.01)</td>\n",
       "      <td>-0.23(0.01)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "      <td>0.33(0.02)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>-0.0(0.0)</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-1</td>\n",
       "      <td>3262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>0.37(0.01)</td>\n",
       "      <td>0.07(0.01)</td>\n",
       "      <td>0.06(0.01)</td>\n",
       "      <td>-0.1(0.01)</td>\n",
       "      <td>-0.21(0.01)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.31(0.02)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>-0.04(0.01)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.34</td>\n",
       "      <td>-1.11</td>\n",
       "      <td>3721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>0.34(0.01)</td>\n",
       "      <td>0.05(0.01)</td>\n",
       "      <td>0.09(0.01)</td>\n",
       "      <td>-0.05(0.0)</td>\n",
       "      <td>-0.12(0.04)</td>\n",
       "      <td>0.02(0.01)</td>\n",
       "      <td>0.29(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.01(0.01)</td>\n",
       "      <td>-0.04(0.02)</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-1</td>\n",
       "      <td>4668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>0.34(0.01)</td>\n",
       "      <td>0.06(0.0)</td>\n",
       "      <td>0.1(0.01)</td>\n",
       "      <td>-0.05(0.0)</td>\n",
       "      <td>-0.22(0.01)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "      <td>0.22(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.03(0.01)</td>\n",
       "      <td>-0.0(0.01)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.44</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>4821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>0.27(0.04)</td>\n",
       "      <td>0.09(0.01)</td>\n",
       "      <td>0.08(0.01)</td>\n",
       "      <td>-0.12(0.01)</td>\n",
       "      <td>-0.13(0.01)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.17(0.02)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>5857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>0.34(0.0)</td>\n",
       "      <td>0.05(0.0)</td>\n",
       "      <td>0.09(0.0)</td>\n",
       "      <td>-0.08(0.0)</td>\n",
       "      <td>-0.18(0.01)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.22(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>-0.0(0.01)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-1</td>\n",
       "      <td>6624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>0.31(0.01)</td>\n",
       "      <td>0.05(0.0)</td>\n",
       "      <td>0.07(0.0)</td>\n",
       "      <td>-0.11(0.0)</td>\n",
       "      <td>-0.19(0.01)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.18(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.03(0.01)</td>\n",
       "      <td>-0.0(0.01)</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>8364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>0.34(0.0)</td>\n",
       "      <td>0.05(0.0)</td>\n",
       "      <td>0.1(0.01)</td>\n",
       "      <td>-0.09(0.0)</td>\n",
       "      <td>-0.08(0.02)</td>\n",
       "      <td>0.01(0.0)</td>\n",
       "      <td>0.15(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>-0.03(0.01)</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>9293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>0.31(0.0)</td>\n",
       "      <td>0.06(0.0)</td>\n",
       "      <td>0.08(0.0)</td>\n",
       "      <td>-0.07(0.0)</td>\n",
       "      <td>-0.2(0.0)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.15(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.02(0.01)</td>\n",
       "      <td>-0.01(0.01)</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.43</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>10871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>0.29(0.01)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "      <td>0.09(0.0)</td>\n",
       "      <td>-0.07(0.0)</td>\n",
       "      <td>-0.18(0.0)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.15(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>-0.01(0.01)</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>12430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>0.31(0.0)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "      <td>0.07(0.0)</td>\n",
       "      <td>-0.06(0.0)</td>\n",
       "      <td>-0.14(0.01)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.13(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-1.15</td>\n",
       "      <td>13769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>0.32(0.01)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.08(0.0)</td>\n",
       "      <td>-0.05(0.0)</td>\n",
       "      <td>-0.19(0.01)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.13(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>16379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>0.33(0.0)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.09(0.0)</td>\n",
       "      <td>-0.05(0.0)</td>\n",
       "      <td>-0.16(0.01)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.15(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>-0.0(0.0)</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-1.28</td>\n",
       "      <td>18423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.33(0.0)</td>\n",
       "      <td>0.04(0.0)</td>\n",
       "      <td>0.07(0.0)</td>\n",
       "      <td>-0.07(0.0)</td>\n",
       "      <td>-0.17(0.0)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.13(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>19223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.32(0.0)</td>\n",
       "      <td>0.05(0.0)</td>\n",
       "      <td>0.08(0.0)</td>\n",
       "      <td>-0.07(0.0)</td>\n",
       "      <td>-0.16(0.01)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.14(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-1.42</td>\n",
       "      <td>20823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.33(0.0)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.08(0.0)</td>\n",
       "      <td>-0.06(0.0)</td>\n",
       "      <td>-0.17(0.0)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.18(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>23263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.39(0.0)</td>\n",
       "      <td>0.01(0.0)</td>\n",
       "      <td>0.1(0.0)</td>\n",
       "      <td>-0.02(0.0)</td>\n",
       "      <td>-0.15(0.01)</td>\n",
       "      <td>0.01(0.0)</td>\n",
       "      <td>0.23(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-1.79</td>\n",
       "      <td>26813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.39(0.0)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.1(0.0)</td>\n",
       "      <td>-0.06(0.0)</td>\n",
       "      <td>-0.15(0.01)</td>\n",
       "      <td>0.01(0.0)</td>\n",
       "      <td>0.22(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-2.08</td>\n",
       "      <td>29225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>0.41(0.0)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.11(0.0)</td>\n",
       "      <td>-0.06(0.0)</td>\n",
       "      <td>-0.13(0.01)</td>\n",
       "      <td>0.01(0.0)</td>\n",
       "      <td>0.14(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-2.34</td>\n",
       "      <td>33591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0      ec_prod_3 ec_degree_3 ec_coauthor_max_hindex_3 team_size_median_3  \\\n",
       "1970  0.26(0.02)  0.12(0.02)               0.15(0.02)        -0.15(0.01)   \n",
       "1971  0.29(0.02)  0.07(0.01)               0.07(0.02)         -0.06(0.0)   \n",
       "1972  0.28(0.01)   0.1(0.01)               0.05(0.02)        -0.07(0.01)   \n",
       "1973   0.3(0.01)  0.11(0.01)               -0.0(0.01)        -0.05(0.01)   \n",
       "1974  0.33(0.01)  0.02(0.01)               0.07(0.01)         -0.03(0.0)   \n",
       "1975   0.3(0.01)  0.11(0.01)                0.1(0.01)         -0.07(0.0)   \n",
       "1976  0.38(0.01)   0.06(0.0)               0.12(0.01)         -0.06(0.0)   \n",
       "1977  0.29(0.03)  0.11(0.01)               0.07(0.01)        -0.11(0.01)   \n",
       "1978  0.28(0.01)  0.06(0.01)                0.1(0.01)        -0.05(0.01)   \n",
       "1979  0.37(0.01)  0.05(0.01)                0.1(0.01)        -0.08(0.01)   \n",
       "1980  0.38(0.01)  0.03(0.01)               0.13(0.01)         -0.06(0.0)   \n",
       "1981  0.39(0.01)   0.03(0.0)               0.06(0.01)         -0.08(0.0)   \n",
       "1982  0.33(0.01)  0.05(0.01)               0.09(0.01)        -0.04(0.01)   \n",
       "1983  0.37(0.01)  0.07(0.01)               0.06(0.01)         -0.1(0.01)   \n",
       "1984  0.34(0.01)  0.05(0.01)               0.09(0.01)         -0.05(0.0)   \n",
       "1985  0.34(0.01)   0.06(0.0)                0.1(0.01)         -0.05(0.0)   \n",
       "1986  0.27(0.04)  0.09(0.01)               0.08(0.01)        -0.12(0.01)   \n",
       "1987   0.34(0.0)   0.05(0.0)                0.09(0.0)         -0.08(0.0)   \n",
       "1988  0.31(0.01)   0.05(0.0)                0.07(0.0)         -0.11(0.0)   \n",
       "1989   0.34(0.0)   0.05(0.0)                0.1(0.01)         -0.09(0.0)   \n",
       "1990   0.31(0.0)   0.06(0.0)                0.08(0.0)         -0.07(0.0)   \n",
       "1991  0.29(0.01)   0.04(0.0)                0.09(0.0)         -0.07(0.0)   \n",
       "1992   0.31(0.0)   0.04(0.0)                0.07(0.0)         -0.06(0.0)   \n",
       "1993  0.32(0.01)   0.03(0.0)                0.08(0.0)         -0.05(0.0)   \n",
       "1994   0.33(0.0)   0.03(0.0)                0.09(0.0)         -0.05(0.0)   \n",
       "1995   0.33(0.0)   0.04(0.0)                0.07(0.0)         -0.07(0.0)   \n",
       "1996   0.32(0.0)   0.05(0.0)                0.08(0.0)         -0.07(0.0)   \n",
       "1997   0.33(0.0)   0.03(0.0)                0.08(0.0)         -0.06(0.0)   \n",
       "1998   0.39(0.0)   0.01(0.0)                 0.1(0.0)         -0.02(0.0)   \n",
       "1999   0.39(0.0)   0.03(0.0)                 0.1(0.0)         -0.06(0.0)   \n",
       "2000   0.41(0.0)   0.03(0.0)                0.11(0.0)         -0.06(0.0)   \n",
       "\n",
       "0    ec_recognition_EC3_RC3   ec_qual_3 quantiles_bin_3     gender_f  \\\n",
       "1970            -0.28(0.02)  0.06(0.01)      0.09(0.02)   0.06(0.06)   \n",
       "1971            -0.23(0.01)   0.04(0.0)      0.21(0.02)   0.06(0.05)   \n",
       "1972            -0.27(0.01)   0.06(0.0)      0.13(0.01)  -0.02(0.02)   \n",
       "1973            -0.26(0.02)   0.06(0.0)      0.13(0.02)     0.0(0.0)   \n",
       "1974            -0.13(0.01)   0.03(0.0)      0.29(0.01)     0.0(0.0)   \n",
       "1975            -0.17(0.02)   0.02(0.0)      0.27(0.01)  -0.03(0.03)   \n",
       "1976            -0.15(0.01)   0.02(0.0)      0.21(0.01)     0.0(0.0)   \n",
       "1977            -0.19(0.01)   0.04(0.0)      0.18(0.03)     0.0(0.0)   \n",
       "1978            -0.21(0.01)   0.04(0.0)      0.27(0.01)  -0.05(0.02)   \n",
       "1979            -0.28(0.01)   0.04(0.0)      0.32(0.02)     0.0(0.0)   \n",
       "1980            -0.24(0.01)   0.03(0.0)      0.32(0.02)     0.0(0.0)   \n",
       "1981            -0.24(0.01)   0.04(0.0)      0.25(0.02)     0.0(0.0)   \n",
       "1982            -0.23(0.01)   0.04(0.0)      0.33(0.02)     0.0(0.0)   \n",
       "1983            -0.21(0.01)   0.03(0.0)      0.31(0.02)     0.0(0.0)   \n",
       "1984            -0.12(0.04)  0.02(0.01)      0.29(0.01)     0.0(0.0)   \n",
       "1985            -0.22(0.01)   0.04(0.0)      0.22(0.01)     0.0(0.0)   \n",
       "1986            -0.13(0.01)   0.02(0.0)      0.17(0.02)     0.0(0.0)   \n",
       "1987            -0.18(0.01)   0.03(0.0)       0.22(0.0)     0.0(0.0)   \n",
       "1988            -0.19(0.01)   0.03(0.0)      0.18(0.01)     0.0(0.0)   \n",
       "1989            -0.08(0.02)   0.01(0.0)      0.15(0.01)     0.0(0.0)   \n",
       "1990              -0.2(0.0)   0.03(0.0)      0.15(0.01)     0.0(0.0)   \n",
       "1991             -0.18(0.0)   0.02(0.0)      0.15(0.01)     0.0(0.0)   \n",
       "1992            -0.14(0.01)   0.02(0.0)      0.13(0.01)     0.0(0.0)   \n",
       "1993            -0.19(0.01)   0.03(0.0)      0.13(0.01)     0.0(0.0)   \n",
       "1994            -0.16(0.01)   0.02(0.0)      0.15(0.01)     0.0(0.0)   \n",
       "1995             -0.17(0.0)   0.02(0.0)       0.13(0.0)     0.0(0.0)   \n",
       "1996            -0.16(0.01)   0.02(0.0)      0.14(0.01)     0.0(0.0)   \n",
       "1997             -0.17(0.0)   0.02(0.0)      0.18(0.01)     0.0(0.0)   \n",
       "1998            -0.15(0.01)   0.01(0.0)      0.23(0.01)     0.0(0.0)   \n",
       "1999            -0.15(0.01)   0.01(0.0)      0.22(0.01)     0.0(0.0)   \n",
       "2000            -0.13(0.01)   0.01(0.0)      0.14(0.01)     0.0(0.0)   \n",
       "\n",
       "0        gender_m  gender_none intercept    r2 neg_mean_squared_error  \\\n",
       "1970  -0.03(0.02)    0.0(0.01)      0.29  0.35                  -0.71   \n",
       "1971  -0.05(0.02)     0.0(0.0)      0.07  0.32                  -0.62   \n",
       "1972     0.0(0.0)     0.0(0.0)       0.1  0.43                  -0.59   \n",
       "1973     0.0(0.0)     0.0(0.0)      0.07   0.4                  -0.67   \n",
       "1974   0.01(0.01)     0.0(0.0)     -0.11  0.43                  -0.62   \n",
       "1975   0.03(0.02)     0.0(0.0)     -0.05  0.43                  -0.57   \n",
       "1976    0.0(0.01)  -0.01(0.01)     -0.09  0.36                  -0.69   \n",
       "1977   0.03(0.03)    -0.0(0.0)      0.17  0.32                  -1.01   \n",
       "1978   0.04(0.02)     0.0(0.0)     -0.02   0.4                  -0.66   \n",
       "1979   0.02(0.02)   -0.0(0.01)     -0.03  0.37                  -0.92   \n",
       "1980     0.0(0.0)    -0.0(0.0)     -0.03  0.38                  -0.94   \n",
       "1981   0.04(0.02)  -0.03(0.02)     -0.02  0.42                  -0.85   \n",
       "1982     0.0(0.0)    -0.0(0.0)     -0.02  0.38                     -1   \n",
       "1983     0.0(0.0)  -0.04(0.01)       0.1  0.34                  -1.11   \n",
       "1984   0.01(0.01)  -0.04(0.02)     -0.02  0.32                     -1   \n",
       "1985   0.03(0.01)   -0.0(0.01)      0.01  0.44                  -0.99   \n",
       "1986     0.0(0.0)     0.0(0.0)      0.33   0.3                  -1.25   \n",
       "1987     0.0(0.0)   -0.0(0.01)       0.1  0.41                     -1   \n",
       "1988   0.03(0.01)   -0.0(0.01)      0.22  0.42                  -0.96   \n",
       "1989     0.0(0.0)  -0.03(0.01)      0.17  0.37                  -1.02   \n",
       "1990   0.02(0.01)  -0.01(0.01)      0.12  0.43                  -0.99   \n",
       "1991     0.0(0.0)  -0.01(0.01)      0.22  0.39                  -0.99   \n",
       "1992     0.0(0.0)     0.0(0.0)      0.17  0.37                  -1.15   \n",
       "1993     0.0(0.0)     0.0(0.0)      0.19   0.4                   -1.2   \n",
       "1994     0.0(0.0)    -0.0(0.0)      0.15  0.39                  -1.28   \n",
       "1995     0.0(0.0)     0.0(0.0)      0.21  0.36                  -1.36   \n",
       "1996     0.0(0.0)     0.0(0.0)      0.26  0.38                  -1.42   \n",
       "1997     0.0(0.0)     0.0(0.0)      0.24  0.39                   -1.5   \n",
       "1998     0.0(0.0)     0.0(0.0)      0.07  0.38                  -1.79   \n",
       "1999     0.0(0.0)     0.0(0.0)      0.21  0.39                  -2.08   \n",
       "2000     0.0(0.0)     0.0(0.0)      0.28  0.42                  -2.34   \n",
       "\n",
       "0    cohort_size  \n",
       "1970         763  \n",
       "1971         981  \n",
       "1972        1207  \n",
       "1973        1400  \n",
       "1974        1830  \n",
       "1975        1599  \n",
       "1976        1996  \n",
       "1977        1929  \n",
       "1978        1907  \n",
       "1979        2352  \n",
       "1980        2458  \n",
       "1981        2817  \n",
       "1982        3262  \n",
       "1983        3721  \n",
       "1984        4668  \n",
       "1985        4821  \n",
       "1986        5857  \n",
       "1987        6624  \n",
       "1988        8364  \n",
       "1989        9293  \n",
       "1990       10871  \n",
       "1991       12430  \n",
       "1992       13769  \n",
       "1993       16379  \n",
       "1994       18423  \n",
       "1995       19223  \n",
       "1996       20823  \n",
       "1997       23263  \n",
       "1998       26813  \n",
       "1999       29225  \n",
       "2000       33591  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_cohort_full_hind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Plot prediction success over cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.set_palette('deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_metric_over_cohorts(data, criteria, criteria_name, title, letter, filename, legend=False):\n",
    "    linewidth = 2\n",
    "    fontsize = 18\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    ax = fig.add_subplot(111)\n",
    "    labels = ['h_index']\n",
    "    i=0\n",
    "    ax.plot(data.index, data[criteria], linewidth=linewidth, label=labels[i], color=sns.color_palette()[0])\n",
    "    ax.xaxis.set_ticks_position('both')\n",
    "    ax.yaxis.set_ticks_position('both')\n",
    "    if 'r2' in criteria:\n",
    "        ax.set_ylim([0.18, 0.65])\n",
    "    if 'precision' in criteria:\n",
    "        ax.set_ylim([0.7, 1.05])\n",
    "    ax.set_xlabel('Cohort year', fontsize=fontsize)\n",
    "    ax.set_ylabel(f'{criteria_name}', fontsize=fontsize)\n",
    "    ax.set_title(title, fontsize=fontsize)\n",
    "    ax.tick_params(axis=\"x\", which='major', direction=\"in\", width=linewidth, size=4*linewidth, labelsize=fontsize, pad=7)\n",
    "    ax.tick_params(axis=\"x\", which='minor', direction=\"in\", width=linewidth, size=2*linewidth, labelsize=fontsize, pad=7)\n",
    "    ax.tick_params(axis=\"y\", which='major', direction=\"in\", width=linewidth, size=4*linewidth, labelsize=fontsize)\n",
    "    ax.tick_params(axis=\"y\", which='minor', direction=\"in\", width=linewidth, size=2*linewidth, labelsize=fontsize)\n",
    "    ax.spines['left'].set_linewidth(linewidth)\n",
    "    ax.spines['right'].set_linewidth(linewidth)\n",
    "    ax.spines['bottom'].set_linewidth(linewidth)\n",
    "    ax.spines['top'].set_linewidth(linewidth)\n",
    "    if legend: ax.legend(fontsize=fontsize/2)\n",
    "    plt.gcf().text(0., 0.9, letter, fontsize=fontsize*2)\n",
    "    plt.subplots_adjust(left=0.25, right=0.95, bottom=0.2, top=0.9)\n",
    "    fig.savefig(f'./fig/{filename}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_metric_over_cohorts(res_cohort_full_hind, 'r2', 'R squared', 'H index increase - full', 'A', 'pred_r2_hind_full')\n",
    "# plot_metric_over_cohorts(res_cohort_sym_hind, 'r2', 'R squared', 'H index increase prediction - symbolic', 'A')\n",
    "plot_metric_over_cohorts(res_cohort_full_cita, 'r2', 'R squared', 'Citation increase - full', 'B', 'pred_r2_cita_full')\n",
    "# plot_metric_over_cohorts(res_cohort_full_drop, 'avg_precision', 'Average precision', 'Dropout prediction - full', 'C', 'pred_avgp_drop_full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregated Elastic Net Models\n",
    "We test the effect of different groups of features (human capital, social capital and gender) on success/dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>human</th>\n",
       "      <th>gender</th>\n",
       "      <th>social</th>\n",
       "      <th>symbolic</th>\n",
       "      <th>full_model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>names</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>start year</th>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.01(0.0)</td>\n",
       "      <td>0.01(0.0)</td>\n",
       "      <td>0.01(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>productivity</th>\n",
       "      <td></td>\n",
       "      <td>0.43(0.0)</td>\n",
       "      <td>0.43(0.0)</td>\n",
       "      <td>0.38(0.0)</td>\n",
       "      <td>0.38(0.0)</td>\n",
       "      <td>0.36(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recognition</th>\n",
       "      <td></td>\n",
       "      <td>0.01(0.0)</td>\n",
       "      <td>0.01(0.0)</td>\n",
       "      <td>-0.03(0.0)</td>\n",
       "      <td>-0.04(0.0)</td>\n",
       "      <td>-0.14(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.0(0.01)</td>\n",
       "      <td>-0.01(0.01)</td>\n",
       "      <td>-0.02(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.01(0.01)</td>\n",
       "      <td>0.0(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.04(0.0)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coauthor hindex</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.11(0.0)</td>\n",
       "      <td>0.11(0.0)</td>\n",
       "      <td>0.09(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median team size</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.06(0.0)</td>\n",
       "      <td>-0.05(0.0)</td>\n",
       "      <td>-0.05(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top-venue</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.25(0.0)</td>\n",
       "      <td>0.19(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.01(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohort size</th>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>-2.4</td>\n",
       "      <td>-1.62</td>\n",
       "      <td>-1.63</td>\n",
       "      <td>-1.55</td>\n",
       "      <td>-1.54</td>\n",
       "      <td>-1.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>-55.73</td>\n",
       "      <td>-34.74</td>\n",
       "      <td>-34.53</td>\n",
       "      <td>-25.48</td>\n",
       "      <td>-24.75</td>\n",
       "      <td>-20.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   baseline      human      gender       social     symbolic  \\\n",
       "names                                                                          \n",
       "start year        0.03(0.0)  0.02(0.0)   0.02(0.0)    0.01(0.0)    0.01(0.0)   \n",
       "productivity                 0.43(0.0)   0.43(0.0)    0.38(0.0)    0.38(0.0)   \n",
       "recognition                  0.01(0.0)   0.01(0.0)   -0.03(0.0)   -0.04(0.0)   \n",
       "male                                    -0.0(0.01)  -0.01(0.01)  -0.02(0.01)   \n",
       "female                                    0.0(0.0)     0.0(0.0)     0.0(0.0)   \n",
       "none                                    0.01(0.01)    0.0(0.01)     0.0(0.0)   \n",
       "degree                                                0.04(0.0)    0.03(0.0)   \n",
       "coauthor hindex                                       0.11(0.0)    0.11(0.0)   \n",
       "median team size                                     -0.06(0.0)   -0.05(0.0)   \n",
       "top-venue                                                          0.25(0.0)   \n",
       "quality                                                                        \n",
       "cohort size          292659     292659      292659       292659       292659   \n",
       "MSE                    -2.4      -1.62       -1.63        -1.55        -1.54   \n",
       "intercept            -55.73     -34.74      -34.53       -25.48       -24.75   \n",
       "R2                     0.01       0.33        0.33         0.36         0.37   \n",
       "\n",
       "                  full_model  \n",
       "names                         \n",
       "start year         0.01(0.0)  \n",
       "productivity       0.36(0.0)  \n",
       "recognition       -0.14(0.0)  \n",
       "male                0.0(0.0)  \n",
       "female              0.0(0.0)  \n",
       "none                0.0(0.0)  \n",
       "degree             0.03(0.0)  \n",
       "coauthor hindex    0.09(0.0)  \n",
       "median team size  -0.05(0.0)  \n",
       "top-venue          0.19(0.0)  \n",
       "quality            0.01(0.0)  \n",
       "cohort size           292659  \n",
       "MSE                    -1.47  \n",
       "intercept             -20.78  \n",
       "R2                       0.4  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_agg_all(EARLY_CAREER, RECOGNITION_CUT, dv_hindex_incr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>human</th>\n",
       "      <th>gender</th>\n",
       "      <th>social</th>\n",
       "      <th>symbolic</th>\n",
       "      <th>full_model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>names</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>start year</th>\n",
       "      <td>0.81(0.01)</td>\n",
       "      <td>0.54(0.01)</td>\n",
       "      <td>0.54(0.01)</td>\n",
       "      <td>0.43(0.01)</td>\n",
       "      <td>0.43(0.01)</td>\n",
       "      <td>0.26(0.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>productivity</th>\n",
       "      <td></td>\n",
       "      <td>11.21(0.1)</td>\n",
       "      <td>11.22(0.1)</td>\n",
       "      <td>10.57(0.09)</td>\n",
       "      <td>10.6(0.09)</td>\n",
       "      <td>6.79(0.06)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recognition</th>\n",
       "      <td></td>\n",
       "      <td>9.14(0.13)</td>\n",
       "      <td>9.14(0.13)</td>\n",
       "      <td>8.25(0.14)</td>\n",
       "      <td>8.27(0.14)</td>\n",
       "      <td>-1.02(0.06)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.21(0.07)</td>\n",
       "      <td>-0.3(0.06)</td>\n",
       "      <td>-0.32(0.06)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.0(0.01)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.86(0.19)</td>\n",
       "      <td>0.67(0.18)</td>\n",
       "      <td>0.7(0.18)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.35(0.03)</td>\n",
       "      <td>-0.29(0.03)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coauthor hindex</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.51(0.05)</td>\n",
       "      <td>3.53(0.05)</td>\n",
       "      <td>1.68(0.03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median team size</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.22(0.02)</td>\n",
       "      <td>-0.27(0.02)</td>\n",
       "      <td>-0.23(0.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top-venue</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-1.62(0.09)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.51(0.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohort size</th>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>-4064.39</td>\n",
       "      <td>-3063.93</td>\n",
       "      <td>-3063.69</td>\n",
       "      <td>-3030.37</td>\n",
       "      <td>-3029.42</td>\n",
       "      <td>-2227.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>-1602.53</td>\n",
       "      <td>-1079.93</td>\n",
       "      <td>-1081.52</td>\n",
       "      <td>-872.76</td>\n",
       "      <td>-877.66</td>\n",
       "      <td>-515.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    baseline       human       gender       social  \\\n",
       "names                                                                \n",
       "start year        0.81(0.01)  0.54(0.01)   0.54(0.01)   0.43(0.01)   \n",
       "productivity                  11.21(0.1)   11.22(0.1)  10.57(0.09)   \n",
       "recognition                   9.14(0.13)   9.14(0.13)   8.25(0.14)   \n",
       "male                                      -0.21(0.07)   -0.3(0.06)   \n",
       "female                                     -0.0(0.01)     0.0(0.0)   \n",
       "none                                       0.86(0.19)   0.67(0.18)   \n",
       "degree                                                 -0.35(0.03)   \n",
       "coauthor hindex                                         3.51(0.05)   \n",
       "median team size                                       -0.22(0.02)   \n",
       "top-venue                                                            \n",
       "quality                                                              \n",
       "cohort size           292659      292659       292659       292659   \n",
       "MSE                 -4064.39    -3063.93     -3063.69     -3030.37   \n",
       "intercept           -1602.53    -1079.93     -1081.52      -872.76   \n",
       "R2                      0.01        0.25         0.25         0.26   \n",
       "\n",
       "                     symbolic   full_model  \n",
       "names                                       \n",
       "start year         0.43(0.01)   0.26(0.01)  \n",
       "productivity       10.6(0.09)   6.79(0.06)  \n",
       "recognition        8.27(0.14)  -1.02(0.06)  \n",
       "male              -0.32(0.06)     0.0(0.0)  \n",
       "female               0.0(0.0)     0.0(0.0)  \n",
       "none                0.7(0.18)     0.0(0.0)  \n",
       "degree            -0.29(0.03)     0.0(0.0)  \n",
       "coauthor hindex    3.53(0.05)   1.68(0.03)  \n",
       "median team size  -0.27(0.02)  -0.23(0.01)  \n",
       "top-venue         -1.62(0.09)     0.0(0.0)  \n",
       "quality                         1.51(0.02)  \n",
       "cohort size            292659       292659  \n",
       "MSE                  -3029.42     -2227.64  \n",
       "intercept             -877.66      -515.76  \n",
       "R2                       0.26         0.45  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_agg_all(EARLY_CAREER, RECOGNITION_CUT, dv_citations_incr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>human</th>\n",
       "      <th>gender</th>\n",
       "      <th>social</th>\n",
       "      <th>symbolic</th>\n",
       "      <th>full_model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>names</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>start year</th>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "      <td>0.0(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>productivity</th>\n",
       "      <td></td>\n",
       "      <td>-0.66(0.01)</td>\n",
       "      <td>-0.67(0.0)</td>\n",
       "      <td>-0.67(0.01)</td>\n",
       "      <td>-0.66(0.01)</td>\n",
       "      <td>-0.65(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recognition</th>\n",
       "      <td></td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.02(0.0)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.07(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.05(0.02)</td>\n",
       "      <td>0.03(0.01)</td>\n",
       "      <td>0.05(0.02)</td>\n",
       "      <td>0.05(0.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.06(0.02)</td>\n",
       "      <td>-0.04(0.01)</td>\n",
       "      <td>-0.06(0.02)</td>\n",
       "      <td>-0.06(0.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.01(0.02)</td>\n",
       "      <td>0.01(0.01)</td>\n",
       "      <td>0.01(0.01)</td>\n",
       "      <td>0.01(0.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "      <td>0.03(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coauthor hindex</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.02(0.0)</td>\n",
       "      <td>-0.01(0.0)</td>\n",
       "      <td>-0.01(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top-venue</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.3(0.04)</td>\n",
       "      <td>-0.3(0.05)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.01(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohort size</th>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "      <td>292659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>% dropouts</th>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.631988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average precision</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   baseline        human       gender       social  \\\n",
       "names                                                                \n",
       "start year         0.0(0.0)     0.0(0.0)     0.0(0.0)     0.0(0.0)   \n",
       "productivity                 -0.66(0.01)   -0.67(0.0)  -0.67(0.01)   \n",
       "recognition                    0.03(0.0)    0.03(0.0)    0.02(0.0)   \n",
       "male                                       0.05(0.02)   0.03(0.01)   \n",
       "female                                    -0.06(0.02)  -0.04(0.01)   \n",
       "none                                       0.01(0.02)   0.01(0.01)   \n",
       "degree                                                   0.03(0.0)   \n",
       "coauthor hindex                                         -0.02(0.0)   \n",
       "top-venue                                                            \n",
       "quality                                                              \n",
       "cohort size          292659       292659       292659       292659   \n",
       "% dropouts         0.631988     0.631988     0.631988     0.631988   \n",
       "Average precision      0.62         0.78         0.79         0.79   \n",
       "\n",
       "                      symbolic   full_model  \n",
       "names                                        \n",
       "start year            0.0(0.0)     0.0(0.0)  \n",
       "productivity       -0.66(0.01)   -0.65(0.0)  \n",
       "recognition          0.03(0.0)    0.07(0.0)  \n",
       "male                0.05(0.02)   0.05(0.01)  \n",
       "female             -0.06(0.02)  -0.06(0.01)  \n",
       "none                0.01(0.01)   0.01(0.02)  \n",
       "degree               0.03(0.0)    0.03(0.0)  \n",
       "coauthor hindex     -0.01(0.0)   -0.01(0.0)  \n",
       "top-venue           -0.3(0.04)   -0.3(0.05)  \n",
       "quality                          -0.01(0.0)  \n",
       "cohort size             292659       292659  \n",
       "% dropouts            0.631988     0.631988  \n",
       "Average precision          0.8          0.8  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_agg_all(EARLY_CAREER, RECOGNITION_CUT, dv_dropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run different configs of the elastic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Test train split 80-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def run_elastic_predictions_test_train(cols_all, cols_std, categorical_cols, REMOVE_NONE_AUTHORS, EARLY_CAREER):\n",
    "    feature_table = pd.DataFrame(cols_all, columns=['feature']).set_index('feature')\n",
    "    feature_table2 = pd.DataFrame(cols_all, columns=['feature']).set_index('feature')\n",
    "    feature_table3 = pd.DataFrame(cols_all, columns=['feature']).set_index('feature')\n",
    " \n",
    "    for year in [1970,1999,2000,2001,2002]:\n",
    "        credible_authors_year = credible_authors[credible_authors.start_year == year]\n",
    "\n",
    "        X = credible_authors_year.copy()\n",
    "\n",
    "        #remove non-gender rows\n",
    "        if REMOVE_NONE_AUTHORS:\n",
    "            X = X[X[\"gender\"]!=\"none\"]\n",
    "\n",
    "        # Make dummy values for categorical columns\n",
    "        gender_cols = pd.get_dummies(X[categorical_cols])\n",
    "\n",
    "        #if(not REMOVE_NONE_AUTHORS):\n",
    "            # drop gender none?\n",
    "            # this is removing rows gender_none col\n",
    "            #gender_cols.drop('gender_none', axis=1, inplace=True)\n",
    "\n",
    "        #standardize cols_std\n",
    "        if len(cols_std)>0:\n",
    "            standardized_cols = RobustScaler().fit_transform(X[cols_std])\n",
    "\n",
    "\n",
    "        # claudia: here we could do a 20:80 split and save 20% for later test\n",
    "\n",
    "        #combine\n",
    "        H = pd.DataFrame(standardized_cols, index=X.index, columns=cols_std)\n",
    "        if INCLUDE_GENDER:\n",
    "            H = H.join(gender_cols)\n",
    "\n",
    "        y = X[f'h_index_increase_15_{EARLY_CAREER}']\n",
    "        y2 = X[f'citation_increase_15_{EARLY_CAREER}']\n",
    "        y3 = X['dropped_after_10'].astype(int)\n",
    "        \n",
    "        f1_dropout_list=[]\n",
    "        r2_hindex_list=[]\n",
    "        for i in range(10):\n",
    "            #dropouts\n",
    "            X_train, X_test, y_train, y_test = train_test_split(H, y3, test_size=0.2)\n",
    "            rgs = LogisticRegressionCV(cv=3) #, penalty='l2', solver='liblinear'\n",
    "            #rgs = SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
    "            #           early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
    "            #           l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=1000,\n",
    "            #           n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
    "            #           power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
    "            #           validation_fraction=0.1, verbose=0, warm_start=False)\n",
    "        \n",
    "            rgs.fit(X_train, y_train)\n",
    "            f1_dropout = f1_score(y_test, rgs.predict(X_test))\n",
    "            f1_dropout_list.append(f1_dropout)\n",
    "            \n",
    "            #h-index increase\n",
    "            X_train, X_test, y_train, y_test = train_test_split(H, y, test_size=0.2)\n",
    "            rgs = ElasticNetCV(cv=3)\n",
    "            #rgs = ElasticNetCV(cv=3, random_state=1000, max_iter=10000,\n",
    "            #       alphas=[1.0], l1_ratio=0.5)\n",
    "            rgs.fit(X_train, y_train)\n",
    "            r2_hindex = r2_score(y_test, rgs.predict(X_test))\n",
    "            print(rgs.alpha_)\n",
    "            r2_hindex_list.append(r2_hindex)\n",
    "            \n",
    "        print(f\"Year: {year}, f1_dropout: {np.mean(f1_dropout_list)}\")\n",
    "        print(f\"Year: {year}, r2_hindex: {np.mean(r2_hindex_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "INCLUDE_PROD = 1\n",
    "INCLUDE_SOCIAL = 1\n",
    "INCLUDE_REC = 1\n",
    "INCLUDE_GENDER = 1\n",
    "INCLUDE_QUALITY = 1\n",
    "REMOVE_NONE_AUTHORS = 0\n",
    "cols_all, cols_std, categorical_cols = make_cols_lists(INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC,\n",
    "                                                       INCLUDE_QUALITY, INCLUDE_GENDER, REMOVE_NONE_AUTHORS, EARLY_CAREER, RECOGNITION_CUT)\n",
    "run_elastic_predictions_test_train(cols_all, cols_std, categorical_cols, REMOVE_NONE_AUTHORS, EARLY_CAREER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Test predictive power over different number of observed years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "EARLY_CAREER_LEN_LIST_EXT = [3,5,7,9,11,12]\n",
    "RECOGNITION_CUT_OFF_LIST_EXT = [3,5,7,9,11,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'citation_increase_15_3'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv_citations_incr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3, 3\n",
      "citation_increase_15_3\n",
      "['start_year', 'citation_increase_15_3', 'early_career_prod_3', 'early_career_degree_3', 'early_career_coauthor_max_hindex_3', 'early_career_recognition_EC3_RC3', 'early_career_qual_3', 'quantiles_bin_3']\n",
      "1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 5, 5\n",
      "citation_increase_15_5\n",
      "['start_year', 'citation_increase_15_5', 'early_career_prod_5', 'early_career_degree_5', 'early_career_coauthor_max_hindex_5', 'early_career_recognition_EC5_RC5', 'early_career_qual_5', 'quantiles_bin_5']\n",
      "1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 7, 7\n",
      "citation_increase_15_7\n",
      "['start_year', 'citation_increase_15_7', 'early_career_prod_7', 'early_career_degree_7', 'early_career_coauthor_max_hindex_7', 'early_career_recognition_EC7_RC7', 'early_career_qual_7', 'quantiles_bin_7']\n",
      "1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 9, 9\n",
      "citation_increase_15_9\n",
      "['start_year', 'citation_increase_15_9', 'early_career_prod_9', 'early_career_degree_9', 'early_career_coauthor_max_hindex_9', 'early_career_recognition_EC9_RC9', 'early_career_qual_9', 'quantiles_bin_9']\n",
      "1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 11, 11\n",
      "citation_increase_15_11\n",
      "['start_year', 'citation_increase_15_11', 'early_career_prod_11', 'early_career_degree_11', 'early_career_coauthor_max_hindex_11', 'early_career_recognition_EC11_RC11', 'early_career_qual_11', 'quantiles_bin_11']\n",
      "1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 12, 12\n",
      "citation_increase_15_12\n",
      "['start_year', 'citation_increase_15_12', 'early_career_prod_12', 'early_career_degree_12', 'early_career_coauthor_max_hindex_12', 'early_career_recognition_EC12_RC12', 'early_career_qual_12', 'quantiles_bin_12']\n",
      "1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 3, 3\n",
      "h_index_increase_15_3\n",
      "['start_year', 'h_index_increase_15_3', 'early_career_prod_3', 'early_career_degree_3', 'early_career_coauthor_max_hindex_3', 'early_career_recognition_EC3_RC3', 'early_career_qual_3', 'quantiles_bin_3']\n",
      "1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-7f34b6801d53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr2_increase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mr2_increase_cit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_r2_increase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOHORT_START_YEARS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEARLY_CAREER_LEN_LIST_EXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRECOGNITION_CUT_OFF_LIST_EXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'citation_increase'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mr2_increase_hind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_r2_increase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOHORT_START_YEARS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEARLY_CAREER_LEN_LIST_EXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRECOGNITION_CUT_OFF_LIST_EXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h_index_increase'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-7f34b6801d53>\u001b[0m in \u001b[0;36mget_r2_increase\u001b[0;34m(COHORT_START_YEARS, EARLY_CAREER_LEN_LIST_EXT, RECOGNITION_CUT_OFF_LIST_EXT, DV)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mDV_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{DV}_15_{EARLY_CAREER}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDV_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mr2_increase\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'{DV}_{EARLY_CAREER}_{RECOGNITION_CUT}'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melastic_cohort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_full_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEARLY_CAREER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRECOGNITION_CUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDV_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'r2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr2_increase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mr2_increase_cit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_r2_increase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOHORT_START_YEARS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEARLY_CAREER_LEN_LIST_EXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRECOGNITION_CUT_OFF_LIST_EXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'citation_increase'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-49e001c31ba0>\u001b[0m in \u001b[0;36melastic_cohort\u001b[0;34m(params_func, EARLY_CAREER, RECOGNITION_CUT, DV)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mREMOVE_NONE_AUTHORS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_elastic_net_cohort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcredible_authors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mREMOVE_NONE_AUTHORS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_result_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-378346bc1316>\u001b[0m in \u001b[0;36mrun_elastic_net_cohort\u001b[0;34m(credible_authors, cols_std, categorical_cols, REMOVE_NONE_AUTHORS, dep_var)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mX_year\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_year\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdep_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mfeat_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_elastic_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_year\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'start_year'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_year\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mfeat_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeat_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mfeat_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-378346bc1316>\u001b[0m in \u001b[0;36mrun_elastic_net\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         cv_dict = cross_validate(ElasticNetCV(cv=10), X, y, scoring=['r2', 'neg_mean_squared_error'], \n\u001b[0;32m---> 88\u001b[0;31m                                  cv=10, return_estimator=True, return_train_score=False)\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mnet_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcv_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'estimator'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_r2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 240\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1205\u001b[0m                 for train, test in folds)\n\u001b[1;32m   1206\u001b[0m         mse_paths = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0;32m-> 1207\u001b[0;31m                              **_joblib_parallel_args(prefer=\"threads\"))(jobs)\n\u001b[0m\u001b[1;32m   1208\u001b[0m         \u001b[0mmse_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_l1_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m         \u001b[0mmean_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py\u001b[0m in \u001b[0;36m_path_residuals\u001b[0;34m(X, y, train, test, path, path_params, alphas, l1_ratio, X_order, dtype)\u001b[0m\n\u001b[1;32m   1042\u001b[0m         \u001b[0mX_test_coefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test_coefs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m         \u001b[0mX_test_coefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m     \u001b[0mresidues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test_coefs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m     \u001b[0mresidues\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mintercepts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_r2_increase(COHORT_START_YEARS, EARLY_CAREER_LEN_LIST_EXT, RECOGNITION_CUT_OFF_LIST_EXT, DV):\n",
    "    r2_increase = pd.DataFrame(index=COHORT_START_YEARS)\n",
    "    for EARLY_CAREER, RECOGNITION_CUT in zip(EARLY_CAREER_LEN_LIST_EXT, RECOGNITION_CUT_OFF_LIST_EXT):\n",
    "        print(f'{EARLY_CAREER}, {RECOGNITION_CUT}')\n",
    "        DV_ = f'{DV}_15_{EARLY_CAREER}'\n",
    "        print(DV_)\n",
    "        r2_increase[f'{DV}_{EARLY_CAREER}_{RECOGNITION_CUT}'] = elastic_cohort(get_full_vars,EARLY_CAREER, RECOGNITION_CUT, DV_)['r2']\n",
    "    return r2_increase\n",
    "r2_increase_cit = get_r2_increase(COHORT_START_YEARS, EARLY_CAREER_LEN_LIST_EXT, RECOGNITION_CUT_OFF_LIST_EXT, 'citation_increase')\n",
    "r2_increase_hind = get_r2_increase(COHORT_START_YEARS, EARLY_CAREER_LEN_LIST_EXT, RECOGNITION_CUT_OFF_LIST_EXT, 'h_index_increase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "r2_increase_hind.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "linewidth = 2\n",
    "fontsize = 18\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot([3,5,7,9,11,12], r2_increase_cit.mean().values, label='citation inc.')\n",
    "ax.plot([3,5,7,9,11,12], r2_increase_hind.mean().values, label='h-index inc.')\n",
    "\n",
    "ax.xaxis.set_ticks_position('both')\n",
    "ax.yaxis.set_ticks_position('both')\n",
    "ax.set_xticks([3,5,7,9,11])\n",
    "\n",
    "ax.set_xlabel('Number of observed years', fontsize=fontsize)\n",
    "ax.set_ylabel('Avg. R2 over cohorts', fontsize=fontsize)\n",
    "ax.set_title(\"Prediction R2 vs observed years\", fontsize=fontsize)\n",
    "ax.tick_params(axis=\"x\", which='major', direction=\"in\", width=linewidth, size=4*linewidth, labelsize=fontsize, pad=7)\n",
    "ax.tick_params(axis=\"x\", which='minor', direction=\"in\", width=linewidth, size=2*linewidth, labelsize=fontsize, pad=7)\n",
    "ax.tick_params(axis=\"y\", which='major', direction=\"in\", width=linewidth, size=4*linewidth, labelsize=fontsize)\n",
    "ax.tick_params(axis=\"y\", which='minor', direction=\"in\", width=linewidth, size=2*linewidth, labelsize=fontsize)\n",
    "ax.spines['left'].set_linewidth(linewidth)\n",
    "ax.spines['right'].set_linewidth(linewidth)\n",
    "ax.spines['bottom'].set_linewidth(linewidth)\n",
    "ax.spines['top'].set_linewidth(linewidth)\n",
    "ax.legend(fontsize=fontsize/1.5)\n",
    "plt.gcf().text(0., 0.9, 'D', fontsize=fontsize*2)\n",
    "plt.subplots_adjust(left=0.25, right=0.95, bottom=0.2, top=0.9)\n",
    "plt.savefig('./fig/pred_r2_obs_years.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Test predictive power over different number of years being predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "EARLY_CAREER_LEN_LIST_EXT = [3,5,7,9,11,12]\n",
    "RECOGNITION_CUT_OFF_LIST_EXT = [3,5,7,9,11,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5, 5\n",
      "citation_increase_5_3\n",
      "['start_year', 'citation_increase_5_3', 'early_career_prod_3', 'early_career_degree_3', 'early_career_coauthor_max_hindex_3', 'early_career_recognition_EC3_RC3', 'early_career_qual_3', 'quantiles_bin_3']\n",
      "1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 7, 7\n",
      "citation_increase_7_3\n",
      "['start_year', 'citation_increase_7_3', 'early_career_prod_3', 'early_career_degree_3', 'early_career_coauthor_max_hindex_3', 'early_career_recognition_EC3_RC3', 'early_career_qual_3', 'quantiles_bin_3']\n",
      "1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 9, 9\n",
      "citation_increase_9_3\n",
      "['start_year', 'citation_increase_9_3', 'early_career_prod_3', 'early_career_degree_3', 'early_career_coauthor_max_hindex_3', 'early_career_recognition_EC3_RC3', 'early_career_qual_3', 'quantiles_bin_3']\n",
      "1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 11, 11\n",
      "citation_increase_11_3\n",
      "['start_year', 'citation_increase_11_3', 'early_career_prod_3', 'early_career_degree_3', 'early_career_coauthor_max_hindex_3', 'early_career_recognition_EC3_RC3', 'early_career_qual_3', 'quantiles_bin_3']\n",
      "1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 12, 12\n",
      "citation_increase_12_3\n",
      "['start_year', 'citation_increase_12_3', 'early_career_prod_3', 'early_career_degree_3', 'early_career_coauthor_max_hindex_3', 'early_career_recognition_EC3_RC3', 'early_career_qual_3', 'quantiles_bin_3']\n",
      "1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 5, 5\n",
      "h_index_increase_5_3\n",
      "['start_year', 'h_index_increase_5_3', 'early_career_prod_3', 'early_career_degree_3', 'early_career_coauthor_max_hindex_3', 'early_career_recognition_EC3_RC3', 'early_career_qual_3', 'quantiles_bin_3']\n",
      "1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 7, 7\n",
      "h_index_increase_7_3\n",
      "['start_year', 'h_index_increase_7_3', 'early_career_prod_3', 'early_career_degree_3', 'early_career_coauthor_max_hindex_3', 'early_career_recognition_EC3_RC3', 'early_career_qual_3', 'quantiles_bin_3']\n",
      "1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 9, 9\n",
      "h_index_increase_9_3\n",
      "['start_year', 'h_index_increase_9_3', 'early_career_prod_3', 'early_career_degree_3', 'early_career_coauthor_max_hindex_3', 'early_career_recognition_EC3_RC3', 'early_career_qual_3', 'quantiles_bin_3']\n",
      "1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 11, 11\n",
      "h_index_increase_11_3\n",
      "['start_year', 'h_index_increase_11_3', 'early_career_prod_3', 'early_career_degree_3', 'early_career_coauthor_max_hindex_3', 'early_career_recognition_EC3_RC3', 'early_career_qual_3', 'quantiles_bin_3']\n",
      "1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 12, 12\n",
      "h_index_increase_12_3\n",
      "['start_year', 'h_index_increase_12_3', 'early_career_prod_3', 'early_career_degree_3', 'early_career_coauthor_max_hindex_3', 'early_career_recognition_EC3_RC3', 'early_career_qual_3', 'quantiles_bin_3']\n",
      "1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 "
     ]
    }
   ],
   "source": [
    "def get_r2_increase_(COHORT_START_YEARS, EARLY_CAREER_LEN_LIST_EXT, RECOGNITION_CUT_OFF_LIST_EXT, DV):\n",
    "    r2_increase = pd.DataFrame(index=COHORT_START_YEARS)\n",
    "    for EARLY_CAREER, RECOGNITION_CUT in zip(EARLY_CAREER_LEN_LIST_EXT[1:], RECOGNITION_CUT_OFF_LIST_EXT[1:]):\n",
    "        print(f'{EARLY_CAREER}, {RECOGNITION_CUT}')\n",
    "        DV_ = f'{DV}_{EARLY_CAREER}_3'\n",
    "        print(DV_)\n",
    "        r2_increase[f'{DV}_{EARLY_CAREER}_3'] = elastic_cohort(get_full_vars,3, 3, DV_)['r2']\n",
    "    return r2_increase\n",
    "r2_increase_cit_pred = get_r2_increase_(COHORT_START_YEARS, EARLY_CAREER_LEN_LIST_EXT, RECOGNITION_CUT_OFF_LIST_EXT, 'citation_increase')\n",
    "r2_increase_hind_pred = get_r2_increase_(COHORT_START_YEARS, EARLY_CAREER_LEN_LIST_EXT, RECOGNITION_CUT_OFF_LIST_EXT, 'h_index_increase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "linewidth = 2\n",
    "fontsize = 18\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot([2,4,6,8,9], r2_increase_cit_pred.mean().values, label='citation inc.')\n",
    "ax.plot([2,4,6,8,9], r2_increase_hind_pred.mean().values, label='h-index inc.')\n",
    "\n",
    "ax.xaxis.set_ticks_position('both')\n",
    "ax.yaxis.set_ticks_position('both')\n",
    "ax.set_xticks([2,4,6,8,9])\n",
    "\n",
    "ax.set_xlabel('Number of years predicted ahead', fontsize=fontsize)\n",
    "ax.set_ylabel('Avg. R2 over cohorts', fontsize=fontsize)\n",
    "ax.set_title(\"Prediction R2 vs years ahead\", fontsize=fontsize)\n",
    "ax.tick_params(axis=\"x\", which='major', direction=\"in\", width=linewidth, size=4*linewidth, labelsize=fontsize, pad=7)\n",
    "ax.tick_params(axis=\"x\", which='minor', direction=\"in\", width=linewidth, size=2*linewidth, labelsize=fontsize, pad=7)\n",
    "ax.tick_params(axis=\"y\", which='major', direction=\"in\", width=linewidth, size=4*linewidth, labelsize=fontsize)\n",
    "ax.tick_params(axis=\"y\", which='minor', direction=\"in\", width=linewidth, size=2*linewidth, labelsize=fontsize)\n",
    "ax.spines['left'].set_linewidth(linewidth)\n",
    "ax.spines['right'].set_linewidth(linewidth)\n",
    "ax.spines['bottom'].set_linewidth(linewidth)\n",
    "ax.spines['top'].set_linewidth(linewidth)\n",
    "ax.legend(fontsize=fontsize/1.5)\n",
    "plt.gcf().text(0., 0.9, 'D', fontsize=fontsize*2)\n",
    "plt.subplots_adjust(left=0.25, right=0.95, bottom=0.2, top=0.9)\n",
    "plt.savefig('./fig/pred_r2_per_years.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### predictor diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "h_index = res_cohort_full_hind\n",
    "citations = res_cohort_full_cita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(h_index['r2'], label='Increase H index')\n",
    "plt.plot(citations['r2'], label='Increase Citations')\n",
    "print(\"Average difference in r squared\", sum(citations['r2']-h_index['r2'])/len(h_index['r2']))\n",
    "# quality was used as a feature!\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### gender diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# gender coefs\n",
    "plt.plot(res_cohort_full_hind['gender_m'], label=\"Male\")\n",
    "plt.plot(res_cohort_full_hind['gender_f'], label=\"Female\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(res_cohort_full_hind['gender_m'] - res_cohort_full_hind['gender_f'], label=\"Male-Female diff\")\n",
    "plt.plot(res_cohort_full_hind.index ,np.zeros(len(res_cohort_full_hind)))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### cohort size diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "# ax1.plot(results['r2'], label='r2')\n",
    "ax1.plot(res_cohort_full_hind['r2'], label='adjusted r2', color='C2')\n",
    "ax1.set_ylim([0,1])\n",
    "ax1.set_xlabel('Years')\n",
    "ax1.set_ylabel('R squared', color='C2')\n",
    "ax1.legend(loc=2)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(res_cohort_full_hind['cohort_size'], label='Cohort size', color='C3')\n",
    "ax2.set_ylabel('Cohort size', color='C3')\n",
    "ax2.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### cheating diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "no_cheating = feature_table2.transpose().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cheat_RC5 = feature_table2.transpose().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cheat_quality = feature_table2.transpose().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# How does removing the quality affect the r squared?\n",
    "plt.plot(with_quality['adj_r2'], label='With quality')\n",
    "plt.plot(cheat_RC5['adj_r2'], label='With recognition year 5')\n",
    "plt.plot(no_cheating['adj_r2'], label='No cheating')\n",
    "print(\"Average difference in r squared\", sum(with_quality['adj_r2']-no_cheating['adj_r2'])/len(cheat_quality))\n",
    "print(np.mean)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "avg = sum(cheat_quality['adj_r2']-no_cheating['adj_r2'])/len(no_cheating)\n",
    "plt.plot(cheat_quality['adj_r2']-no_cheating['adj_r2'], label='Difference')\n",
    "plt.plot(no_cheating.index, [avg]*len(no_cheating), label='Average diff')\n",
    "plt.title(\"Difference between quality(15y) and recognition(3y)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### scaler diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "std_scaler = feature_table2.transpose().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rob_scaler = feature_table2.transpose().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# How does changing the scaler affect the r squared?\n",
    "plt.plot(std_scaler['adj_r2'], label='Std')\n",
    "plt.plot(rob_scaler['adj_r2'], label='Rob')\n",
    "print(\"Average difference in r squared\", sum(std_scaler['adj_r2']-rob_scaler['adj_r2'])/len(rob_scaler))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# almost no difference\n",
    "\n",
    "avg = sum(std_scaler['adj_r2']-rob_scaler['adj_r2'])/len(std_scaler)\n",
    "plt.plot(std_scaler['adj_r2']-rob_scaler['adj_r2'], label='Difference')\n",
    "plt.plot(std_scaler.index, [avg]*len(std_scaler), label='Average diff')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# feature_table3.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Best feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression, RFE, RFECV\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def show_kbest(data_frame, target, linear_rel=True, k=4):\n",
    "    \"\"\"\n",
    "    Selecting K-Best features for classification\n",
    "    :param data_frame: A pandas dataFrame with the training data\n",
    "    :param target: target variable name in DataFrame\n",
    "    :param k: desired number of features from the data\n",
    "    :returns feature_scores: scores for each feature in the data as \n",
    "    pandas DataFrame\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    if linear_rel == True: \n",
    "        feat_selector = SelectKBest(f_regression, k=k)\n",
    "        col_name = \"F Score\"\n",
    "    else:\n",
    "        feat_selector = SelectKBest(mutual_info_regression, k=k)\n",
    "        col_name = \"Mutual Information\"\n",
    "    \n",
    "    feat_selector = feat_selector.fit(data_frame, target)\n",
    "    feat_scores = pd.DataFrame()\n",
    "    feat_scores[col_name] = feat_selector.scores_\n",
    "    feat_scores[\"P Value\"] = feat_selector.pvalues_\n",
    "    feat_scores[\"Support\"] = feat_selector.get_support()\n",
    "    feat_scores[\"Attribute\"] = data_frame.columns\n",
    "    \n",
    "    return feat_scores \n",
    "\n",
    "def get_features_rfe(data_frame, target, model,k=5):\n",
    "    \"\"\"\n",
    "    Returns list of features (k specified) selected using RFE for\n",
    "    :param data_frame: A pandas dataFrame with features and labels\n",
    "    :param k: top k features to select  \n",
    "    :returns list: most relevant features \n",
    "    \"\"\"\n",
    "    X = data_frame\n",
    "    y = target\n",
    "    selector = RFE(model, k, step=1)\n",
    "    selector = selector.fit(X, y)\n",
    "#     print(selector.support_)\n",
    "    df = pd.DataFrame({\n",
    "        \"feature\": X.columns,\n",
    "        \"support\": selector.support_\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def get_features_rfecv(data_frame, target, model, cv=3):\n",
    "    \"\"\"\n",
    "    Returns list of features (k specified) selected using RFE for\n",
    "    :param data_frame: A pandas dataFrame with features and labels\n",
    "    :param k: top k features to select  \n",
    "    :returns list: most relevant features \n",
    "    \"\"\"\n",
    "    X = data_frame\n",
    "    y = target\n",
    "    selector = RFECV(model, step=1, cv=cv)\n",
    "    selector = selector.fit(X, y)\n",
    "#     print(selector.support_)\n",
    "    df = pd.DataFrame({\n",
    "        \"feature\": X.columns,\n",
    "        \"support\": selector.support_\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "years = credible_authors.start_year.unique()\n",
    "years = sorted(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = credible_authors.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "categorical_cols = ['gender']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df = df.join(pd.get_dummies(df[categorical_cols]))\n",
    "\n",
    "df.drop(categorical_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Show k best - F regression or mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "linear = True\n",
    "# true - fregression\n",
    "# false - mutual info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params = []\n",
    "for year in years:\n",
    "    df_year = df[df.start_year == year]\n",
    "    df_year = df_year.drop('start_year', axis=1)\n",
    "#     for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "#         for RECOGNITION_CUT in RECOGNITION_CUT_OFF_LIST:\n",
    "#             if RECOGNITION_CUT < EARLY_CAREER: continue\n",
    "    EARLY_CAREER = 3\n",
    "    RECOGNITION_CUT= 5\n",
    "    X_year = df_year[['max_absence-0-3', 'avg_absence-0-3', \n",
    "           'gender_f', 'gender_m', 'gender_none',\n",
    "           f'early_career_degree_{EARLY_CAREER}', \n",
    "           f'early_career_prod_{EARLY_CAREER}',\n",
    "           f'early_career_qual_{EARLY_CAREER}', f'early_career_recognition_EC{EARLY_CAREER}_RC{RECOGNITION_CUT}']]\n",
    "    y_year = df_year['succ_after_15y']\n",
    "    params.append(show_kbest(X_year, y_year, linear, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "selected_f = defaultdict(int)\n",
    "for param in params:\n",
    "    selected = param[param.Support == True]['Attribute'].values\n",
    "    selected_f['total'] += 1\n",
    "#     print(selected)\n",
    "    for select in selected:\n",
    "        selected_f[select] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "selected_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params_rfe = []\n",
    "for year in years:\n",
    "    df_year = df[df.start_year == year]\n",
    "    df_year = df_year.drop('start_year', axis=1)\n",
    "#     for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "#         for RECOGNITION_CUT in RECOGNITION_CUT_OFF_LIST:\n",
    "#             if RECOGNITION_CUT < EARLY_CAREER: continue\n",
    "    EARLY_CAREER = 3\n",
    "    RECOGNITION_CUT= 5\n",
    "    X_year = df_year[[\n",
    "        #'max_absence-0-3', 'avg_absence-0-3', \n",
    "           'gender_f', 'gender_m', 'gender_none',\n",
    "           f'early_career_degree_{EARLY_CAREER}', \n",
    "           f'early_career_prod_{EARLY_CAREER}',\n",
    "           f'early_career_qual_{EARLY_CAREER}', f'early_career_recognition_EC{EARLY_CAREER}_RC{RECOGNITION_CUT}']]\n",
    "    y_year = df_year['succ_after_15y']\n",
    "    params_rfe.append(get_features_rfe(X_year, y_year, LinearRegression(),k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "selected_f = defaultdict(int)\n",
    "for param in params_rfe:\n",
    "    selected = param[param.support == True]['feature'].values\n",
    "    selected_f['total'] += 1\n",
    "#     print(selected)\n",
    "    for select in selected:\n",
    "        selected_f[select] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "selected_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### RFE CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params_rfecv = []\n",
    "for year in years:\n",
    "    df_year = df[df.start_year == year]\n",
    "    df_year = df_year.drop('start_year', axis=1)\n",
    "#     for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "#         for RECOGNITION_CUT in RECOGNITION_CUT_OFF_LIST:\n",
    "#             if RECOGNITION_CUT < EARLY_CAREER: continue\n",
    "    EARLY_CAREER = 3\n",
    "    RECOGNITION_CUT= 5\n",
    "    X_year = df_year[['max_absence-0-3', 'avg_absence-0-3', \n",
    "           'gender_f', 'gender_m', 'gender_none',\n",
    "           f'early_career_degree_{EARLY_CAREER}', \n",
    "           f'early_career_prod_{EARLY_CAREER}',\n",
    "           f'early_career_qual_{EARLY_CAREER}', f'early_career_recognition_EC{EARLY_CAREER}_RC{RECOGNITION_CUT}']]\n",
    "    y_year = df_year['succ_after_15y']\n",
    "    params_rfecv.append(get_features_rfecv(X_year, y_year, LinearRegression(),cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "selected_f = defaultdict(int)\n",
    "for param in params_rfecv:\n",
    "    selected = param[param.support == True]['feature'].values\n",
    "    selected_f['total'] += 1\n",
    "#     print(selected)\n",
    "    for select in selected:\n",
    "        selected_f[select] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "selected_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Null experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "citations_per_year = pd.read_csv('derived-data/paper-citation-count.csv', header=None, names=['pub_id', 'cit_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "publications = pd.read_csv('derived-data/author-publications.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# publications.sort_values(by='author').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# remove authors by career_len, and add start year\n",
    "publications = publications.merge(credible_authors[['author', 'start_year']], on='author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "publications = publications[publications.year <= publications.year + MAX_CAREER_LEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# citations_per_year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "publications['pub_id'] = shuffle(publications['pub_id']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# publications.sort_values(by='author').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "publications = publications.merge(citations_per_year, on='pub_id', how='left')\n",
    "publications = publications.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "publications.sort_values(by='author').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "credible_authors[credible_authors.author == \"a min tjoa\"]['succ_after_15y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "credible_authors.set_index('author', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "credible_authors['succ_shuffled'] = publications.groupby('author')['cit_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "credible_authors[['succ_shuffled', 'succ_after_15y']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "credible_authors.columns"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
