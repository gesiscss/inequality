{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: add \\addlinespace to the latex output files at lines 4,7,10,11 :)\n",
    "# TODO: one of the horizontal lines in latex is wrong, at line -4 instead of minus 3.\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, ElasticNet, ElasticNetCV, Lasso, LogisticRegressionCV, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, f1_score, matthews_corrcoef\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "CAREER_LENGTH = 1\n",
    "\n",
    "#EARLY_CAREER_LEN_LIST = [1, 2, 3, 4, 5]\n",
    "EARLY_CAREER_LEN_LIST = [3]\n",
    "EARLY_CAREER = 3\n",
    "#RECOGNITION_CUT_OFF_LIST = [3, 4, 5, 6, 7, 8, 9]\n",
    "RECOGNITION_CUT_OFF_LIST = [3]\n",
    "RECOGNITION_CUT = 3\n",
    "\n",
    "MAX_CAREER_LEN = 15\n",
    "END_YEAR = 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(292443, 107)\n"
     ]
    }
   ],
   "source": [
    "credible_authors = pd.read_csv('derived-data/authors-scientific-extended.csv')\n",
    "print(credible_authors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_size_year = pd.read_csv('derived-data/team_size_avg_per_year.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "years = sorted(credible_authors.start_year.unique())\n",
    "COHORT_START_YEARS = [y for y in years if y < (END_YEAR - MAX_CAREER_LEN)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#credible_authors.columns\n",
    "#print(credible_authors.groupby(\"start_year\")['dropped_after_10'].agg('sum'))\n",
    "#print(credible_authors.groupby(\"start_year\")['author'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(292443, 107)\n",
      "1\n",
      "[1992 1979 1995 1986 1998 1999 1980 1988 1996 1970 1994 1997 1987 1982\n",
      " 2000 1990 1989 1985 1974 1977 1993 1991 1975 1984 1983 1973 1972 1971\n",
      " 1981 1978 1976]\n",
      "(292443, 107)\n",
      "[1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000]\n"
     ]
    }
   ],
   "source": [
    "credible_authors = credible_authors[credible_authors.career_length >= CAREER_LENGTH]\n",
    "print(credible_authors.shape)\n",
    "print(CAREER_LENGTH)\n",
    "print(credible_authors.start_year.unique())\n",
    "\n",
    "credible_authors = credible_authors[credible_authors.start_year.isin(COHORT_START_YEARS)]\n",
    "\n",
    "print(credible_authors.shape)\n",
    "print(COHORT_START_YEARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['author', 'start_year', 'end_year', 'total_num_pub',\n",
       "       'career_length', 'max_absence-0-15', 'avg_absence-0-15',\n",
       "       'dropped_after_10', 'gender', 'ec_first_auth_3', 'ec_first_auth_5',\n",
       "       'ec_first_auth_7', 'ec_first_auth_9', 'ec_first_auth_11',\n",
       "       'ec_first_auth_12', 'team_size_median_3', 'team_size_mean_3',\n",
       "       'team_size_median_5', 'team_size_mean_5', 'team_size_median_7',\n",
       "       'team_size_mean_7', 'team_size_median_9', 'team_size_mean_9',\n",
       "       'team_size_median_11', 'team_size_mean_11', 'team_size_median_12',\n",
       "       'team_size_mean_12', 'h5_index_max_3', 'deciles_min_3',\n",
       "       'quantiles_min_3', 'quantiles_bin_3', 'h5_index_max_5',\n",
       "       'deciles_min_5', 'quantiles_min_5', 'quantiles_bin_5',\n",
       "       'h5_index_max_7', 'deciles_min_7', 'quantiles_min_7',\n",
       "       'quantiles_bin_7', 'h5_index_max_9', 'deciles_min_9',\n",
       "       'quantiles_min_9', 'quantiles_bin_9', 'h5_index_max_11',\n",
       "       'deciles_min_11', 'quantiles_min_11', 'quantiles_bin_11',\n",
       "       'h5_index_max_12', 'deciles_min_12', 'quantiles_min_12',\n",
       "       'quantiles_bin_12', 'early_career_degree_3',\n",
       "       'early_career_degree_5', 'early_career_degree_7',\n",
       "       'early_career_degree_9', 'early_career_degree_11',\n",
       "       'early_career_degree_12', 'early_career_qual_3',\n",
       "       'early_career_qual_first_3', 'early_career_qual_5',\n",
       "       'early_career_qual_first_5', 'early_career_qual_7',\n",
       "       'early_career_qual_first_7', 'early_career_qual_9',\n",
       "       'early_career_qual_first_9', 'early_career_qual_11',\n",
       "       'early_career_qual_first_11', 'early_career_qual_12',\n",
       "       'early_career_qual_first_12', 'early_career_recognition_EC3_RC3',\n",
       "       'early_career_recognition_EC5_RC5',\n",
       "       'early_career_recognition_EC7_RC7',\n",
       "       'early_career_recognition_EC9_RC9',\n",
       "       'early_career_recognition_EC11_RC11',\n",
       "       'early_career_recognition_EC12_RC12', 'succ_after_15y',\n",
       "       'h-index_3', 'h-index_5', 'h-index_7', 'h-index_9', 'h-index_11',\n",
       "       'h-index_12', 'h-index_15', 'early_career_prod_3',\n",
       "       'early_career_prod_5', 'early_career_prod_7',\n",
       "       'early_career_prod_9', 'early_career_prod_11',\n",
       "       'early_career_prod_12', 'early_career_coauthor_max_hindex_3',\n",
       "       'early_career_coauthor_max_hindex_5',\n",
       "       'early_career_coauthor_max_hindex_7',\n",
       "       'early_career_coauthor_max_hindex_9',\n",
       "       'early_career_coauthor_max_hindex_11',\n",
       "       'early_career_coauthor_max_hindex_12', 'citation_increase_15_3',\n",
       "       'h_index_increase_15_3', 'citation_increase_15_5',\n",
       "       'h_index_increase_15_5', 'citation_increase_15_7',\n",
       "       'h_index_increase_15_7', 'citation_increase_15_9',\n",
       "       'h_index_increase_15_9', 'citation_increase_15_11',\n",
       "       'h_index_increase_15_11', 'citation_increase_15_12',\n",
       "       'h_index_increase_15_12'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credible_authors.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: move this to 0. also check it \n",
    "EARLY_CAREER_LEN_LIST_EXT = [3,5,7,9,11,12]\n",
    "RECOGNITION_CUT_OFF_LIST_EXT = [3,5,7,9,11,12]\n",
    "# EARLY_CAREER_LEN_LIST_EXT = [3]\n",
    "# RECOGNITION_CUT_OFF_LIST_EXT = [3]\n",
    "\n",
    "for year in EARLY_CAREER_LEN_LIST_EXT:\n",
    "    credible_authors[f'citation_increase_15_{year}'] = credible_authors['succ_after_15y'] - credible_authors[\n",
    "        f'early_career_recognition_EC{year}_RC{year}']\n",
    "    credible_authors[f'h_index_increase_{year}_{EARLY_CAREER}'] = credible_authors[\n",
    "        f'h-index_{year}'] - credible_authors[f'h-index_{EARLY_CAREER}']\n",
    "    credible_authors[f'h_index_increase_15_{EARLY_CAREER}'] = credible_authors[\n",
    "        f'h-index_15'] - credible_authors[f'h-index_{EARLY_CAREER}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in EARLY_CAREER_LEN_LIST_EXT[1:]:\n",
    "    credible_authors[f'citation_increase_{year}_{EARLY_CAREER}'] = credible_authors[\n",
    "        f'early_career_recognition_EC{year}_RC{year}'] - credible_authors[f'early_career_recognition_EC{EARLY_CAREER}_RC{EARLY_CAREER}']\n",
    "    credible_authors[f'h_index_increase_{year}_{EARLY_CAREER}'] = credible_authors[f'h-index_{year}'] - credible_authors[f'h-index_{EARLY_CAREER}']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "cols = ['succ_after_15y', 'h_index_increase_15_3', 'citation_increase_15_3', 'max_absence-0-15', \n",
    "        'early_career_prod_3', 'early_career_degree_3', 'early_career_coauthor_max_hindex_12', \n",
    "        'early_career_recognition_EC3_RC3', 'early_career_qual_12']\n",
    "\n",
    "col_names_short = ['succ', 'hindex_incr', 'cit_incr', 'max_abs', \n",
    "        'prod_3', 'degree_3', 'maxh_3', \n",
    "        'rec_3', 'qual_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "cor_qual = credible_authors[cols].corr(method='kendall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "cor_qual\n",
    "#cor_qual['succ_after_15y'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cor_qual, vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,9,1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(col_names_short, rotation=45)\n",
    "ax.set_yticklabels(col_names_short)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cor = credible_authors.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cor_qual[f'h_index_increase_15_{EARLY_CAREER}'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.heatmap(cor, center=0,\n",
    "#             square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test different predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# test different early career lenghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "year = 1995\n",
    "\n",
    "credible_authors_1991 = credible_authors[credible_authors.start_year == year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "X = credible_authors_1991.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "categorical_cols = ['gender']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    X = X.join(pd.get_dummies(X[categorical_cols]))\n",
    "\n",
    "X.drop(categorical_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def run_linear(func, name):\n",
    "    df = pd.DataFrame(columns=['params', f'r_squared_{name}'])\n",
    "    for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "        for RECOGNITION_CUT in RECOGNITION_CUT_OFF_LIST:\n",
    "            if RECOGNITION_CUT < EARLY_CAREER: continue\n",
    "            H = X[[\n",
    "                #'max_absence-0-3', 'avg_absence-0-3',\n",
    "                   'gender_f', 'gender_m', 'gender_none',\n",
    "                   f'early_career_degree_{EARLY_CAREER}', \n",
    "                   f'early_career_prod_{EARLY_CAREER}',\n",
    "                   f'early_career_qual_{EARLY_CAREER}', f'early_career_recognition_EC{EARLY_CAREER}_RC{RECOGNITION_CUT}']]\n",
    "            reg = func.fit(H, y)\n",
    "            df = df.append({'params': f'EC:{EARLY_CAREER},REC:{RECOGNITION_CUT}',\n",
    "                            f'r_squared_{name}': reg.score(H, y)}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def run_cv(func, name, cv, y_col='succ_after_15y'):\n",
    "    df = pd.DataFrame(columns=['params', f'r_squared_{name}'])\n",
    "    for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "        for RECOGNITION_CUT in RECOGNITION_CUT_OFF_LIST:\n",
    "            if RECOGNITION_CUT < EARLY_CAREER: continue\n",
    "            H = X[[\n",
    "                #'max_absence-0-3', 'avg_absence-0-3',\n",
    "                   'gender_f', 'gender_m', 'gender_none',\n",
    "                   f'early_career_degree_{EARLY_CAREER}', \n",
    "                   f'early_career_prod_{EARLY_CAREER}',\n",
    "                   f'early_career_qual_{EARLY_CAREER}', f'early_career_recognition_EC{EARLY_CAREER}_RC{RECOGNITION_CUT}']]\n",
    "            y = X[y_col]\n",
    "            score = np.mean(cross_val_score(func, H, y, cv=cv, scoring='r2'))\n",
    "            df = df.append({'params': f'EC:{EARLY_CAREER},REC:{RECOGNITION_CUT}',\n",
    "                            f'r_squared_{name}': score}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1 = run_cv(LinearRegression(), 'linear', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# df1_null = run_cv(LinearRegression(), 'linear_null', cv=3, y_col='succ_shuffled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2 = run_cv(ElasticNet(), 'elastic', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df3 = run_cv(ElasticNetCV(cv=3), 'elastic_CV', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df4 = run_cv(Lasso(alpha=0.1), 'lasso', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Decision tree overfits pretty bad. Maybe GridParam Search?\n",
    "df5 = run_cv(DecisionTreeRegressor(), 'tree', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df6 = run_cv(RandomForestRegressor(), 'forest', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# df6_null = run_cv(RandomForestRegressor(), 'forest_null', cv=3, y_col='succ_shuffled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfs = [df1, df2, df3, df4, df5, df6] #df1_null, df6_null\n",
    "for df_ in dfs: df_.set_index('params', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfs[0].join(dfs[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EARLY_CAREER = EARLY_CAREER_LEN_LIST[0]\n",
    "# RECOGNITION_CUT = RECOGNITION_CUT_OFF_LIST[0]\n",
    "EARLY_CAREER_LEN_LIST = [3,5,7,9,11,12]\n",
    "RECOGNITION_CUT_OFF_LIST = [3,5,7,9,11,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,RobustScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_percent = credible_authors.groupby('start_year')['dropped_after_10'].sum() / credible_authors.groupby('start_year')['dropped_after_10'].count()\n",
    "dropped_percent = dropped_percent.to_frame().T\n",
    "\n",
    "dropped_percent_agg = credible_authors['dropped_after_10'].sum() / credible_authors['dropped_after_10'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_authors_stayed = credible_authors[credible_authors['dropped_after_10'] == False].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 groups of features: productivity, social capital, quality/rec and gender\n",
    "def make_cols_lists(INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC, INCLUDE_QUALITY, INCLUDE_GENDER, REMOVE_NONE_AUTHORS, \n",
    "                    INCLUDE_VENUE, INCLUDE_YEAR, EARLY_CAREER, RECOGNITION_CUT, dep_var):\n",
    "    categorical_cols = []\n",
    "    cols_std = []\n",
    "\n",
    "    if INCLUDE_YEAR:\n",
    "        cols_std.append(\"start_year\")\n",
    "    #scale dependant var\n",
    "    if dep_var == \"dropped_after_10\":\n",
    "        categorical_cols.append(dep_var)\n",
    "    else:\n",
    "        cols_std.append(dep_var)\n",
    "\n",
    "    if INCLUDE_PROD:\n",
    "        cols_std.append(f'early_career_prod_{EARLY_CAREER}')\n",
    "        cols_std.append(f'ec_first_auth_{EARLY_CAREER}')\n",
    "\n",
    "    if INCLUDE_SOCIAL:\n",
    "        cols_std.append(f'early_career_degree_{EARLY_CAREER}')\n",
    "        cols_std.append(f'early_career_coauthor_max_hindex_{EARLY_CAREER}')\n",
    "        cols_std.append(f'team_size_median_{EARLY_CAREER}')\n",
    "    #     cols_std.append(f'early_career_coauthor_max_cit_{EARLY_CAREER}')\n",
    "\n",
    "    if INCLUDE_REC:\n",
    "        cols_std.append(f'early_career_recognition_EC{EARLY_CAREER}_RC{RECOGNITION_CUT}')\n",
    "\n",
    "    if INCLUDE_QUALITY:\n",
    "        cols_std.append(f'early_career_qual_{EARLY_CAREER}')\n",
    "        cols_std.append(f'early_career_qual_first_{EARLY_CAREER}')\n",
    "\n",
    "    if INCLUDE_GENDER:\n",
    "        categorical_cols.append('gender')\n",
    "\n",
    "    if INCLUDE_VENUE:\n",
    "        cols_std.extend([f'quantiles_bin_{EARLY_CAREER}']) #'deciles_min_3''quantiles_min_3', 'quantiles_bin_3'\n",
    "    \n",
    "    return cols_std, categorical_cols #cols_all, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO we scale data every time we train. Modify to keep data and add remove parameters. Somehow separate the prep from train\n",
    "def scale_columns(X):\n",
    "    if len(X.columns) > 0:\n",
    "        scaler = RobustScaler().fit(X)\n",
    "#         print(scaler.mean_)\n",
    "        standardized_cols = scaler.transform(X)\n",
    "    else: \n",
    "        standardized_cols = []\n",
    "    return pd.DataFrame(standardized_cols, index=X.index, columns=X.columns)\n",
    "\n",
    "def prepare_data(credible_authors, cols_std, categorical_cols, REMOVE_NONE_AUTHORS, aggr=False):\n",
    "    X = credible_authors[credible_authors.start_year.isin(COHORT_START_YEARS)].copy()\n",
    "    \n",
    "    # Either scale OR INCLUDE start_year as control Var\n",
    "    # scale dependent variables per year --> WE SHOULD ALSO SCALE OUTCOME VAR\n",
    "    \n",
    "    if not aggr:\n",
    "        for year in COHORT_START_YEARS:\n",
    "            X.loc[X.start_year == year, cols_std] = scale_columns(X.loc[X.start_year == year, cols_std])\n",
    "    else:\n",
    "#     scale over whole dataset\n",
    "        X[cols_std] = scale_columns(X[cols_std])\n",
    "    \n",
    "    # make dummies of categorical cols\n",
    "    if len(categorical_cols)>0:\n",
    "        cat_cols = pd.get_dummies(X[categorical_cols]) \n",
    "        X = X[cols_std].join(cat_cols)\n",
    "    else:\n",
    "        X = X[cols_std]\n",
    "    if REMOVE_NONE_AUTHORS:\n",
    "        X.drop('gender_none' , axis=1)\n",
    "    X['start_year'] = credible_authors['start_year']\n",
    "    return X\n",
    "\n",
    "def run_elastic_net_aggr(credible_authors, cols_std, categorical_cols, INCLUDE_YEAR, REMOVE_NONE_AUTHORS, dep_var):\n",
    "    X = prepare_data(credible_authors, cols_std, categorical_cols, REMOVE_NONE_AUTHORS, aggr=True)\n",
    "    Y = X[dep_var].copy()\n",
    "    X = X.drop(dep_var, axis=1)\n",
    "#     Y = credible_authors[dep_var]\n",
    "   \n",
    "    if not INCLUDE_YEAR:\n",
    "        X = X.drop('start_year' , axis=1)\n",
    "#     else:\n",
    "#         # Robust scaler seems to be a poor choice here. Maybe minmax?\n",
    "#         X['start_year'] = MinMaxScaler().fit_transform(X['start_year'].to_frame())\n",
    "    \n",
    "   \n",
    "    feat_table = run_elastic_net(X, Y)\n",
    "    feat_table = feat_table.set_index(0)\n",
    "    \n",
    "    if dep_var == 'dropped_after_10': \n",
    "        feat_table = feat_table.append(pd.DataFrame(index=['drop_percentage'], data=[dropped_percent_agg], columns=[1]))\n",
    "    return feat_table\n",
    "\n",
    "def run_elastic_net_cohort(credible_authors, cols_std, categorical_cols, REMOVE_NONE_AUTHORS, dep_var):\n",
    "    table_list = []\n",
    "    X = prepare_data(credible_authors, cols_std, categorical_cols, REMOVE_NONE_AUTHORS)\n",
    "    # TODO This means we are scaling data over whole dataset even for cohort analysis!\n",
    "    for year in COHORT_START_YEARS:\n",
    "        X_year = X[X.start_year == year]\n",
    "#         y_year = credible_authors[credible_authors.start_year == year][dep_var]\n",
    "        y_year = X_year[dep_var].copy()\n",
    "        X_year = X_year.drop(dep_var, axis=1)\n",
    "        print(year, end=' ')\n",
    "        feat_data = run_elastic_net(X_year.drop('start_year', axis=1), y_year)\n",
    "        feat_data = feat_data.set_index(0)\n",
    "        feat_data.rename(index=str, columns={1: year}, inplace=True)\n",
    "        table_list.append(feat_data)\n",
    "       \n",
    "    table = pd.DataFrame(index=table_list[0].index)\n",
    "    for x in table_list: table=table.join(x)\n",
    "    if dep_var == 'dropped_after_10': table = table.append(dropped_percent)\n",
    "    return table\n",
    "\n",
    "def run_elastic_net(X, y):\n",
    "    # train model and do cross validation\n",
    "\n",
    "    # add dummy var if no features are given\n",
    "    # TODO is this still used?\n",
    "    if X.empty:\n",
    "        X = pd.DataFrame(1, index=np.arange(len(y)), columns=[\"dummy\"])\n",
    "    \n",
    "    \n",
    "    if y.nunique()==2:   \n",
    "        y = y.astype(int)\n",
    "        #f1, average_precision, roc_auc\n",
    "        cv_dict = cross_validate(LogisticRegressionCV(cv=10, penalty='l2', max_iter=200), X, y, scoring=\"average_precision\", cv=10, \n",
    "                                 return_estimator=True, return_train_score=False)\n",
    "        net_coef = pd.DataFrame([es.coef_[0] for es in cv_dict['estimator']], columns=X.columns)\n",
    "#         print(cv_dict)\n",
    "        score = np.mean(cv_dict['test_score'])\n",
    "        score2 = None\n",
    "    else:\n",
    "        cv_dict = cross_validate(ElasticNetCV(cv=10), X, y, scoring=['r2', 'neg_mean_squared_error'], \n",
    "                                 cv=10, return_estimator=True, return_train_score=False)\n",
    "        net_coef = pd.DataFrame([es.coef_ for es in cv_dict['estimator']], columns=X.columns)\n",
    "        score = np.mean(cv_dict['test_r2'])\n",
    "        score2 = np.mean(cv_dict['test_neg_mean_squared_error'])\n",
    "\n",
    "    # save the intercepts\n",
    "    net_intercept = np.mean([es.intercept_ for es in cv_dict['estimator']])\n",
    "    # take the mean and std from coefs\n",
    "    net_coef_mean = net_coef.mean()\n",
    "    net_coef_std = net_coef.std()\n",
    "    rounding = 2\n",
    "    net_coef_mean_std = list(zip(np.round(net_coef_mean.values,rounding), np.round(net_coef_std.values,rounding)))\n",
    "    net_coef_mean_std = [f\"{x[0]}({x[1]})\" for x in net_coef_mean_std]\n",
    "\n",
    "    cohort_size = len(y)\n",
    "    #     num_nonzero_coefs = sum(net2.coef_ != 0)\n",
    "    #     adj_score2 = 1 - (1-score2)*(cohort_size-1)/(cohort_size-num_nonzero_coefs-1)\n",
    "    if score2:\n",
    "        net_coef_mean_std.extend([np.round(net_intercept, rounding), np.round(score, rounding), np.round(score2, rounding), cohort_size])\n",
    "        feat_table = pd.DataFrame(list(zip(np.append(X.columns, ['intercept', 'r2', 'neg_mean_squared_error', 'cohort_size']), net_coef_mean_std)))\n",
    "    else:\n",
    "        net_coef_mean_std.extend([np.round(net_intercept, rounding), np.round(score, rounding), cohort_size])\n",
    "        feat_table = pd.DataFrame(list(zip(np.append(X.columns, ['intercept', 'avg_precision', 'cohort_size']), net_coef_mean_std)))\n",
    "    return feat_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Stuff that we potentially use as outcome Vars\n",
    "# dv_hindex = 'h-index_15'\n",
    "# dv_citations = 'succ_after_15y'\n",
    "\n",
    "dv_hindex_incr = f'h_index_increase_15_{EARLY_CAREER}'\n",
    "dv_citations_incr = f'citation_increase_15_{EARLY_CAREER}'\n",
    "dv_dropped = 'dropped_after_10'\n",
    "\n",
    "DV = dv_hindex_incr\n",
    "\n",
    "# check if outcome vars are plausible\n",
    "# #print(credible_authors.columns)\n",
    "# credible_authors[[\"start_year\", \"succ_after_15y\"]].groupby(\"start_year\").mean().plot()\n",
    "# credible_authors[[\"start_year\", \"h_index_increase_15_3\"]].groupby(\"start_year\").mean().plot()\n",
    "# credible_authors[[\"start_year\", \"citation_increase_15_3\"]].groupby(\"start_year\").mean().plot()\n",
    "# credible_authors[[\"start_year\", \"avg_absence-0-15\"]].groupby(\"start_year\").mean().plot()\n",
    "# credible_authors[[\"start_year\", \"dropped_after_10\"]].groupby(\"start_year\").mean().plot()\n",
    "# credible_authors[[\"start_year\", \"total_num_pub\"]].groupby(\"start_year\").mean().plot()\n",
    "# credible_authors[[\"start_year\", \"career_length\"]].groupby(\"start_year\").mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort Elastic Net Models\n",
    "We compare the predictive performance across cohorts. We should plot R2 and F1 over cohorts.\n",
    "Is predictive performance stable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     8
    ]
   },
   "outputs": [],
   "source": [
    "def make_result_table(feature_table):\n",
    "    results = feature_table.transpose()\n",
    "    #shorten column names\n",
    "    new_cols = dict(zip(results.columns, [col.replace('early_career', 'ec') for col in results.columns]))\n",
    "\n",
    "    results.rename(new_cols, axis='columns', inplace=True)\n",
    "    results.rename({'feature':'cohort','ec_coauthor_max_cit_3': 'ec_coauth_max_cit_3', 'ec_recognition_EC3_RC5':'ec_recog_EC3_RC5'}, axis='columns', inplace=True)\n",
    "    return results\n",
    "def results_to_latex(results, name):\n",
    "    ltx_file = open(f\"results_{name}.tex\", \"w\")\n",
    "    ltx_file.write('\\n'.join(results.to_latex().split('\\n')[5:-7]))\n",
    "    ltx_file.write('\\hline \\n')\n",
    "    ltx_file.write('\\n'.join(results.to_latex().split('\\n')[-7:-3]))\n",
    "    ltx_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     10,
     20,
     30,
     40,
     50,
     62,
     116
    ]
   },
   "outputs": [],
   "source": [
    "def get_baseline_vars():\n",
    "    INCLUDE_PROD = 0\n",
    "    INCLUDE_SOCIAL = 0\n",
    "    INCLUDE_REC = 0\n",
    "    INCLUDE_QUALITY = 0\n",
    "    INCLUDE_GENDER = 0\n",
    "    REMOVE_NONE_AUTHORS = 0\n",
    "    INCLUDE_VENUE = 0\n",
    "    INCLUDE_YEAR = 1\n",
    "    return INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC, INCLUDE_QUALITY, INCLUDE_GENDER, REMOVE_NONE_AUTHORS,INCLUDE_VENUE,INCLUDE_YEAR\n",
    "def get_human_cap_vars():\n",
    "    INCLUDE_PROD = 1\n",
    "    INCLUDE_SOCIAL = 0\n",
    "    INCLUDE_REC = 1\n",
    "    INCLUDE_QUALITY = 0\n",
    "    INCLUDE_GENDER = 0\n",
    "    REMOVE_NONE_AUTHORS = 0\n",
    "    INCLUDE_VENUE = 0\n",
    "    INCLUDE_YEAR = 1\n",
    "    return INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC, INCLUDE_QUALITY, INCLUDE_GENDER, REMOVE_NONE_AUTHORS,INCLUDE_VENUE,INCLUDE_YEAR\n",
    "def get_gender_vars():\n",
    "    INCLUDE_PROD = 1\n",
    "    INCLUDE_SOCIAL = 0\n",
    "    INCLUDE_REC = 1\n",
    "    INCLUDE_GENDER = 1\n",
    "    INCLUDE_QUALITY = 0\n",
    "    REMOVE_NONE_AUTHORS = 0\n",
    "    INCLUDE_VENUE = 0\n",
    "    INCLUDE_YEAR = 1\n",
    "    return INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC, INCLUDE_QUALITY, INCLUDE_GENDER, REMOVE_NONE_AUTHORS,INCLUDE_VENUE,INCLUDE_YEAR\n",
    "def get_social_vars():\n",
    "    INCLUDE_PROD = 1\n",
    "    INCLUDE_SOCIAL = 1\n",
    "    INCLUDE_REC = 1\n",
    "    INCLUDE_GENDER = 1\n",
    "    INCLUDE_QUALITY = 0\n",
    "    REMOVE_NONE_AUTHORS = 0\n",
    "    INCLUDE_VENUE = 0\n",
    "    INCLUDE_YEAR = 1\n",
    "    return INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC, INCLUDE_QUALITY, INCLUDE_GENDER, REMOVE_NONE_AUTHORS,INCLUDE_VENUE,INCLUDE_YEAR\n",
    "def get_symbolic_vars():\n",
    "    INCLUDE_PROD = 1\n",
    "    INCLUDE_SOCIAL = 1\n",
    "    INCLUDE_REC = 1\n",
    "    INCLUDE_GENDER = 1\n",
    "    INCLUDE_QUALITY = 0\n",
    "    REMOVE_NONE_AUTHORS = 0\n",
    "    INCLUDE_VENUE = 1\n",
    "    INCLUDE_YEAR = 1\n",
    "    return INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC, INCLUDE_QUALITY, INCLUDE_GENDER, REMOVE_NONE_AUTHORS,INCLUDE_VENUE,INCLUDE_YEAR\n",
    "def get_full_vars():\n",
    "    INCLUDE_PROD = 1\n",
    "    INCLUDE_SOCIAL = 1\n",
    "    INCLUDE_REC = 1\n",
    "    INCLUDE_GENDER = 1\n",
    "    INCLUDE_QUALITY = 1\n",
    "    REMOVE_NONE_AUTHORS = 0\n",
    "    INCLUDE_VENUE = 1\n",
    "    INCLUDE_YEAR = 1\n",
    "    return INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC, INCLUDE_QUALITY, INCLUDE_GENDER, REMOVE_NONE_AUTHORS,INCLUDE_VENUE,INCLUDE_YEAR\n",
    "\n",
    "# Run the elastic net across cohorts\n",
    "def elastic_cohort(credible_authors, params_func, EARLY_CAREER, RECOGNITION_CUT, DV):\n",
    "    params = params_func()\n",
    "    cols_std, categorical_cols = make_cols_lists(*params, EARLY_CAREER, RECOGNITION_CUT, DV)\n",
    "    print(cols_std)\n",
    "    REMOVE_NONE_AUTHORS = params[-3]\n",
    "    res = run_elastic_net_cohort(credible_authors, cols_std, categorical_cols, REMOVE_NONE_AUTHORS, DV)\n",
    "    res = make_result_table(res)\n",
    "    return res\n",
    "def elastic_agg(credible_authors, params_func, EARLY_CAREER, RECOGNITION_CUT, DV):\n",
    "    params = params_func()\n",
    "    cols_std, categorical_cols = make_cols_lists(*params, EARLY_CAREER, RECOGNITION_CUT, DV)\n",
    "    INCLUDE_YEAR = params[-1]\n",
    "    REMOVE_NONE_AUTHORS = params[-3]\n",
    "    res_agg = run_elastic_net_aggr(credible_authors, cols_std, categorical_cols, INCLUDE_YEAR, REMOVE_NONE_AUTHORS, DV)\n",
    "    return res_agg\n",
    "# Run the elastic net across grouped data, for all variations\n",
    "def elastic_agg_all(credible_authors, EARLY_CAREER, RECOGNITION_CUT, DV):\n",
    "    params_func_list = [get_baseline_vars, get_human_cap_vars, get_gender_vars, get_social_vars, get_symbolic_vars, get_full_vars]\n",
    "    res_agg_list = [elastic_agg(credible_authors, params_func, EARLY_CAREER, RECOGNITION_CUT, DV) for params_func in params_func_list]\n",
    "    res_all_agg = pd.DataFrame(index=res_agg_list[-1].index, data=[])\n",
    "    res_all_agg['baseline'] = res_agg_list[0]\n",
    "    res_all_agg['human'] = res_agg_list[1]\n",
    "    res_all_agg['gender'] = res_agg_list[2]\n",
    "    res_all_agg['social'] = res_agg_list[3]\n",
    "    res_all_agg['symbolic'] = res_agg_list[4]\n",
    "    res_all_agg['full_model'] = res_agg_list[5]\n",
    "    if DV == 'dropped_after_10':\n",
    "        reorderlist = ['start_year', 'early_career_prod_3', 'early_career_recognition_EC3_RC3', 'ec_first_auth_3',\n",
    "                   'gender_f', 'gender_m', 'gender_none', \n",
    "                   'early_career_degree_3', 'early_career_coauthor_max_hindex_3', 'team_size_median_3',\n",
    "                   'quantiles_bin_3', 'early_career_qual_3', 'early_career_qual_first_3',\n",
    "                   'cohort_size', 'drop_percentage','avg_precision']\n",
    "        res_all_agg = res_all_agg.reindex(reorderlist)\n",
    "        res_all_agg = res_all_agg.fillna('')\n",
    "        res_all_agg['names'] = ['start year', 'productivity', 'recognition', 'prod first author',\n",
    "                       'male', 'female', 'none', \n",
    "                       'degree', 'coauthor hindex', 'median team size',\n",
    "                       'top-venue', 'quality', 'quality first author',\n",
    "                       'cohort size', '% dropouts','Average precision']\n",
    "    else:\n",
    "        reorderlist = ['start_year', 'early_career_prod_3', 'early_career_recognition_EC3_RC3', 'ec_first_auth_3',\n",
    "                   'gender_f', 'gender_m', 'gender_none', \n",
    "                   'early_career_degree_3', 'early_career_coauthor_max_hindex_3', 'team_size_median_3',\n",
    "                   'quantiles_bin_3', 'early_career_qual_3',  'early_career_qual_first_3',\n",
    "                   'cohort_size', 'neg_mean_squared_error', 'intercept','r2']\n",
    "        res_all_agg = res_all_agg.reindex(reorderlist)\n",
    "        res_all_agg = res_all_agg.fillna('')\n",
    "        res_all_agg['names'] = ['start year', 'productivity', 'recognition', 'prod first author', \n",
    "                       'male', 'female', 'none', \n",
    "                       'degree', 'coauthor hindex', 'median team size',\n",
    "                       'top-venue', 'quality', 'quality first author',\n",
    "                       'cohort size', 'MSE', 'intercept','R2']\n",
    "    res_all_agg = res_all_agg.set_index('names')\n",
    "    return res_all_agg\n",
    "def get_report_from_table(result_table):\n",
    "    report = []\n",
    "    for col in result_table.columns[:-4]:\n",
    "        float_vals = result_table[col].apply(lambda x: float(x.split('(')[0]))\n",
    "        num_positive = float_vals.gt(0).sum()\n",
    "        num_neg = float_vals.lt(0).sum()\n",
    "        report.append({\n",
    "            \"feature\": col, \n",
    "            'num_positive': num_positive, \n",
    "            'num_negative': num_neg,\n",
    "            'mean': float_vals.mean()})\n",
    "    return pd.DataFrame(report).set_index('feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "res_cohort_base_hind = elastic_cohort(credible_authors, get_baseline_vars, EARLY_CAREER, RECOGNITION_CUT,\n",
    "                                      dv_hindex_incr)\n",
    "# res_cohort_base_cita = elastic_cohort(credible_authors, get_baseline_vars, EARLY_CAREER, RECOGNITION_CUT,\n",
    "#                                       dv_citations_incr)\n",
    "# res_cohort_base_drop = elastic_cohort(get_baseline_vars, EARLY_CAREER, RECOGNITION_CUT, dv_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# res_cohort_base_hind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Human Capital Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res_cohort_humcap_hind = elastic_cohort(credible_authors, get_human_cap_vars, EARLY_CAREER, RECOGNITION_CUT,\n",
    "                                        dv_hindex_incr)\n",
    "# res_cohort_humcap_cita = elastic_cohort(credible_authors, get_human_cap_vars, EARLY_CAREER, RECOGNITION_CUT,\n",
    "#                                         dv_citations_incr)\n",
    "# res_cohort_humcap_drop = elastic_cohort(get_human_cap_vars, EARLY_CAREER, RECOGNITION_CUT, dv_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#no scale\n",
    "res_cohort_humcap_hind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#robust\n",
    "res_cohort_humcap_hind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#no scale\n",
    "# res_cohort_humcap_hind.apply(lambda x: float(x['ec_prod_3'].split('(')[0])+float(x['ec_prod_4'].split('(')[0]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#robust\n",
    "res_cohort_humcap_hind.apply(lambda x: float(x['ec_prod_3'].split('(')[0])+float(x['ec_prod_4'].split('(')[0]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "r2_old_col = res_cohort_humcap_hind.r2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Gender Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "res_cohort_gender_hind = elastic_cohort(credible_authors, get_gender_vars, EARLY_CAREER, RECOGNITION_CUT,\n",
    "                                        dv_hindex_incr)\n",
    "res_cohort_gender_cita = elastic_cohort(credible_authors, get_gender_vars, EARLY_CAREER, RECOGNITION_CUT,\n",
    "                                        dv_citations_incr)\n",
    "# res_cohort_gender_drop = elastic_cohort(get_gender_vars, EARLY_CAREER, RECOGNITION_CUT, dv_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "res_cohort_gender_hind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Social Capital Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "res_cohort_soccap_hind = elastic_cohort(credible_authors, get_social_vars, EARLY_CAREER, RECOGNITION_CUT,\n",
    "                                        dv_hindex_incr)\n",
    "res_cohort_soccap_cita = elastic_cohort(credible_authors, get_social_vars, EARLY_CAREER, RECOGNITION_CUT,\n",
    "                                        dv_citations_incr)\n",
    "# res_cohort_soccap_drop = elastic_cohort(get_social_vars, EARLY_CAREER, RECOGNITION_CUT, dv_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "res_cohort_soccap_hind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Symbolic Capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "res_cohort_symcap_hind = elastic_cohort(credible_authors, get_symbolic_vars, EARLY_CAREER, RECOGNITION_CUT,\n",
    "                                        dv_hindex_incr)\n",
    "res_cohort_symcap_cita = elastic_cohort(credible_authors, get_symbolic_vars, EARLY_CAREER, RECOGNITION_CUT,\n",
    "                                        dv_citations_incr)\n",
    "# res_cohort_symcap_drop = elastic_cohort(get_symbolic_vars, EARLY_CAREER, RECOGNITION_CUT, dv_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "res_cohort_symcap_hind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Model (Extended Human Capital)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "res_cohort_full_hind = elastic_cohort(credible_authors, get_full_vars, EARLY_CAREER, RECOGNITION_CUT, dv_hindex_incr)\n",
    "res_cohort_full_cita = elastic_cohort(credible_authors, get_full_vars, EARLY_CAREER, RECOGNITION_CUT, dv_citations_incr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_cohort_full_drop = elastic_cohort(credible_authors, get_full_vars, EARLY_CAREER, RECOGNITION_CUT, dv_dropped)\n",
    "res_cohort_full_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_report_from_table(res_cohort_full_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_report_from_table(res_cohort_full_hind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Stayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#stayed\n",
    "res_cohort_full_hind_stay = elastic_cohort(credible_authors_stayed, get_full_vars,\n",
    "                                           EARLY_CAREER, RECOGNITION_CUT, dv_hindex_incr)\n",
    "res_cohort_full_hind_stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "res_cohort_full_cita_stay = elastic_cohort(credible_authors_stayed, get_full_vars, EARLY_CAREER, RECOGNITION_CUT, \n",
    "                                           dv_citations_incr)\n",
    "res_cohort_full_cita_stay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Plot prediction success over cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.set_palette('deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_metric_over_cohorts(data, criteria, criteria_name, title, letter, filename, legend=False):\n",
    "    linewidth = 2\n",
    "    fontsize = 18\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    ax = fig.add_subplot(111)\n",
    "    labels = ['h_index']\n",
    "    i=0\n",
    "    ax.plot(data.index, data[criteria], linewidth=linewidth, label=labels[i], color=sns.color_palette()[0])\n",
    "    ax.xaxis.set_ticks_position('both')\n",
    "    ax.yaxis.set_ticks_position('both')\n",
    "    if 'r2' in criteria:\n",
    "        ax.set_ylim([0.18, 0.65])\n",
    "    if 'precision' in criteria:\n",
    "        ax.set_ylim([0.7, 1.05])\n",
    "    ax.set_xlabel('Cohort year', fontsize=fontsize)\n",
    "    ax.set_ylabel(f'{criteria_name}', fontsize=fontsize)\n",
    "    ax.set_title(title, fontsize=fontsize)\n",
    "    ax.tick_params(axis=\"x\", which='major', direction=\"in\", width=linewidth, size=4*linewidth, labelsize=fontsize, pad=7)\n",
    "    ax.tick_params(axis=\"x\", which='minor', direction=\"in\", width=linewidth, size=2*linewidth, labelsize=fontsize, pad=7)\n",
    "    ax.tick_params(axis=\"y\", which='major', direction=\"in\", width=linewidth, size=4*linewidth, labelsize=fontsize)\n",
    "    ax.tick_params(axis=\"y\", which='minor', direction=\"in\", width=linewidth, size=2*linewidth, labelsize=fontsize)\n",
    "    ax.spines['left'].set_linewidth(linewidth)\n",
    "    ax.spines['right'].set_linewidth(linewidth)\n",
    "    ax.spines['bottom'].set_linewidth(linewidth)\n",
    "    ax.spines['top'].set_linewidth(linewidth)\n",
    "    if legend: ax.legend(fontsize=fontsize/2)\n",
    "    plt.gcf().text(0., 0.9, letter, fontsize=fontsize*2)\n",
    "    plt.subplots_adjust(left=0.25, right=0.95, bottom=0.2, top=0.9)\n",
    "    fig.savefig(f'./fig/{filename}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_metric_over_cohorts(res_cohort_full_hind, 'r2', 'R squared', 'H index increase - full', 'A', 'pred_r2_hind_full')\n",
    "# plot_metric_over_cohorts(res_cohort_sym_hind, 'r2', 'R squared', 'H index increase prediction - symbolic', 'A')\n",
    "plot_metric_over_cohorts(res_cohort_full_cita, 'r2', 'R squared', 'Citation increase - full', 'B', 'pred_r2_cita_full')\n",
    "# plot_metric_over_cohorts(res_cohort_full_drop, 'avg_precision', 'Average precision', 'Dropout prediction - full', 'C', 'pred_avgp_drop_full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregated Elastic Net Models\n",
    "We test the effect of different groups of features (human capital, social capital and gender) on success/dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv_hindex_incr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_ind_agg_all = elastic_agg_all(credible_authors, EARLY_CAREER, RECOGNITION_CUT, dv_hindex_incr)\n",
    "results_to_latex(h_ind_agg_all, 'agg_hindex')\n",
    "h_ind_agg_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cit_agg_all = elastic_agg_all(credible_authors, EARLY_CAREER, RECOGNITION_CUT, dv_citations_incr)\n",
    "results_to_latex(cit_agg_all, 'agg_citations')\n",
    "cit_agg_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_agg_all = elastic_agg_all(credible_authors, EARLY_CAREER, RECOGNITION_CUT, dv_dropped)\n",
    "results_to_latex(drop_agg_all, 'agg_dropout')\n",
    "drop_agg_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run different configs of the elastic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Test train split 80-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def run_elastic_predictions_test_train(cols_all, cols_std, categorical_cols, REMOVE_NONE_AUTHORS, EARLY_CAREER):\n",
    "    feature_table = pd.DataFrame(cols_all, columns=['feature']).set_index('feature')\n",
    "    feature_table2 = pd.DataFrame(cols_all, columns=['feature']).set_index('feature')\n",
    "    feature_table3 = pd.DataFrame(cols_all, columns=['feature']).set_index('feature')\n",
    " \n",
    "    for year in [1970,1999,2000,2001,2002]:\n",
    "        credible_authors_year = credible_authors[credible_authors.start_year == year]\n",
    "\n",
    "        X = credible_authors_year.copy()\n",
    "\n",
    "        #remove non-gender rows\n",
    "        if REMOVE_NONE_AUTHORS:\n",
    "            X = X[X[\"gender\"]!=\"none\"]\n",
    "\n",
    "        # Make dummy values for categorical columns\n",
    "        gender_cols = pd.get_dummies(X[categorical_cols])\n",
    "\n",
    "        #if(not REMOVE_NONE_AUTHORS):\n",
    "            # drop gender none?\n",
    "            # this is removing rows gender_none col\n",
    "            #gender_cols.drop('gender_none', axis=1, inplace=True)\n",
    "\n",
    "        #standardize cols_std\n",
    "        if len(cols_std)>0:\n",
    "            standardized_cols = RobustScaler().fit_transform(X[cols_std])\n",
    "\n",
    "\n",
    "        # claudia: here we could do a 20:80 split and save 20% for later test\n",
    "\n",
    "        #combine\n",
    "        H = pd.DataFrame(standardized_cols, index=X.index, columns=cols_std)\n",
    "        if INCLUDE_GENDER:\n",
    "            H = H.join(gender_cols)\n",
    "\n",
    "        y = X[f'h_index_increase_15_{EARLY_CAREER}']\n",
    "        y2 = X[f'citation_increase_15_{EARLY_CAREER}']\n",
    "        y3 = X['dropped_after_10'].astype(int)\n",
    "        \n",
    "        f1_dropout_list=[]\n",
    "        r2_hindex_list=[]\n",
    "        for i in range(10):\n",
    "            #dropouts\n",
    "            X_train, X_test, y_train, y_test = train_test_split(H, y3, test_size=0.2)\n",
    "            rgs = LogisticRegressionCV(cv=3) #, penalty='l2', solver='liblinear'\n",
    "            #rgs = SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
    "            #           early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
    "            #           l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=1000,\n",
    "            #           n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
    "            #           power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
    "            #           validation_fraction=0.1, verbose=0, warm_start=False)\n",
    "        \n",
    "            rgs.fit(X_train, y_train)\n",
    "            f1_dropout = f1_score(y_test, rgs.predict(X_test))\n",
    "            f1_dropout_list.append(f1_dropout)\n",
    "            \n",
    "            #h-index increase\n",
    "            X_train, X_test, y_train, y_test = train_test_split(H, y, test_size=0.2)\n",
    "            rgs = ElasticNetCV(cv=3)\n",
    "            #rgs = ElasticNetCV(cv=3, random_state=1000, max_iter=10000,\n",
    "            #       alphas=[1.0], l1_ratio=0.5)\n",
    "            rgs.fit(X_train, y_train)\n",
    "            r2_hindex = r2_score(y_test, rgs.predict(X_test))\n",
    "            print(rgs.alpha_)\n",
    "            r2_hindex_list.append(r2_hindex)\n",
    "            \n",
    "        print(f\"Year: {year}, f1_dropout: {np.mean(f1_dropout_list)}\")\n",
    "        print(f\"Year: {year}, r2_hindex: {np.mean(r2_hindex_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "INCLUDE_PROD = 1\n",
    "INCLUDE_SOCIAL = 1\n",
    "INCLUDE_REC = 1\n",
    "INCLUDE_GENDER = 1\n",
    "INCLUDE_QUALITY = 1\n",
    "REMOVE_NONE_AUTHORS = 0\n",
    "cols_all, cols_std, categorical_cols = make_cols_lists(INCLUDE_PROD, INCLUDE_SOCIAL, INCLUDE_REC,\n",
    "                                                       INCLUDE_QUALITY, INCLUDE_GENDER, REMOVE_NONE_AUTHORS, EARLY_CAREER, RECOGNITION_CUT)\n",
    "run_elastic_predictions_test_train(cols_all, cols_std, categorical_cols, REMOVE_NONE_AUTHORS, EARLY_CAREER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Test predictive power over different number of observed years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "EARLY_CAREER_LEN_LIST_EXT = [3,5,7,9,11,12]\n",
    "RECOGNITION_CUT_OFF_LIST_EXT = [3,5,7,9,11,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dv_citations_incr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_r2_increase(COHORT_START_YEARS, EARLY_CAREER_LEN_LIST_EXT, RECOGNITION_CUT_OFF_LIST_EXT, DV):\n",
    "    r2_increase = pd.DataFrame(index=COHORT_START_YEARS)\n",
    "    for EARLY_CAREER, RECOGNITION_CUT in zip(EARLY_CAREER_LEN_LIST_EXT, RECOGNITION_CUT_OFF_LIST_EXT):\n",
    "        print(f'{EARLY_CAREER}, {RECOGNITION_CUT}')\n",
    "        DV_ = f'{DV}_15_{EARLY_CAREER}'\n",
    "        print(DV_)\n",
    "        r2_increase[f'{DV}_{EARLY_CAREER}_{RECOGNITION_CUT}'] = elastic_cohort(credible_authors, get_full_vars,\n",
    "                                                                               EARLY_CAREER, RECOGNITION_CUT, DV_)['r2']\n",
    "    return r2_increase\n",
    "r2_increase_cit = get_r2_increase(COHORT_START_YEARS, EARLY_CAREER_LEN_LIST_EXT, RECOGNITION_CUT_OFF_LIST_EXT, 'citation_increase')\n",
    "r2_increase_hind = get_r2_increase(COHORT_START_YEARS, EARLY_CAREER_LEN_LIST_EXT, RECOGNITION_CUT_OFF_LIST_EXT, 'h_index_increase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "r2_increase_hind.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "linewidth = 2\n",
    "fontsize = 18\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot([3,5,7,9,11,12], r2_increase_cit.mean().values, label='citation inc.')\n",
    "ax.plot([3,5,7,9,11,12], r2_increase_hind.mean().values, label='h-index inc.')\n",
    "\n",
    "ax.xaxis.set_ticks_position('both')\n",
    "ax.yaxis.set_ticks_position('both')\n",
    "ax.set_xticks([3,5,7,9,11])\n",
    "\n",
    "ax.set_xlabel('Number of observed years', fontsize=fontsize)\n",
    "ax.set_ylabel('Avg. R2 over cohorts', fontsize=fontsize)\n",
    "ax.set_title(\"Prediction R2 vs observed years\", fontsize=fontsize)\n",
    "ax.tick_params(axis=\"x\", which='major', direction=\"in\", width=linewidth, size=4*linewidth, labelsize=fontsize, pad=7)\n",
    "ax.tick_params(axis=\"x\", which='minor', direction=\"in\", width=linewidth, size=2*linewidth, labelsize=fontsize, pad=7)\n",
    "ax.tick_params(axis=\"y\", which='major', direction=\"in\", width=linewidth, size=4*linewidth, labelsize=fontsize)\n",
    "ax.tick_params(axis=\"y\", which='minor', direction=\"in\", width=linewidth, size=2*linewidth, labelsize=fontsize)\n",
    "ax.spines['left'].set_linewidth(linewidth)\n",
    "ax.spines['right'].set_linewidth(linewidth)\n",
    "ax.spines['bottom'].set_linewidth(linewidth)\n",
    "ax.spines['top'].set_linewidth(linewidth)\n",
    "ax.legend(fontsize=fontsize/1.5)\n",
    "plt.gcf().text(0., 0.9, 'D', fontsize=fontsize*2)\n",
    "plt.subplots_adjust(left=0.25, right=0.95, bottom=0.2, top=0.9)\n",
    "plt.savefig('./fig/pred_r2_obs_years.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Test predictive power over different number of years being predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "EARLY_CAREER_LEN_LIST_EXT = [3,5,7,9,11,12]\n",
    "RECOGNITION_CUT_OFF_LIST_EXT = [3,5,7,9,11,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_r2_increase_(COHORT_START_YEARS, EARLY_CAREER_LEN_LIST_EXT, RECOGNITION_CUT_OFF_LIST_EXT, DV):\n",
    "    r2_increase = pd.DataFrame(index=COHORT_START_YEARS)\n",
    "    for EARLY_CAREER, RECOGNITION_CUT in zip(EARLY_CAREER_LEN_LIST_EXT[1:], RECOGNITION_CUT_OFF_LIST_EXT[1:]):\n",
    "        print(f'{EARLY_CAREER}, {RECOGNITION_CUT}')\n",
    "        DV_ = f'{DV}_{EARLY_CAREER}_3'\n",
    "        print(DV_)\n",
    "        r2_increase[f'{DV}_{EARLY_CAREER}_3'] = elastic_cohort(credible_authors, get_full_vars, 3, 3, DV_)['r2']\n",
    "    return r2_increase\n",
    "r2_increase_cit_pred = get_r2_increase_(COHORT_START_YEARS, EARLY_CAREER_LEN_LIST_EXT, RECOGNITION_CUT_OFF_LIST_EXT, 'citation_increase')\n",
    "r2_increase_hind_pred = get_r2_increase_(COHORT_START_YEARS, EARLY_CAREER_LEN_LIST_EXT, RECOGNITION_CUT_OFF_LIST_EXT, 'h_index_increase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "linewidth = 2\n",
    "fontsize = 18\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot([2,4,6,8,9], r2_increase_cit_pred.mean().values, label='citation inc.')\n",
    "ax.plot([2,4,6,8,9], r2_increase_hind_pred.mean().values, label='h-index inc.')\n",
    "\n",
    "ax.xaxis.set_ticks_position('both')\n",
    "ax.yaxis.set_ticks_position('both')\n",
    "ax.set_xticks([2,4,6,8,9])\n",
    "\n",
    "ax.set_xlabel('Number of years predicted ahead', fontsize=fontsize)\n",
    "ax.set_ylabel('Avg. R2 over cohorts', fontsize=fontsize)\n",
    "ax.set_title(\"Prediction R2 vs years ahead\", fontsize=fontsize)\n",
    "ax.tick_params(axis=\"x\", which='major', direction=\"in\", width=linewidth, size=4*linewidth, labelsize=fontsize, pad=7)\n",
    "ax.tick_params(axis=\"x\", which='minor', direction=\"in\", width=linewidth, size=2*linewidth, labelsize=fontsize, pad=7)\n",
    "ax.tick_params(axis=\"y\", which='major', direction=\"in\", width=linewidth, size=4*linewidth, labelsize=fontsize)\n",
    "ax.tick_params(axis=\"y\", which='minor', direction=\"in\", width=linewidth, size=2*linewidth, labelsize=fontsize)\n",
    "ax.spines['left'].set_linewidth(linewidth)\n",
    "ax.spines['right'].set_linewidth(linewidth)\n",
    "ax.spines['bottom'].set_linewidth(linewidth)\n",
    "ax.spines['top'].set_linewidth(linewidth)\n",
    "ax.legend(fontsize=fontsize/1.5)\n",
    "plt.gcf().text(0., 0.9, 'D', fontsize=fontsize*2)\n",
    "plt.subplots_adjust(left=0.25, right=0.95, bottom=0.2, top=0.9)\n",
    "plt.savefig('./fig/pred_r2_per_years.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### predictor diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "h_index = res_cohort_full_hind\n",
    "citations = res_cohort_full_cita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(h_index['r2'], label='Increase H index')\n",
    "plt.plot(citations['r2'], label='Increase Citations')\n",
    "print(\"Average difference in r squared\", sum(citations['r2']-h_index['r2'])/len(h_index['r2']))\n",
    "# quality was used as a feature!\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### gender diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# gender coefs\n",
    "plt.plot(res_cohort_full_hind['gender_m'], label=\"Male\")\n",
    "plt.plot(res_cohort_full_hind['gender_f'], label=\"Female\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(res_cohort_full_hind['gender_m'] - res_cohort_full_hind['gender_f'], label=\"Male-Female diff\")\n",
    "plt.plot(res_cohort_full_hind.index ,np.zeros(len(res_cohort_full_hind)))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### cohort size diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "# ax1.plot(results['r2'], label='r2')\n",
    "ax1.plot(res_cohort_full_hind['r2'], label='adjusted r2', color='C2')\n",
    "ax1.set_ylim([0,1])\n",
    "ax1.set_xlabel('Years')\n",
    "ax1.set_ylabel('R squared', color='C2')\n",
    "ax1.legend(loc=2)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(res_cohort_full_hind['cohort_size'], label='Cohort size', color='C3')\n",
    "ax2.set_ylabel('Cohort size', color='C3')\n",
    "ax2.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### cheating diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "no_cheating = feature_table2.transpose().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cheat_RC5 = feature_table2.transpose().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cheat_quality = feature_table2.transpose().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# How does removing the quality affect the r squared?\n",
    "plt.plot(with_quality['adj_r2'], label='With quality')\n",
    "plt.plot(cheat_RC5['adj_r2'], label='With recognition year 5')\n",
    "plt.plot(no_cheating['adj_r2'], label='No cheating')\n",
    "print(\"Average difference in r squared\", sum(with_quality['adj_r2']-no_cheating['adj_r2'])/len(cheat_quality))\n",
    "print(np.mean)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "avg = sum(cheat_quality['adj_r2']-no_cheating['adj_r2'])/len(no_cheating)\n",
    "plt.plot(cheat_quality['adj_r2']-no_cheating['adj_r2'], label='Difference')\n",
    "plt.plot(no_cheating.index, [avg]*len(no_cheating), label='Average diff')\n",
    "plt.title(\"Difference between quality(15y) and recognition(3y)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### scaler diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "std_scaler = feature_table2.transpose().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rob_scaler = feature_table2.transpose().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# How does changing the scaler affect the r squared?\n",
    "plt.plot(std_scaler['adj_r2'], label='Std')\n",
    "plt.plot(rob_scaler['adj_r2'], label='Rob')\n",
    "print(\"Average difference in r squared\", sum(std_scaler['adj_r2']-rob_scaler['adj_r2'])/len(rob_scaler))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# almost no difference\n",
    "\n",
    "avg = sum(std_scaler['adj_r2']-rob_scaler['adj_r2'])/len(std_scaler)\n",
    "plt.plot(std_scaler['adj_r2']-rob_scaler['adj_r2'], label='Difference')\n",
    "plt.plot(std_scaler.index, [avg]*len(std_scaler), label='Average diff')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# feature_table3.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Best feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression, RFE, RFECV\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def show_kbest(data_frame, target, linear_rel=True, k=4):\n",
    "    \"\"\"\n",
    "    Selecting K-Best features for classification\n",
    "    :param data_frame: A pandas dataFrame with the training data\n",
    "    :param target: target variable name in DataFrame\n",
    "    :param k: desired number of features from the data\n",
    "    :returns feature_scores: scores for each feature in the data as \n",
    "    pandas DataFrame\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    if linear_rel == True: \n",
    "        feat_selector = SelectKBest(f_regression, k=k)\n",
    "        col_name = \"F Score\"\n",
    "    else:\n",
    "        feat_selector = SelectKBest(mutual_info_regression, k=k)\n",
    "        col_name = \"Mutual Information\"\n",
    "    \n",
    "    feat_selector = feat_selector.fit(data_frame, target)\n",
    "    feat_scores = pd.DataFrame()\n",
    "    feat_scores[col_name] = feat_selector.scores_\n",
    "    feat_scores[\"P Value\"] = feat_selector.pvalues_\n",
    "    feat_scores[\"Support\"] = feat_selector.get_support()\n",
    "    feat_scores[\"Attribute\"] = data_frame.columns\n",
    "    \n",
    "    return feat_scores \n",
    "\n",
    "def get_features_rfe(data_frame, target, model,k=5):\n",
    "    \"\"\"\n",
    "    Returns list of features (k specified) selected using RFE for\n",
    "    :param data_frame: A pandas dataFrame with features and labels\n",
    "    :param k: top k features to select  \n",
    "    :returns list: most relevant features \n",
    "    \"\"\"\n",
    "    X = data_frame\n",
    "    y = target\n",
    "    selector = RFE(model, k, step=1)\n",
    "    selector = selector.fit(X, y)\n",
    "#     print(selector.support_)\n",
    "    df = pd.DataFrame({\n",
    "        \"feature\": X.columns,\n",
    "        \"support\": selector.support_\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def get_features_rfecv(data_frame, target, model, cv=3):\n",
    "    \"\"\"\n",
    "    Returns list of features (k specified) selected using RFE for\n",
    "    :param data_frame: A pandas dataFrame with features and labels\n",
    "    :param k: top k features to select  \n",
    "    :returns list: most relevant features \n",
    "    \"\"\"\n",
    "    X = data_frame\n",
    "    y = target\n",
    "    selector = RFECV(model, step=1, cv=cv)\n",
    "    selector = selector.fit(X, y)\n",
    "#     print(selector.support_)\n",
    "    df = pd.DataFrame({\n",
    "        \"feature\": X.columns,\n",
    "        \"support\": selector.support_\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "years = credible_authors.start_year.unique()\n",
    "years = sorted(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = credible_authors.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "categorical_cols = ['gender']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df = df.join(pd.get_dummies(df[categorical_cols]))\n",
    "\n",
    "df.drop(categorical_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Show k best - F regression or mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "linear = True\n",
    "# true - fregression\n",
    "# false - mutual info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params = []\n",
    "for year in years:\n",
    "    df_year = df[df.start_year == year]\n",
    "    df_year = df_year.drop('start_year', axis=1)\n",
    "#     for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "#         for RECOGNITION_CUT in RECOGNITION_CUT_OFF_LIST:\n",
    "#             if RECOGNITION_CUT < EARLY_CAREER: continue\n",
    "    EARLY_CAREER = 3\n",
    "    RECOGNITION_CUT= 5\n",
    "    X_year = df_year[['max_absence-0-3', 'avg_absence-0-3', \n",
    "           'gender_f', 'gender_m', 'gender_none',\n",
    "           f'early_career_degree_{EARLY_CAREER}', \n",
    "           f'early_career_prod_{EARLY_CAREER}',\n",
    "           f'early_career_qual_{EARLY_CAREER}', f'early_career_recognition_EC{EARLY_CAREER}_RC{RECOGNITION_CUT}']]\n",
    "    y_year = df_year['succ_after_15y']\n",
    "    params.append(show_kbest(X_year, y_year, linear, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "selected_f = defaultdict(int)\n",
    "for param in params:\n",
    "    selected = param[param.Support == True]['Attribute'].values\n",
    "    selected_f['total'] += 1\n",
    "#     print(selected)\n",
    "    for select in selected:\n",
    "        selected_f[select] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "selected_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params_rfe = []\n",
    "for year in years:\n",
    "    df_year = df[df.start_year == year]\n",
    "    df_year = df_year.drop('start_year', axis=1)\n",
    "#     for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "#         for RECOGNITION_CUT in RECOGNITION_CUT_OFF_LIST:\n",
    "#             if RECOGNITION_CUT < EARLY_CAREER: continue\n",
    "    EARLY_CAREER = 3\n",
    "    RECOGNITION_CUT= 5\n",
    "    X_year = df_year[[\n",
    "        #'max_absence-0-3', 'avg_absence-0-3', \n",
    "           'gender_f', 'gender_m', 'gender_none',\n",
    "           f'early_career_degree_{EARLY_CAREER}', \n",
    "           f'early_career_prod_{EARLY_CAREER}',\n",
    "           f'early_career_qual_{EARLY_CAREER}', f'early_career_recognition_EC{EARLY_CAREER}_RC{RECOGNITION_CUT}']]\n",
    "    y_year = df_year['succ_after_15y']\n",
    "    params_rfe.append(get_features_rfe(X_year, y_year, LinearRegression(),k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "selected_f = defaultdict(int)\n",
    "for param in params_rfe:\n",
    "    selected = param[param.support == True]['feature'].values\n",
    "    selected_f['total'] += 1\n",
    "#     print(selected)\n",
    "    for select in selected:\n",
    "        selected_f[select] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "selected_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### RFE CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params_rfecv = []\n",
    "for year in years:\n",
    "    df_year = df[df.start_year == year]\n",
    "    df_year = df_year.drop('start_year', axis=1)\n",
    "#     for EARLY_CAREER in EARLY_CAREER_LEN_LIST:\n",
    "#         for RECOGNITION_CUT in RECOGNITION_CUT_OFF_LIST:\n",
    "#             if RECOGNITION_CUT < EARLY_CAREER: continue\n",
    "    EARLY_CAREER = 3\n",
    "    RECOGNITION_CUT= 5\n",
    "    X_year = df_year[['max_absence-0-3', 'avg_absence-0-3', \n",
    "           'gender_f', 'gender_m', 'gender_none',\n",
    "           f'early_career_degree_{EARLY_CAREER}', \n",
    "           f'early_career_prod_{EARLY_CAREER}',\n",
    "           f'early_career_qual_{EARLY_CAREER}', f'early_career_recognition_EC{EARLY_CAREER}_RC{RECOGNITION_CUT}']]\n",
    "    y_year = df_year['succ_after_15y']\n",
    "    params_rfecv.append(get_features_rfecv(X_year, y_year, LinearRegression(),cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "selected_f = defaultdict(int)\n",
    "for param in params_rfecv:\n",
    "    selected = param[param.support == True]['feature'].values\n",
    "    selected_f['total'] += 1\n",
    "#     print(selected)\n",
    "    for select in selected:\n",
    "        selected_f[select] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "selected_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations_per_year = pd.read_csv('derived-data/paper-citation-count.csv', header=None, names=['pub_id', 'cit_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publications = pd.read_csv('derived-data/author-publications.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# publications.sort_values(by='author').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove authors by career_len, and add start year\n",
    "publications = publications.merge(credible_authors[['author', 'start_year']], on='author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publications = publications[publications.year <= publications.year + MAX_CAREER_LEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# citations_per_year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publications['pub_id'] = shuffle(publications['pub_id']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# publications.sort_values(by='author').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publications = publications.merge(citations_per_year, on='pub_id', how='left')\n",
    "publications = publications.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publications.sort_values(by='author').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_authors[credible_authors.author == \"a min tjoa\"]['succ_after_15y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_authors.set_index('author', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_authors['succ_shuffled'] = publications.groupby('author')['cit_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_authors[['succ_shuffled', 'succ_after_15y']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_authors.columns"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
